,link,text,title,date,author,keywords,summary,source
0,https://artificialintelligence-news.com/,"



Learning the lessons of the past to fast-forward to the future of work










If you take a keen interest in technology and the economy, you may well have come across the term ‘fourth industrial revolution’ recently. This moniker has become a common label for the current period in which intelligent technologies such as AI, automation and robotics are becoming... 






        3 February 2021                    |
            Society





",Artificial Intelligence News,,['Ryan Daws'],"['succeed', 'research', 'users', 'thorough', 'intelligence', 'ai', 'view', 'vendors', 'artificial', 'report', 'strategy', 'understanding']","Research firm Strategy Analytics has argued in a new report that both vendors of AI products and their users can succeed with a 'thorough understanding' of customer journeys.
The report, 'Defining the AI Buyer Journey', aims to take a comprehensive view of the 'who, what, why and how...",AInews
1,https://artificialintelligence-news.com/2020/12/09/from-fantasy-to-reality-misunderstanding-the-impact-of-ai/,"

From fantasy to reality: Misunderstanding the impact of AI




 






By Rachel Roumeliotis |
        December 9, 2020
https://www.oreilly.com/ 
                            Categories:
                                    Adoption,
                                    Education,
                                    Entertainment,
                                    Research,
                        


Rachel Roumeliotis is vice president of data and AI at O’Reilly.




The prominence of artificial intelligence (AI) has significantly grown in pop culture and science fiction over the years. It has speculated on how AI can change people’s lives, the places we live and our day-to-day activities. However, despite the increase of AI in popular films such as I, Robot, Star Trek and WALL-E, it’s continued depiction and futuristic tendencies throughout the years have altered individual perceptions about the true meaning of AI and how it is already playing a vital part in our everyday lives.
A recent survey conducted by O’Reilly paints this exact picture. It gives AI-creators an in-depth look at how consumers identify and use AI technology, showcasing the heightened misunderstanding that consumers have of AI and its use.
AI takes over popular culture
Television and the big screen have played a large role in introducing AI into our homes, but how does this depiction impact how we develop and implement the technology?
For those working to incorporate AI technology into products and develop new ways to use it, robots and cars are not an everyday focus. The areas of advancement instead look at AI that learns from our actions to more efficiently help us in our day-to-day lives, answering questions for us and completing tasks through speech recognition and language processing at work and at home.
But how do we harness the excitement around the fantasy of AI to increase everyday adoption?
The true potential of AI
One of the best ways to merge the fantasy and reality of AI is to truly understand what consumers think and what they believe is the potential of the technology.
In our survey, when asked what the most useful form of AI is, more than half (58%) of consumers regarded smart home technology as the most vital. This was closely followed by home security systems (54%), travel recommendations (52%), and virtual assistants (50%). This provides insight into how AI creators can expand their ideas of where AI can be useful to encourage consumers to adopt it in their personal lives.
While AI is already present in our homes—thanks to smart speakers from Amazon, Apple and Google—more and more consumer groups appreciate the success of smart home technology and are willing to adopt it in the future.
Answering the questions: What is AI? And why should I care?
Survey respondents were also asked what application of AI excited them the most in the future. Fraud detection (28%) topped the list as the most exciting area for AI development.
It was the most commonly cited use by men. This is despite only 11% of consumers closely associating fraud detection with AI.
While self-driving cars also generated great excitement among 24% of respondents, interestingly, it was the most popular choice among women, younger consumers, and those working in the AI industry by a significant margin (50%). With fraud detection coming out on top, we can start to see the shift from fantasy to practicality, a trend that AI-creators should leverage to reinforce the pragmatic use of AI within the workforce.
It is up to a wide range of individuals including developers, marketers, product managers and sales to ensure that AI is used and understood correctly. For successful consumer AI adoption, developers should focus their efforts on leveraging AI to make consumers’ everyday lives easier, augmenting existing experiences to make them more seamless and exciting. While there might be an indifference with fantasy and reality, more and more consumer groups appreciate the success of smart home technology and are watching the development of autonomous vehicles very closely. 
It’s up to these sectors to capitalise on the hype, but the results are also a call for the creators of work-focused AI to make solutions that capture the imagination and generate excitement. Not only this, but developers need to have in mind consumer needs relatively clearly even at the start of the process when an idea might be more amorphous.
What’s next?
What does the future hold for AI? While the notion of AI has been perpetuated in popular culture and science fiction throughout our lives, individuals are yet to understand the meaning that AI has and that it isn’t an ‘out-there’ concept. In fact, it is already all around us. It plays a role in our homes and at work, in ways that we wouldn’t expect.
Ultimately, AI creators need to bear this in mind and continuously learn from consumer attitudes towards AI to ensure individuals continue to stay engaged with technology, making the most out of the fantasy.

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 






View Comments


Leave a comment




            One comment on “From fantasy to reality: Misunderstanding the impact of AI”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",From fantasy to reality: Misunderstanding the impact of AI,2020-12-09,"['Rachel Roumeliotis', 'Rachel Roumeliotis Is Vice President Of Data', 'Ai At O Reilly.']","['everyday', 'technology', 'misunderstanding', 'consumers', 'popular', 'fantasy', 'smart', 'reality', 'expo', 'ai', 'lives', 'consumer', 'impact']","It gives AI-creators an in-depth look at how consumers identify and use AI technology, showcasing the heightened misunderstanding that consumers have of AI and its use.
For those working to incorporate AI technology into products and develop new ways to use it, robots and cars are not an everyday focus.
But how do we harness the excitement around the fantasy of AI to increase everyday adoption?
For successful consumer AI adoption, developers should focus their efforts on leveraging AI to make consumers’ everyday lives easier, augmenting existing experiences to make them more seamless and exciting.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
2,https://artificialintelligence-news.com/2020/12/15/from-experimentation-to-implementation-how-ai-is-proving-its-worth-in-financial-services/,"

From experimentation to implementation: How AI is proving its worth in financial services




 






By Mani Nagasundaram |
        December 15, 2020
https://www.hcltech.com/ 
                            Categories:
                                    Adoption,
                                    Enterprise,
                                    Fintech,
                                    Machine Learning,
                        


Mani Nagasundaram is SVP and head of solutions, global financial services at HCL Technologies.




For financial institutions, recovering from the pandemic will put an end to tentative experiments with artificial intelligence (AI) and machine learning (ML), and demand their large-scale adoption. The crisis has required financial organisations to respond to customer needs around the clock. Many are therefore transforming with ever-increasing pace, but they must ensure that their core critical operations continue to run smoothly. This has sparked an interest in AI and ML solutions, which reduce the need for manual intervention in operations, significantly improve security and free up time for innovation. Reducing the time between the generation of an idea and it delivering value for the business, AI and ML promise long-term, strategic advantages for organisations.
We’re now seeing banks transforming into digitally driven enterprises akin to big tech firms, building capabilities that enable a relentless focus on customers. So how can banks and finance institutions make the most of AI, and what are the key use cases in practice?
Benefits across the business
Many financial services firms had already adopted AI and ML prior to the pandemic. However, many had difficulties identifying which key functions benefit most from AI, and so the technology did not always deliver the returns expected. This is set to change in the coming months: increased AI and ML deployment will be at the heart of the economic recovery from COVID-19, and the pandemic has highlighted particular areas where AI should be applied. These range from informing credit decisions and preventing fraud, to improving the customer experience through frictionless, 24/7 interactions.
Some specific financial services processes that can be improved by AI include:
Document processing with intelligent automation
Intelligent and robotic process automation optimise various functions, enhance efficiency, and improve the overall speed and accuracy of core financial processes, leading to substantial cost-savings. One area that has risen in prominence is e-KYC, or ‘electronic know-your-customer’. This is a remote, paperless process that reduces the bureaucratic costs of crucial ‘know-your-customer’ protocols, such as verification of client identities and signatures.
This task once involved repetitive, mundane actions with considerable effort required just to keep track of document handling, loan disbursement and repayment, as well as regulatory reporting of the entire process. However, this year, organisations are embracing intelligent automation platforms that manage, interpret and extract unstructured data, including text, images, scanned documents (handwritten and electronic), faxes, and web content. Running on an NLP (natural language processing) engine, which identifies any missing, unseen, and ill-formed data, these platforms offer near-perfect accuracy and higher reliability. Average handling time is reduced, and firms gain a significant competitive advantage through an improved customer experience.
Efficient and thorough customer support
Virtual assistants can respond to customer needs with minimal employee input. A straightforward  means of increasing productivity, the time and effort spent on generic customer queries is reduced, freeing up teams to focus on longer-term projects that drive innovation across the business.
We’re all familiar with chatbots on e-commerce sites, and such solutions will become increasingly common in the financial services industry, with organisations such as JP Morgan now making use of these bots to streamline their back-office operations and strengthen customer support. The platforms involve COIN, short for ‘contract intelligence’, which runs on an ML system powered by the bank’s private cloud network. As well as creating appropriate responses to general queries, COIN automates legal filing tasks, reviews documents, handles basic IT requests such as password resets, and creates new tools for both bankers and clients with greater proficiency and less human error. 
Risk management analytics
Estimating creditworthiness is largely based on the likelihood of an individual or business repaying a loan. Determining the chances of default underpins the risk management processes at all lending organisations. Even with impeccable data, assessing this has its difficulties, as some individuals and organisations can be untruthful about their ability to pay their loans back.
To combat this, companies such as Lenddo and ZestFinance are using AI for risk assessment, and to determine an individual’s creditworthiness. Credit bureaus such as Equifax also use AI, ML and advanced data and analytical tools to analyse alternate sources in the evaluation of risk, and gain customer insight in the process.
Lenders once used a limited set of data, such as annual salaries and credit scores, for this process. However, thanks to AI, organisations are now able to consider an individual’s entire digital financial footprint to determine the likelihood of default. In addition to traditional data sets, the analysis of this alternative data is particularly useful in determining the creditworthiness of individuals without conventional records of loan or credit history.
The time to adopt is now
The way that businesses and clients interact with each other has changed irreversibly this year, and the finance industry is no different. Before the urgency demanded by the pandemic, financial institutions had been experimenting with AI and ML on a limited scale – mainly as a tick-box exercise in an effort to ‘keep up with the Joneses’. The widespread adoption that has been taking place this year stems from the need to truly innovate and increase resilience across the sector.
Banks and financial institutions are now aware of the key areas that benefit from AI, such as greater efficiency in back office operations, and significant improvements in customer engagement. A transformation process that was in its infancy prior to Covid-19 has accelerated and is fast becoming the standard approach. What’s more, financial organisations that are embracing AI now and prioritising its full implementation will be best placed to reap its rewards in the future.
Photo by Jeffrey Blum on Unsplash

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 






View Comments


Leave a comment




            One comment on “From experimentation to implementation: How AI is proving its worth in financial services”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",From experimentation to implementation: How AI is proving its worth in financial services,2020-12-15,"['Mani Nagasundaram', 'Mani Nagasundaram Is Svp', 'Head Of Solutions', 'Global Financial Services At Hcl Technologies.']","['process', 'experimentation', 'data', 'customer', 'proving', 'services', 'ml', 'pandemic', 'expo', 'ai', 'operations', 'financial', 'worth', 'implementation', 'organisations']","The crisis has required financial organisations to respond to customer needs around the clock.
Benefits across the businessMany financial services firms had already adopted AI and ML prior to the pandemic.
However, thanks to AI, organisations are now able to consider an individual’s entire digital financial footprint to determine the likelihood of default.
What’s more, financial organisations that are embracing AI now and prioritising its full implementation will be best placed to reap its rewards in the future.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
3,https://artificialintelligence-news.com/2020/12/14/eu-human-rights-agency-issues-report-ai-ethical-considerations/,"

EU human rights agency issues report on AI ethical considerations




 






By Ryan Daws |
        December 14, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Ethics,
                                    Europe,
                                    Government,
                                    Policy,
                                    Regulation,
                                    Research,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The European Union’s Fundamental Rights Agency (FRA) has issued a report on AI which delves into the ethical considerations which must be made about the technology.
FRA’s report is titled Getting The Future Right and opens with some of the ways AI is already making lives better—such as helping with cancer diagnosis, and even predicting where burglaries are likely to take place.
“The possibilities seem endless,” writes Michael O’Flaherty, Director of the FRA, in the report’s foreword. “But how can we fully uphold fundamental rights standards when using AI?”
The FRA interviewed over a hundred public administration officials, private company staff, and a diverse range of experts, in a bid to answer that question.
With evidence of algorithms having biases which could lead to automating societal issues like racial profiling—it’s a question that needs answering if the full potential of AI is going to be unlocked for the whole of society.
O’Flaherty says:
“AI is not infallible, it is made by people – and humans can make mistakes. That is why people need to be aware when AI is used, how it works and how to challenge automated decisions. The EU needs to clarify how existing rules apply to AI. And organisations need to assess how their technologies can interfere with people’s rights both in the development and use of AI.“We have an opportunity to shape AI that not only respects our human and fundamental rights but that also protects and promotes them.”
AI is being used in almost every industry in some form or another—if not already, it will be soon.
Biases in AI are more dangerous in some industries than others. Policing is an obvious example, but in areas like financial services it could mean one person being given a loan or mortgage compared to another.
Without due transparency, these biases could happen without anyone knowing the reasons behind such decisions—it could simply be because someone grew up in a different neighbourhood. Each automated decision has a very real human impact.
The FRA calls for the EU to:
Make sure that AI respects ALL fundamental rights – AI can affect many rights – not just privacy or data protection. It can also discriminate or impede justice. Any future AI legislation has to consider this and create effective safeguards.Guarantee that people can challenge decisions taken by AI – people need to know when AI is used and how it is used, as well as how and where to complain. Organisations using AI need to be able to explain how their systems take decisions.Assess AI before and during its use to reduce negative impacts – private and public organisations should carry out assessments of how AI could harm fundamental rights.Provide more guidance on data protection rules – the EU should further clarify how data protection rules apply to AI. More clarity is also needed on the implications of automated decision-making and the right to human review when AI is used.Assess whether AI discriminates – awareness about the potential for AI to discriminate, and the impact of this, is relatively low. This calls for more research funding to look into the potentially discriminatory effects of AI so Europe can guard against it.Create an effective oversight system – the EU should invest in a more ‘joined-up’ system to hold businesses and public administrations accountable when using AI. Authorities need to ensure that oversight bodies have adequate resources and skills to do the job.
The EU has increased its scrutiny of “big tech” companies like Google in recent years over concerns of invasive privacy practices and abusing their market positions. Last week, AI News reported that Google had controversially fired leading AI ethics researcher Timnit Gebru after she criticised her employer in an email.
Google chief executive Sundar Pichai wrote in a memo: “We need to accept responsibility for the fact that a prominent black, female leader with immense talent left Google unhappily.
“It’s incredibly important to me that our black, women, and under-represented Googlers know that we value you and you do belong at Google.”
Gebru gave an interview to the BBC this week in which she called Google and big tech “institutionally racist”. With that in mind, the calls made in the FRA’s report seem especially important to heed.
You can download a full copy of the FRA’s report here.
(Photo by Guillaume Périgois on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, ai bias, algorithm, algorithmic bias, artificial intelligence, bias, ethics, eu, europe, Featured, fra, Fundamental Rights Agency, Getting The Future Right, report, research, study






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",EU human rights agency issues report on AI ethical considerations,2020-12-14,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['agency', 'issues', 'human', 'fundamental', 'rights', 'eu', 'need', 'expo', 'tech', 'considerations', 'ai', 'google', 'ethical', 'report', 'used']","The European Union’s Fundamental Rights Agency (FRA) has issued a report on AI which delves into the ethical considerations which must be made about the technology.
The FRA calls for the EU to:Make sure that AI respects ALL fundamental rights – AI can affect many rights – not just privacy or data protection.
Organisations using AI need to be able to explain how their systems take decisions.
Assess AI before and during its use to reduce negative impacts – private and public organisations should carry out assessments of how AI could harm fundamental rights.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
4,https://artificialintelligence-news.com/2020/03/19/gartner-strongest-demand-for-ai-talent-coming-from-outside-of-it/,"

Gartner: Strongest demand for AI talent coming from outside of IT




 



 

By James Bourne |
        March 19, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Adoption,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




A new report from Gartner has argued that in the last
four years the strongest demand for talent with AI skills has not come from the
IT department, but instead from other business units in the organisation. 
Data from Gartner’s Talent Neuron program shows that
although the IT department’s need for AI talent has tripled between 2015 and
2019, the number of AI jobs posted by IT is still less than half of that
stemming from other business units.
Peter Krensky, research director at Gartner, said: “High
demand and tight labour markets have made candidates with AI skills highly
competitive, but hiring techniques and strategies have not kept up. In the
recent Gartner AI and Machine Learning Development Strategies Study,
respondents ranked “skills of staff” as the No. 1 challenge or barrier to the
adoption of AI and machine learning.”
Sales, marketing, customer service, finance, and R&D
are the departments that are recruiting AI talent in large numbers. These
business units are also using the AI talent for customer churn modelling,
customer profitability analysis, customer segmentation, cross-sell and upsell
recommendations, demand planning, and risk management.
A recent WhiteHat Security survey
 of industry professionals reveal that over half of the organisations 
use AI or machine learning in their security stack. According to the 
survey, three-quarters of respondents use an application security tool, 
and over 40% of those application security solutions use both AI- and 
human-based verification. Meanwhile, an Oracle study
 of 700 respondents stated that organisations adopting AI alongside 
other emerging technologies in finance and operations are likely to see 
their annual profits grow 80% faster.





 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam. 


 






View Comments


Leave a comment




            One comment on “Gartner: Strongest demand for AI talent coming from outside of IT”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Gartner: Strongest demand for AI talent coming from outside of IT,2020-03-19,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['gartner', 'coming', 'outside', 'security', 'customer', 'business', 'strongest', 'skills', 'james', 'respondents', 'ai', 'demand', 'machine', 'talent']","A new report from Gartner has argued that in the last four years the strongest demand for talent with AI skills has not come from the IT department, but instead from other business units in the organisation.
Peter Krensky, research director at Gartner, said: “High demand and tight labour markets have made candidates with AI skills highly competitive, but hiring techniques and strategies have not kept up.
In the recent Gartner AI and Machine Learning Development Strategies Study, respondents ranked “skills of staff” as the No.
1 challenge or barrier to the adoption of AI and machine learning.”Sales, marketing, customer service, finance, and R&D are the departments that are recruiting AI talent in large numbers.
These business units are also using the AI talent for customer churn modelling, customer profitability analysis, customer segmentation, cross-sell and upsell recommendations, demand planning, and risk management.",AInews
5,https://artificialintelligence-news.com/2020/04/20/ai-researchers-toolbox-verifying-ethics-claims/,"

Leading AI researchers propose ‘toolbox’ for verifying ethics claims




 






By Ryan Daws |
        April 20, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Google,
                                    Intel,
                                    Machine Learning,
                                    OpenAI,
                                    Policy,
                                    Privacy,
                                    Regulation,
                                    Society,
                                    TECHEX,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers from OpenAI, Google Brain, Intel, and 28 other leading organisations have published a paper which proposes a ‘toolbox’ for verifying AI ethics claims.
With concerns around AI spanning from dangerous indifference to innovation-halting scaremongering; it’s clear there’s a need for a system to achieve a healthy balance.
“AI systems have been developed in ways that are inconsistent with the stated values of those developing them,” the researchers wrote. “This has led to a rise in concern, research, and activism relating to the impacts of AI systems.”
The researchers note that significant work has gone into articulating ethical principles by many players involved with AI development, but the claims are meaningless without some way to verify them.
“People who get on airplanes don’t trust an airline manufacturer because of its PR campaigns about the importance of safety – they trust it because of the accompanying infrastructure of technologies, norms, laws, and institutions for ensuring airline safety.”
Among the core ideas put forward is to pay developers for discovering bias in algorithms. Such a practice is already widespread in cybersecurity; with many companies offering up bounties to find bugs in their software.
“Bias and safety bounties would extend the bug bounty concept to AI and could complement existing efforts to better document data sets and models for their performance limitations and other properties,” the authors wrote.
“We focus here on bounties for discovering bias and safety issues in AI systems as a starting point for analysis and experimentation but note that bounties for other properties (such as security, privacy protection, or interpretability) could also be explored.”
Another potential avenue is so-called “red teaming,” the creation of a dedicated team which adopts the mindset of a possible attacker to find flaws and vulnerabilities in a plan, organisation, or technical system.
“Knowledge that a lab has a red team can potentially improve the trustworthiness of an organization with respect to their safety and security claims.”
A red team alone is unlikely to give too much confidence; but combined with other measures can go a long way. Verification from parties outside an organisation itself will be key to instil trust in that company’s AI developments.
“Third party auditing is a form of auditing conducted by an external and independent auditor, rather than the organization being audited, and can help address concerns about the incentives for accuracy in self-reporting.”
“Provided that they have sufficient information about the activities of an AI system, independent auditors with strong reputational and professional incentives for truthfulness can help verify claims about AI development.”
The researchers highlight that a current roadblock with third-party auditing is that there’s yet to be any techniques or best practices established specifically for AI. Frameworks, such as Claims-Arguments-Evidence (CAE) and Goal Structuring Notation (GSN), may provide a starting place as they’re already widely-used for safety-critical auditing.
Audit trails, covering all steps of the AI development process, are also recommended to become the norm. The researchers again point to commercial aircraft, as a safety-critical system, and their use of flight data recorders to capture multiple types of data every second and provide a full log.
“Standards setting bodies should work with academia and industry to develop audit trail requirements for safety-critical applications of AI systems.”
The final suggestion for software-oriented methods of verifying AI ethics claims is the use of privacy-preserving machine learning (PPML).
Privacy-preserving machine learning aims to protect the privacy of data or models used in machine learning, at training or evaluation time, and during deployment.
Three established types of PPML are covered in the paper: Federated learning, differential privacy, and encrypted computation.
“Where possible, AI developers should contribute to, use, and otherwise support the work of open-source communities working on PPML, such as OpenMined, Microsoft SEAL, tf-encrypted, tf-federated, and nGraph-HE.”
The researchers, representing some of the most renowned institutions in the world, have come up with a comprehensive package of ways any organisation involved with AI development can provide assurance to governance and the wider public to ensure the industry can reach its full potential responsibly.
You can find the full preprint paper on arXiv here (PDF)
(Photo by Alexander Sinn on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, ethics, Featured, Google, intel, openai, Society






View Comments


Leave a comment




            One comment on “Leading AI researchers propose ‘toolbox’ for verifying ethics claims”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Leading AI researchers propose ‘toolbox’ for verifying ethics claims,2020-04-20,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['toolbox', 'claims', 'data', 'team', 'trust', 'researchers', 'safety', 'learning', 'leading', 'ethics', 'bounties', 'expo', 'work', 'ai', 'verifying', 'propose']","Researchers from OpenAI, Google Brain, Intel, and 28 other leading organisations have published a paper which proposes a ‘toolbox’ for verifying AI ethics claims.
“AI systems have been developed in ways that are inconsistent with the stated values of those developing them,” the researchers wrote.
Verification from parties outside an organisation itself will be key to instil trust in that company’s AI developments.
“Standards setting bodies should work with academia and industry to develop audit trail requirements for safety-critical applications of AI systems.”The final suggestion for software-oriented methods of verifying AI ethics claims is the use of privacy-preserving machine learning (PPML).
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
6,https://artificialintelligence-news.com/2021/01/11/police-use-clearview-ai-facial-recognition-increased-26-capitol-raid/,"

Police use of Clearview AI’s facial recognition increased 26% after Capitol raid




 






By Ryan Daws |
        January 11, 2021                    | TechForge Media

                            Categories:
                                    Face Recognition,
                                    Law Enforcement,
                                    Privacy,
                                    Smart Cities,
                                    Society,
                                    Surveillance,
                                    USA,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Clearview AI reports that police use of the company’s highly-controversial facial recognition system jumped 26 percent following the raid on the Capitol.
The facial recognition system relies on scraping the data of people from across the web without their explicit consent, a practice which has naturally raised some eyebrows—including the ACLU’s which called it a “nightmare scenario” for privacy.
Around three billion images are said to have been scraped for Clearview AI’s system.
“Common law has never recognised a right to privacy for your face,” Clearview AI lawyer Tor Ekeland once argued.
Whether you call them protestors or domestic terrorists, the Trump supporters who raided the US Capitol Building last week – incited by the president to halt democracy and overturn the votes of millions of Americans – committed clear criminal offences that were bipartisanly condemned.
In comments to New York Times, Clearview AI CEO Hoan Ton-That claimed the company’s witnesses “a 26 percent increase of searches over our usual weekday search volume” on January 7th, following the riots.
Given the number of individuals involved, law enforcement has a gargantuan task to identify and locate the people that went far beyond exercising their right to peaceful protest and invaded a federal building, caused huge amounts of damage, and threatened elected representatives and staff.
The FBI has issued public appeals, but it’s little surprise that law enforcement is turning to automated means—regardless of the controversy. According to Clearview AI, approximately 2,400 agencies across the US use the company’s facial recognition technology.
Last year, the UK and Australia launched a joint probe into Clearview AI’s practices.
“The Office of the Australian Information Commissioner (OAIC) and the UK’s Information Commissioner’s Office (ICO) have opened a joint investigation into the personal information handling practices of Clearview Inc., focusing on the company’s use of ‘scraped’ data and biometrics of individuals,” the ICO wrote in a statement.
A similar probe was also launched by the EU’s privacy watchdog. The European Data Protection Board ruled that any use of the service by law enforcement in Europe would “likely not be consistent with the EU data protection regime” and that it “has doubts as to whether any Union or Member State law provides a legal basis for using a service such as the one offered by Clearview AI.”
Clearview AI has already been forced to suspend operations in Canada after the federal Office of the Privacy Commissioner of Canada opened an investigation into the company.
While Clearview AI’s facial recognition tech continues to have widespread use in the US, some police departments have taken the independent decision to ban officers from using such systems due to the well-documented inaccuracies which particularly affect minority communities.
(Photo by Andy Feliciotti on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: capitol raid, clearview ai, facial recognition, Featured, government, law enforcement, police, protest, us capitol






View Comments


Leave a comment




            One comment on “Police use of Clearview AI’s facial recognition increased 26% after Capitol raid”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Police use of Clearview AI’s facial recognition increased 26% after Capitol raid,2021-01-11,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['26', 'capitol', 'ais', 'recognition', 'data', 'clearview', 'raid', 'privacy', 'expo', 'companys', 'ai', 'tech', 'increased', 'law', 'facial']","Clearview AI reports that police use of the company’s highly-controversial facial recognition system jumped 26 percent following the raid on the Capitol.
“Common law has never recognised a right to privacy for your face,” Clearview AI lawyer Tor Ekeland once argued.
According to Clearview AI, approximately 2,400 agencies across the US use the company’s facial recognition technology.
While Clearview AI’s facial recognition tech continues to have widespread use in the US, some police departments have taken the independent decision to ban officers from using such systems due to the well-documented inaccuracies which particularly affect minority communities.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
7,https://artificialintelligence-news.com/resources/2020/dec/09/applause-webinar/,"



 


FREE ON-DEMAND WEBINAR: The AI & Automation Revolution; Humans & AI Working Together






                Published By:     





Join our industry thought leaders in this live panel webinar, as they delve into the world of AI and the Automation Revolution. In this session you will:
Discover the latest innovations for AI and automation.Understand how humans and machines enable one another.Learn how to adopt and utilise AI for your business and learn from industry use-cases.A look at the future of the AI enabled workforce.
The industry experts speaking on this innovative topic include:
Ana Rollan, Former Fellow, Artificial Intelligence and Machine Learning, World Economic Forum (Moderator)Jonathan Zaleski, Sr. Director of Engineering, ApplauseAndrei Lopatenko, VP Engineering, Head of Search and Conversational AI, Zillow GroupDan Wulin, Head of Data Science & Machine Learning, WayfairOlga Patel, Principal Technical Architect, Emerging Technologies, The Walt Disney Company
TO WATCH THIS WEBINAR ON-DEMAND, PLEASE COMPLETE THE FORM TO THE RIGHT




                            Submit details here to view
                        


First Name*Last Name*Work Email*

Company Name*Job Title*Industry*IndustryAdvertising/MarketingAerospaceAgricultureAutomotiveBiotechComputers and TechConstructionCorporate ServicesEducationFinanceGovernmentHealthcareInsuranceLegalManufacturingMediaNon-ProfitReal EstateRetailTelecomsTransport/LogisticsTravel/HospitalityUtilitiesOtherCompany Size*Company Size1-249250-499500-9991000-4,9995000+Country*CountryAfghanistanÅland IslandsAlbaniaAlgeriaAmerican SamoaAndorraAngolaAnguillaAntarcticaAntigua and BarbudaArgentinaArmeniaArubaAustraliaAustriaAzerbaijanBahamasBahrainBangladeshBarbadosBelarusBelgiumBelizeBeninBermudaBhutanBoliviaBonaire, Sint Eustatius and SabaBosnia and HerzegovinaBotswanaBouvet IslandBrazilBritish Indian Ocean TerritoryBrunei DarussalamBulgariaBurkina FasoBurundiCambodiaCameroonCanadaCape VerdeCayman IslandsCentral African RepublicChadChileChinaChristmas IslandCocos IslandsColombiaComorosCongo, Democratic Republic of theCongo, Republic of theCook IslandsCosta RicaCôte d'IvoireCroatiaCubaCuraçaoCyprusCzech RepublicDenmarkDjiboutiDominicaDominican RepublicEcuadorEgyptEl SalvadorEquatorial GuineaEritreaEstoniaEswatini (Swaziland)EthiopiaFalkland IslandsFaroe IslandsFijiFinlandFranceFrench GuianaFrench PolynesiaFrench Southern TerritoriesGabonGambiaGeorgiaGermanyGhanaGibraltarGreeceGreenlandGrenadaGuadeloupeGuamGuatemalaGuernseyGuineaGuinea-BissauGuyanaHaitiHeard and McDonald IslandsHoly SeeHondurasHong KongHungaryIcelandIndiaIndonesiaIranIraqIrelandIsle of ManIsraelItalyJamaicaJapanJerseyJordanKazakhstanKenyaKiribatiKuwaitKyrgyzstanLao People's Democratic RepublicLatviaLebanonLesothoLiberiaLibyaLiechtensteinLithuaniaLuxembourgMacauMacedoniaMadagascarMalawiMalaysiaMaldivesMaliMaltaMarshall IslandsMartiniqueMauritaniaMauritiusMayotteMexicoMicronesiaMoldovaMonacoMongoliaMontenegroMontserratMoroccoMozambiqueMyanmarNamibiaNauruNepalNetherlandsNew CaledoniaNew ZealandNicaraguaNigerNigeriaNiueNorfolk IslandNorth KoreaNorthern Mariana IslandsNorwayOmanPakistanPalauPalestine, State ofPanamaPapua New GuineaParaguayPeruPhilippinesPitcairnPolandPortugalPuerto RicoQatarRéunionRomaniaRussiaRwandaSaint BarthélemySaint HelenaSaint Kitts and NevisSaint LuciaSaint MartinSaint Pierre and MiquelonSaint Vincent and the GrenadinesSamoaSan MarinoSao Tome and PrincipeSaudi ArabiaSenegalSerbiaSeychellesSierra LeoneSingaporeSint MaartenSlovakiaSloveniaSolomon IslandsSomaliaSouth AfricaSouth GeorgiaSouth KoreaSouth SudanSpainSri LankaSudanSurinameSvalbard and Jan Mayen IslandsSwedenSwitzerlandSyriaTaiwanTajikistanTanzaniaThailandTimor-LesteTogoTokelauTongaTrinidad and TobagoTunisiaTurkeyTurkmenistanTurks and Caicos IslandsTuvaluUgandaUkraineUnited Arab EmiratesUnited KingdomUnited StatesUruguayUS Minor Outlying IslandsUzbekistanVanuatuVenezuelaVietnamVirgin Islands, BritishVirgin Islands, U.S.Wallis and FutunaWestern SaharaYemenZambiaZimbabweI would like to subscribe to receive communications from AI News about industry trends, news, upcoming events and digital marketing services. I understand that I can unsubscribe at any time.*

Yes


No
Consent* I agree to the privacy policy.View privacy policyCAPTCHA

 











                        Or login to your account
                    

Login to download this resource


Username or Email:



Password:











",FREE ON-DEMAND WEBINAR: The AI & Automation Revolution; Humans & AI Working Together,2020-12-09,[],"['head', 'webinar', 'humans', 'free', 'learning', 'engineering', 'world', 'ai', 'revolution', 'learn', 'machine', 'industry', 'automation', 'ondemand', 'working']","Join our industry thought leaders in this live panel webinar, as they delve into the world of AI and the Automation Revolution.
In this session you will:Discover the latest innovations for AI and automation.
Understand how humans and machines enable one another.
Learn how to adopt and utilise AI for your business and learn from industry use-cases.
A look at the future of the AI enabled workforce.",AInews
8,https://artificialintelligence-news.com/2020/05/26/dorian-selz-ceo-squirro-why-the-ai-revolution-will-take-time/,"

Dorian Selz, CEO, Squirro: Why the AI revolution will take time




 



 

By James Bourne |
        May 26, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Adoption,
                                    Big Data,
                                    Connected Cars,
                                    Machine Learning,
                                    Research,
                                    Retail,
                                    TECHEX,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




Imagine you are riding in a fully driverless car – with no human controls – down a narrow countryside road, with no lights or road markings. Upon emerging from a twisting bend a flock of sheep confront you. What happens next?
These types of situations are what programs such as the MIT-developed Moral Machine have been looking to unlock. The site has for the past four years canvassed public opinion by presenting a series of ethical dilemmas: should an autonomous car protect its passenger for instance, or a pedestrian, in a particular scenario?
The wider point, however, is that such autonomy – or to put it more romantically, machines thinking for themselves – requires vast amounts of data. Data which, to date, has not been calibrated. Would you entrust your safety to your vehicle?
This is an analogy which Dorian Selz, co-founder and CEO of Squirro, uses to explain why the great AI revolution might take longer than many think. “I think we’re going to see massive advances in the underlying technology over the next 10 years – we are probably going to see some level of breakthrough to have some low level of intelligence in these machines,” Selz tells AI News. “I can imagine that – but it will take time until it is really adopted widely.”
For the CEO of an AI platform provider, this may be an interesting position to take – something which Selz accepts. Yet Squirro’s business case may give an indication. The company’s modus operandi is  taking organisations’ unstructured data sets – everything from emails, to market reports, to PowerPoint presentations and Word documents – and utilising what it calls ‘augmented intelligence’ to surface greater insights.
This collaborative process not only leans on the human factor, but takes time to appreciate. “Most companies have ratios of 90% to 99% of all data they generate or acquire never being used beyond the first use,” explains Salz. “That is the equivalent of buying a car, driving it from the dealership back to your garage, and then throwing away the key and never driving that car again.
“If you say data is the new oil, at the same time companies are not making use of that data,” he adds. “What works wonderfully well for numbers doesn’t work at all for text in an Excel.”
Selz knows of which he speaks with regard to how companies use and stockpile data. Squirro is the fourth company he has co-built, with a previous success being Swiss homegrown search engine local.ch. With Squirro, which promises benefits from customer and service insights to cognitive search, the goal is for this data to complement business processes and working methods.
Take an accounts department, for example, whereby the data can be able to show not just whether a client has paid or not, but any relevant news or market research which could impact their ability to pay. In the supply chain, issues can be identified several levels down the chain which may impact the direct supplier.
“If you look at any company today, small or big, their IT landscape is effectively a combination of boxed applicastions – a supply chain system at the back of the company, an ERP system in the middle, some level of CRM at the front and support systems in the background,” explains Selz. “The bigger the company, the more of that stuff you have, but it’s still essentially a landscape of boxed IT applications.
“The future we see is a future where you’re going to see a machine learning-driven layer that weaves all these different data silos together,” Selz adds. “We foresee a future where these types of intimately weaved informational fabrics become the new norm in any enterprise.
“It doesn’t replace you – I don’t believe in that at all. But it will support you in decision making.”
One customer which exemplifies this ‘weaving’ of data is Brookson, a UK-based local accountancy firm for contractors. The company had already been using Squirro to classify data coming in to expedite the administrative and call centre process, but the next step was particularly noteworthy: using the technology to assess future customer relationships. Based on a roadmap created from previous customers, good, bad or indifferent, every new interaction can be assessed and forecast using pre-defined journeys.
“I love to retell that story, because it shows that AI per se is not just for the big boys,” says Selz. “As a nimble, agile, SME enterprise, you can use this type of technology to really fundamentally put yourself in a better position in the marketplace.”
This is an interesting point; plenty of research, not least a study from VC company Work-Bench in 2018, has argued that bigger companies are at a natural advantage with AI because they can hoover up the best talent. But as AI expertise does not automatically equal big businesses, big effects are not the results of such technology yet, Selz argues – going back to his original theme around transformation.
“Everybody talks about these big intelligence machines that do these fantastic things for companies and automate,” he explains. “Transform entire industries? I don’t really believe that.
“If you look at many machine learning techniques in use today, from the more simplistic ones like SVM, Bayesian algorithms, all the way to more sophisticated deep learning models, at the end, they’re not really intelligent,” Selz adds. “It’s pattern matching at the power of whatever computer you have.”
Selz notes that ‘none of the lovely AI engines had foreseen the coronavirus’. Given the reactive, rather than proactive, steps taken by governments worldwide, it wasn’t just the machines who were flat-footed. Looking at various stories assessing AI’s impact on Covid-19, many argue its role is to assess what will happen next – rather, assessing the damage once the horse has bolted – with a Singapore research unit predicting last month, with extreme caution, that the pandemic will end globally by December.
This informs Selz’s overall theory that we are nowhere near ready for primetime in B2B just yet. “It’s outright dangerous to think such an AI engine can suddenly transform your business if it is so limited in its capabilities and capacity,” he says.
“A customer relationship is more than what you have in your data sets,” Selz adds. “Even in retail volume segments, no one has a fully digitised customer relationship yet. If you don’t have it fully digitised, every aspect of it, why would you entrust some anonymous algorithm call method to evaluate and effectively decide on the future of that relationship?
“No sane person would do that.”
Editor’s note: You can find out more about augmented intelligence at AIM, a virtual event hosted by Squirro on June 23-25.

Interested in hearing industry leaders discuss subjects like this and their use cases? Attend the co-located AI & Big Data Expo events with upcoming shows in Silicon Valley, London, and Amsterdam to learn more. Co-located with the IoT Tech Expo, Blockchain Expo, and Cyber Security & Cloud Expo.
 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






","Dorian Selz, CEO, Squirro: Why the AI revolution will take time",2020-05-26,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['data', 'technology', 'customer', 'selz', 'future', 'ceo', 'big', 'dorian', 'revolution', 'ai', 'companies', 'company', 'squirro']","This is an analogy which Dorian Selz, co-founder and CEO of Squirro, uses to explain why the great AI revolution might take longer than many think.
“I love to retell that story, because it shows that AI per se is not just for the big boys,” says Selz.
But as AI expertise does not automatically equal big businesses, big effects are not the results of such technology yet, Selz argues – going back to his original theme around transformation.
“A customer relationship is more than what you have in your data sets,” Selz adds.
Attend the co-located AI & Big Data Expo events with upcoming shows in Silicon Valley, London, and Amsterdam to learn more.",AInews
9,https://artificialintelligence-news.com/news/,"



Researchers find systems to counter deepfakes can be deceived










Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:
""Our work shows that attacks on deepfake detectors could be a real-world threat.More alarmingly, we demonstrate that it's... 






        10 February 2021                    |
            Deepfakes





",AI News,,[],"['diego', 'systems', 'student', 'researchers', 'wacv', 'work', 'threatmore', 'ai', 'university', 'uc', 'san']","Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:""Our work shows that attacks on deepfake detectors could be a real-world threat.
More alarmingly, we demonstrate that it's...",AInews
10,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
11,https://artificialintelligence-news.com/2020/06/11/eu-privacy-watchdog-aim-clearview-ai-facial-recognition/,"

The EU’s privacy watchdog takes aim at Clearview AI’s facial recognition




 






By Ryan Daws |
        June 11, 2020                    | TechForge Media

                            Categories:
                                    Europe,
                                    Face Recognition,
                                    Government,
                                    Law Enforcement,
                                    Policy,
                                    Privacy,
                                    Regulation,
                                    Smart Cities,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The European Data Protection Board (EDPB) believes use of Clearview AI’s controversial facial recognition system would be illegal.
Clearview AI’s facial recognition system is used by over 2,200 law enforcement agencies around the world and even commercial businesses like Best Buy and Macy’s, according to a recent leak.
The EDPB has now ruled that any use of the service by law enforcement in Europe would “likely not be consistent with the EU data protection regime.”
Furthermore, the watchdog “has doubts as to whether any Union or Member State law provides a legal basis for using a service such as the one offered by Clearview AI.”
Clearview AI scrapes billions of photos from across the internet for its powerful system, a practice which has come under fire by privacy campaigners. “Common law has never recognised a right to privacy for your face,” Clearview AI lawyer Tor Ekeland argued recently.
The American Civil Liberties Union (ACLU) launched a lawsuit against Clearview AI last month after calling it a “nightmare scenario” for privacy.
“Companies like Clearview will end privacy as we know it, and must be stopped,” said Nathan Freed Wessler, senior staff attorney with the ACLU’s Speech, Privacy, and Technology Project.
Aside from the company’s practices, concerns have been raised about Clearview AI’s extensive ties with the far-right. Ekeland himself has gained notoriety as “The Troll’s Lawyer” for defending clients such as neo-Nazi troll Andrew Auernheimer.
Backlash over Clearview AI forced the company to announce it will no longer offer its services to private companies. The EU’s ruling will limit Clearview AI’s potential customers even further.
Concerns have grown in recent weeks about facial recognition services amid protests over racial discrimination. Facial recognition services have been repeatedly found to falsely flag minorities; stoking fears they’ll lead to automated racial profiling.
IBM and Amazon have both announced this week they’ll no longer provide facial recognition services to law enforcement and have called on Congress to increase regulation to help ensure future deployments meet ethical standards.
(Photo by Christian Lue on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, clearview ai, data, edpb, eu, european, face recognition, facial recognition, Featured, law enforcement, police, policing, privacy, surveillance






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",The EU’s privacy watchdog takes aim at Clearview AI’s facial recognition,2020-06-11,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['ais', 'aim', 'recognition', 'clearview', 'services', 'privacy', 'expo', 'ai', 'watchdog', 'system', 'law', 'takes', 'eus', 'facial']","The European Data Protection Board (EDPB) believes use of Clearview AI’s controversial facial recognition system would be illegal.
Clearview AI’s facial recognition system is used by over 2,200 law enforcement agencies around the world and even commercial businesses like Best Buy and Macy’s, according to a recent leak.
Aside from the company’s practices, concerns have been raised about Clearview AI’s extensive ties with the far-right.
Concerns have grown in recent weeks about facial recognition services amid protests over racial discrimination.
Facial recognition services have been repeatedly found to falsely flag minorities; stoking fears they’ll lead to automated racial profiling.",AInews
12,https://artificialintelligence-news.com/2020/05/26/beware-the-ai-winter-but-can-covid-19-alter-this-process/,"

Beware the AI winter – but can Covid-19 alter this process?




 



 

By James Bourne |
        May 26, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Deep Learning,
                                    Healthcare,
                                    Machine Learning,
                                    TECHEX,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




We have had a blockchain winter as the hype around the technology moves towards a reality – and the same will happen with artificial intelligence (AI).
That’s according to Dr Karol Przystalski, CTO at IT consulting and software development provider Codete. Przystalski founded Codete having had a significant research background in AI, with previous employers including Sabre and IBM and a PhD exploring skin cancer pattern recognition using neural networks.
Yet what effect will the Covid-19 pandemic have on this change? Speaking with AI News, Przystalski argues – much like Dorian Selz, CEO of Squirro, in a piece published earlier this week – that while AI isn’t quite there to predict or solve the current pandemic, the future can look bright.
—
AI News: Hi Karol. Tell us about your career to date and your current role and responsibilities as the CTO of Codete?
Dr Karol Przystalski: The experience from the previous companies I worked at and the AI background that I had from my PhD work allowed me to get Codete off the ground. At the beginning, not every potential client could see the advantages of machine learning, but it has changed in the last couple of years. We’ve started to implement more and more machine learning-based solutions.
Currently, my responsibilities as the CTO are not focused solely on development, as we have already grown to 160 engineers. Even though I still devote some of my attention to research and development, most of my work right now is centred on mentoring and training in the areas of artificial intelligence and big data.
AI: Tell us about the big data and data science services Codete provides and how your company aims to differ from the competitors?
KP: We offer a number of services related to big data and data science: consulting, auditing, training, and software development support. Based on our extensive experience in machine learning solutions, we provide advice to our clients. We audit already implemented solutions, as well as whole processes of product development. We also have a workshop for managers on how not to fail with a machine learning project.
All the materials are based on our own case studies. As a technological partner, we focus on the quality of the applications that we deliver, and we always aim at full transparency in relationships with our clients.
AI: How difficult is it, in your opinion, for companies to gather data science expertise? Is there a shortage of skills and a gap in this area?
KP: In the past, to become a data scientist you had to have a mathematical background or, even better, a PhD in this field. We now know it’s not that hard to implement machine learning solutions, and almost every software developer can become a data scientist.
There are plenty of workshops, lectures, and many other materials dedicated to software developers who want to understand machine learning methods. Usually, the journey starts with a few proof of concepts and, in the next build, production solutions. It usually takes a couple of months at the very minimum to become a solid junior level data scientist, even for experienced software engineers. Codete is well-known in the machine learning communities at several universities, and that’s why we can easily extend our team with experienced ML engineers.
AI: What example can you provide of a client Codete has worked with throughout their journey, from research and development to choosing a solution for implementation?
KP: We don’t implement all of the projects that clients bring to us. In the first stage, we distinguish between projects that are buzzword-driven and the real-world ones.
One time, a client came to us with an idea for an NLP project for their business. After some research, it turned out that ML was not the best choice for the project – we recommended a simpler, cheaper solution that was more suitable in their case.
We are transparent with our clients, even if it takes providing them with constructive criticism on the solution they want to build. Most AI projects start with a PoC, and if it works well, the project goes through the next stages to a full production solution. In our AI projects, we follow the ‘fail fast’ approach to prevent our clients from potential over-investing.
AI: Which industries do you think will have the most potential for machine learning and AI and why?
KP: In the Covid-19 times, for sure the health, med, and pharma industries will grow and use AI more often. We will see more use cases applied in telemedicine and medical diagnosis. For sure, the pharma industry and the development of drugs might be supported by AI. We can see how fast the vaccine for Covid-19 is being developed. In the future, the process of finding a valid vaccine can be supported by AI.
But it is not only health-related industries which will use AI more often. I think that almost every industry will invest more in digitalisation, like process automation where ML can be applied. First, we will see an increasing interest in AI in the industries that were not affected by the virus so much, but in the long run even the hospitality and travel industry, as well as many governments, will introduce AI-based solutions to prevent future lockdown.
AI: What is the greatest benefit of AI in business in your opinion – and what is the biggest fear?
KP: There are plenty of ways machine learning can be applied in many industries. There is a machine learning and artificial intelligence hype going on now, and many managers become aware of the benefits that machine learning can bring to their companies. On the other hand, many can take AI for a solution for almost everything – but that’s how buzzword-driven projects are born, not real-world use cases.
This hype may end similarly to other tech hypes that we have witnessed before, when a buzzword was popular, but eventually only a limited number of companies applied the technology. Blockchain is a good example – many companies have tried using it, for almost everything, and in many cases the technology didn’t really prove useful, sometimes even causing new problems.
Blockchain is now being used with success in several industries. Just the same, we can have an ‘AI winter’ again, if we don’t distinguish between the hype and the true value behind an AI solution.
Photo by Aaron Burden on Unsplash

Interested in hearing industry leaders discuss subjects like this and their use cases? Attend the co-located AI & Big Data Expo events with upcoming shows in Silicon Valley, London, and Amsterdam to learn more. Co-located with the IoT Tech Expo, Blockchain Expo, and Cyber Security & Cloud Expo.
 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",but can Covid-19 alter this process?,2020-05-26,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['process', 'data', 'industries', 'solution', 'alter', 'learning', 'solutions', 'ai', 'codete', 'software', 'machine', 'covid19', 'development']","KP: We offer a number of services related to big data and data science: consulting, auditing, training, and software development support.
Based on our extensive experience in machine learning solutions, we provide advice to our clients.
We also have a workshop for managers on how not to fail with a machine learning project.
There is a machine learning and artificial intelligence hype going on now, and many managers become aware of the benefits that machine learning can bring to their companies.
Just the same, we can have an ‘AI winter’ again, if we don’t distinguish between the hype and the true value behind an AI solution.",AInews
13,https://artificialintelligence-news.com/2020/08/27/global-spending-ai-110-billion-2024/,"

Global spending on AI ‘expected to double in four years’, says IDC




 



 

By James Bourne |
        August 27, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Adoption,
                                    Enterprise,
                                    Research,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




Worldwide spending on artificial intelligence (AI) is forecast to double over the coming for years to hit $110 billion by 2024, according to new data from IDC.
The figure, which comes from the analyst firm’s latest Worldwide Artificial Intelligence Spending Guide, calculates a CAGR of 20.1% as adopting AI becomes a ‘must’ in the enterprise.
In particular, companies will utilise AI to deliver a better customer experience, as well as help employees to become better at their jobs. Automated customer service agents, sales process recommendation and automation, as well as automated threat intelligence and prevention, are the primary use cases outlined by IDC.
Retail and banking are the two industries most likely to splurge in the coming years. The former, unsurprisingly, will focus more on customer experience, while the latter will invest on fraud analysis and investigation, as well as program advisors and recommendation systems.
Other industries have hit something of a proverbial wall, primarily as a result of Covid-19. Transportation, as well as the services industry – including leisure and hospitality – have already struggled with the pandemic. Naturally, IDC argued, AI investments will be on the back burner here in 2020. Yet the pandemic has seen some innovation; the research specifically noted hospitals who were using AI to speed up Covid-19 diagnosis and testing.
“Companies will adopt AI – not just because they can, but because they must,” said Ritu Jyoti, program vice president for artificial intelligence at IDC. “AI is the technology that will help businesses to be agile, innovate, and scale. The companies that become ‘AI powered’ will have the ability to synthesise information, the capacity to learn, and the capability to deliver insights at scale.”
In other words, leading organisations will be able to use AI to convert data into information and insights, understand those relationships and apply those insights to business problems, and then support decisions and bring through automation.
Sounds simple when it’s put like that.
Photo by Fabian Blank on Unsplash

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 






View Comments


Leave a comment




            One comment on “Global spending on AI ‘expected to double in four years’, says IDC”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






","Global spending on AI ‘expected to double in four years’, says IDC",2020-08-27,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['data', 'insights', 'customer', 'global', 'james', 'expo', 'expected', 'idc', 'ai', 'world', 'artificial', 'intelligence', 'double', 'spending']","Worldwide spending on artificial intelligence (AI) is forecast to double over the coming for years to hit $110 billion by 2024, according to new data from IDC.
The figure, which comes from the analyst firm’s latest Worldwide Artificial Intelligence Spending Guide, calculates a CAGR of 20.1% as adopting AI becomes a ‘must’ in the enterprise.
Naturally, IDC argued, AI investments will be on the back burner here in 2020.
“Companies will adopt AI – not just because they can, but because they must,” said Ritu Jyoti, program vice president for artificial intelligence at IDC.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
14,https://artificialintelligence-news.com/2020/12/08/state-of-european-tech-investment-deep-tech-ai-drops-13-percent/,"

State of European Tech: Investment in ‘deep tech’ like AI drops 13%




 






By Ryan Daws |
        December 8, 2020                    | TechForge Media

                            Categories:
                                    Europe,
                                    Funding,
                                    Research,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The latest State of European Tech report highlights that investment in “deep tech” like AI has dropped 13 percent this year.
Data from Dealroom was used for the State of European Tech report. Dealroom defines deep tech as 16 fields: Artificial Intelligence, Machine Learning, Big Data, Augmented Reality, Virtual Reality, Drones, Autonomous Driving, Blockchain, Nanotech, Robotics, Internet of Things, 3D Technology, Computer Vision, Connected Devices, Sensors Technology, and Recognition Technology (NLP, image, video, text, speech recognition).
In 2019, there was $10.2 billion capital invested in European deep tech. In 2020, that dropped to $8.9 billion:

I think it’s fair to say that 2020 has been a tough year for most people and businesses. Economic uncertainty – not just from COVID-19 but also trade wars, Brexit, and a rather tumultuous US presidential election – has naturally led to fewer investments and people tightening their wallets.
For just one example, innovative satellite firm OneWeb was forced to declare bankruptcy earlier this year after crucial funding it was close to securing was pulled during the peak of the pandemic. Fortunately, OneWeb was saved following an acquisition by the UK government and Bharti Global—but not all companies have been so fortunate.
Many European businesses will now be watching the close-to-collapse Brexit talks with hope that a deal can yet be salvaged to limit the shock to supply lines, prevent disruption to Europe’s leading financial hub, and help to build a friendly relationship going forward with a continued exchange of ideas and talent rather than years of bitterness and resentment.
The report shows the UK has retained its significant lead in European tech investment and startups this year:

Despite the uncertainties, the UK looks unlikely to lose its position as the hub of European technology anytime soon.
Investments in European tech as a whole should bounce back – along with the rest of the world – in 2021, with promising COVID-19 vaccines rolling out and hopefully some calm in geopolitics.
94 percent of survey respondents for the report stated they have either increased or maintained their appetite to invest in the European venture asset class. Furthermore, a record number of US institutions have participated in more than one investment round in Europe this year—up 36% since 2016.
You can find a full copy of the State of European Tech report here.
(Photo by Mayank Dhanawade on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, deep tech, eu, europe, european, Featured, funding, investment, report, research, Startups, state of european tech, study, Tech, technology, uk






View Comments


Leave a comment




            One comment on “State of European Tech: Investment in ‘deep tech’ like AI drops 13%”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",State of European Tech: Investment in ‘deep tech’ like AI drops 13%,2020-12-08,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['european', '13', 'technology', 'uk', 'expo', 'tech', 'ai', 'world', 'drops', 'deep', 'state', 'report', 'investment']","The latest State of European Tech report highlights that investment in “deep tech” like AI has dropped 13 percent this year.
Data from Dealroom was used for the State of European Tech report.
In 2019, there was $10.2 billion capital invested in European deep tech.
You can find a full copy of the State of European Tech report here.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
15,https://artificialintelligence-news.com/2020/02/19/elon-musk-stringent-ai-regulation-tesla/,"

Elon Musk wants more stringent AI regulation, including for Tesla




 






By Ryan Daws |
        February 19, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Government,
                                    Machine Learning,
                                    Policy,
                                    Regulation,
                                    Research,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Elon Musk has once again called for more stringent regulations around the development of AI technologies.
The founder of Tesla and SpaceX has been one of the most vocal prominent figures in expressing concerns about AI – going as far as to call it humanity’s “biggest existential threat” if left unchecked.
Of course, given the nature of the companies Musk has founded, he is also well aware of AI’s potential.
Back in 2015, Musk co-founded OpenAI – an organisation founded with the aim of pursuing and promoting ethical AI development. Musk ended up leaving OpenAI in February last year over disagreements with the company’s work.
Earlier this week, Musk said that OpenAI should be more transparent and specifically said his confidence is “not high” in former Google engineer Dario Amodei when it comes to safety.
Responding to a piece by MIT Technology Review about OpenAI, Musk tweeted: “All orgs developing advanced AI should be regulated, including Tesla.”
In response to a further question of whether such regulations should be via individual governments or global institutions like the UN, Musk said he believes both.
Musk’s tweet generated some feedback from other prominent industry figures, including legendary Id Software founder John Carmack who recently stepped back from video game development to focus on independent AI research.
Carmack asked Musk: “How would you imagine that working for someone like me? Cloud vendors refuse to spawn larger clusters without a government approval? I would not be supportive.”
Coder Pranay Pathole shared a similar scepticism to Musk’s call as Carmack, saying: “Large companies ask for regulations acting all virtuous. What they are really doing is creating barriers for entry for new competition because only they can afford to comply with the new regulations.”
The debate over the extent of AI regulations and how they should be implemented will likely go on for some time – we can only hope to get them right before a disaster occurs. If you want to help Musk in building AI, he’s hosting a “super fun” hackathon at his place.

 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, elon musk, Featured, openai, policy, regulation, Tesla






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






","Elon Musk wants more stringent AI regulation, including for Tesla",2020-02-19,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['prominent', 'musk', 'including', 'elon', 'regulation', 'expo', 'ai', 'tech', 'stringent', 'tesla', 'openai', 'regulations', 'industry', 'development', 'wants']","Elon Musk has once again called for more stringent regulations around the development of AI technologies.
Back in 2015, Musk co-founded OpenAI – an organisation founded with the aim of pursuing and promoting ethical AI development.
Musk’s tweet generated some feedback from other prominent industry figures, including legendary Id Software founder John Carmack who recently stepped back from video game development to focus on independent AI research.
If you want to help Musk in building AI, he’s hosting a “super fun” hackathon at his place.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
16,https://artificialintelligence-news.com/2020/08/12/microsoft-uk-ai-skills-risk-falling-behind/,"

Microsoft: The UK must increase its AI skills, or risk falling behind




 






By Ryan Daws |
        August 12, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Developers,
                                    Education,
                                    Enterprise,
                                    Europe,
                                    Machine Learning,
                                    Microsoft,
                                    Research,
                                    Society,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A report from Microsoft warns that the UK faces an AI skills gap which may harm its global competitiveness.
The research, titled AI Skills in the UK, shines a spotlight on some concerning issues.
For its UK report, Microsoft used data from a global AI skills study featuring more than 12,000 people in 20 countries to see how the UK is doing in comparison to the rest of the world.
Most notably, compared to the rest of the world, the UK is seeing a higher failure rate for AI projects. 29 percent of AI ventures launched by UK businesses have generated no commercial value compared to the 19 percent average elsewhere in the world.
35 percent of British business leaders foresee an AI skills gap within two years, while 28 percent believe there already is one (above the global average of 24%).
However, it seems UK businesses aren’t helping to prepare employees with the skills they need. Just 17 percent of British employees have been part of AI reskilling efforts (compared to the global figure of 38 percent.)
Agata Nowakowska, AVP EMEA at Skillsoft, said:
“UK employers will have to address the growing digital skills gap within the workforce to ensure their business is able to fully leverage every digital transformation investment that’s made. With technologies like AI and cloud becoming as commonplace as word processing or email in the workplace, firms will need to ensure employees can use such tools and aren’t apprehensive about using them.Organisations will need to think holistically about managing reskilling, upskilling and job transitioning. As the war for talent intensifies, employee development and talent pooling will become increasingly vital to building a modern workforce that’s adaptable and flexible. Addressing and easing workplace role transitions will require new training models and approaches that include on-the-job training and opportunities that support and signpost workers to opportunities to upgrade their skills.” 
Currently, a mere 32 percent of British employees feel their workplace is doing enough to prepare them for an AI-enabled future (compared to the global average of 42%)
“The most successful organisations will be the ones that transform both technically and culturally, equipping their people with the skills and knowledge to become the best competitive asset they have,” comments Simon Lambert, Chief Learning Officer for Microsoft UK.
“Human ingenuity is what will make the difference – AI technology alone will not be enough.”
AI brain drain
It’s well-documented that the UK suffers from a “brain drain” problem. The country’s renowned universities – like Oxford and Cambridge – produce globally desirable AI talent, but they’re often swooped up by Silicon Valley giants who are willing to pay much higher salaries than many British firms.
In one example, a senior professor from Imperial College London couldn’t understand why one of her students was not turning up to any classes. Most people wouldn’t pay £9,250 per year in tuition fees and not turn up. The professor called her student to find out why he’d completed three years but wasn’t turning up for his final year. She found that he was offered a six-figure salary at Apple. 
This problem also applies to teachers who are needed to pass their knowledge onto the future generations. Many are lured away from academia to work on groundbreaking projects with almost endless resources, less administrative duties, and be paid handsomely for it too.
Some companies, Microsoft included, have taken measures to address the brain drain problem. After all, a lack of AI talent harms the entire industry.
Dr Chris Bishop, Director of Microsoft’s Research Lab in Cambridge, said:
“One thing we’ve seen over the past few years is: because there are so many opportunities for people with skills in machine learning, particularly in industry, we’ve seen a lot of outflux of top academic talent to industry.This concerns us because it’s those top academic professors and researchers who are responsible not just for doing research, but also for nurturing the next generation of talent in this field.”
Since 2018, Microsoft has funded a program for training the next generation of data scientists and machine-learning engineers called the Microsoft Research-Cambridge University Machine Learning Initiative.
Microsoft partners with universities to ensure it doesn’t steal talent, allows employees to continue roles in teaching, funds some related PhD scholarships, sends researchers to co-supervise students in universities, and offers paid internships to work alongside teams at Microsoft on projects.
You can find the full AI Skills in the UK report here.
(Photo by William Warby on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, education, Featured, learning, microsoft, report, research, skills, Society, uk






View Comments


Leave a comment




            One comment on “Microsoft: The UK must increase its AI skills, or risk falling behind”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






","Microsoft: The UK must increase its AI skills, or risk falling behind",2020-08-12,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['british', 'compared', 'uk', 'global', 'skills', 'expo', 'ai', 'employees', 'microsoft', 'talent', 'falling', 'increase', 'risk']","A report from Microsoft warns that the UK faces an AI skills gap which may harm its global competitiveness.
The research, titled AI Skills in the UK, shines a spotlight on some concerning issues.
For its UK report, Microsoft used data from a global AI skills study featuring more than 12,000 people in 20 countries to see how the UK is doing in comparison to the rest of the world.
You can find the full AI Skills in the UK report here.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
17,https://artificialintelligence-news.com/2020/12/24/google-telling-scientists-give-ai-positive-spin/,"

Google is telling its scientists to give AI a ‘positive’ spin




 






By Ryan Daws |
        December 24, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Google,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Google has reportedly been telling its scientists to give AI a “positive” spin in research papers.
Documents obtained by Reuters suggest that, in at least three cases, Google’s researchers were requested to refrain from being critical of AI technology.
A “sensitive topics” review was established by Google earlier this year to catch papers which cast a negative light on AI ahead of their publication.
Google asks its scientists to consult with legal, policy, and public relations teams prior to publishing anything on topics which could be deemed sensitive like sentiment analysis and categorisations of people based on race and/or political affiliation.
The new review means that papers from Google’s expert researchers which raise questions about AI developments may never be published. Reuters says four staff researchers believe Google is interfering with studies into potential technology harms.
Google recently faced scrutiny after firing leading AI ethics researcher Timnit Gebru.
Gebru is considered a pioneer in the field and researched the risks and inequalities found in large language models. She claims to have been fired by Google over an unpublished paper and sending an email critical of the company’s practices.
In an internal email countering Gebru’s claims, Head of Google Research Jeff Dean wrote:
“We’ve approved dozens of papers that Timnit and/or the other Googlers have authored and then published, but as you know, papers often require changes during the internal review process (or are even deemed unsuitable for submission). Unfortunately, this particular paper was only shared with a day’s notice before its deadline — we require two weeks for this sort of review — and then instead of awaiting reviewer feedback, it was approved for submission and submitted.A cross-functional team then reviewed the paper as part of our regular process and the authors were informed that it didn’t meet our bar for publication and were given feedback about why.”
While it’s one word against another, it’s not a great look for Google.
“Advances in technology and the growing complexity of our external environment are increasingly leading to situations where seemingly inoffensive projects raise ethical, reputational, regulatory or legal issues,” Reuters reported one of Google’s documents as saying.
On its public-facing website, Google says that its scientists have “substantial” freedom—but that’s increasingly appearing like it’s not the case.
(Photo by Mitchell Luo on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, ethics, Featured, Google, paper, privacy, report, research, technology, timnit gebru






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google is telling its scientists to give AI a ‘positive’ spin,2020-12-24,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['scientists', 'topics', 'telling', 'googles', 'researchers', 'spin', 'positive', 'expo', 'ai', 'review', 'google', 'papers', 'paper']","Google has reportedly been telling its scientists to give AI a “positive” spin in research papers.
Documents obtained by Reuters suggest that, in at least three cases, Google’s researchers were requested to refrain from being critical of AI technology.
A “sensitive topics” review was established by Google earlier this year to catch papers which cast a negative light on AI ahead of their publication.
The new review means that papers from Google’s expert researchers which raise questions about AI developments may never be published.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
18,https://artificialintelligence-news.com/2020/08/18/ai-gartner-hype-cycle-emerging-technologies/,"

AI dominates Gartner’s latest Hype Cycle for emerging technologies




 






By Ryan Daws |
        August 18, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Machine Learning,
                                    Research,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Gartner’s latest Hype Cycle has a distinct AI flavour, highlighting the technology’s importance over the next decade.
Of the 30 emerging technologies featured in Gartner’s latest Hype Cycle, nine are directly related to artificial intelligence:
Generative adversarial networksAdaptive machine learningComposite AIGenerative AIResponsible AIAI-augmented developmentEmbedded AIExplainable AIAI-augmented design
Most of the AI technologies are currently in the initial “Innovation Trigger” part of the Hype Cycle, where excitement builds the fastest.

Responsible AI, AI-augmented development, embedded AI, and explainable AI, have all now reached the “Peak of Inflated Expectations” and will next move into the dreaded “Trough of Disillusionment” as disappointment sets in over what can realistically be achieved.
Only after the trough, which none of the AI technologies have yet reached, do we head into the areas of the Hype Cycle where adoption occurs with realistic expectations and the productivity rewards are reaped.
Gartner’s Hype Cycle covers the next decade. The current placings of most of the AI technologies on the Hype Cycle indicates that Gartner believes it won’t be until towards the end of the decade we’ll see the most benefits.
Brian Burke, VP of research at Gartner, comments:
“Emerging technologies are disruptive by nature, but the competitive advantage they provide is not yet well known or proven in the market. Most will take more than five years, and some more than 10 years, to reach the Plateau of Productivity.But some technologies on the Hype Cycle will mature in the near term and technology innovation leaders must understand the opportunities for these technologies, particularly those with transformational or high impact.”
Two technologies which Gartner expects to fast-track through the Hype Cycle are health passports and social distancing technologies, due to their necessity amid the COVID-19 pandemic.
You can find the full Gartner report here (paywall)
(Photo by Verena Yunita Yapi on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: adoption, ai, artificial intelligence, emerging technologies, Featured, gartner, hype cycle, machine learning, report, research, technologies, technology






View Comments


Leave a comment




            One comment on “AI dominates Gartner’s latest Hype Cycle for emerging technologies”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI dominates Gartner’s latest Hype Cycle for emerging technologies,2020-08-18,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['gartner', 'technologies', 'hype', 'cycle', 'gartners', 'expo', 'tech', 'latest', 'ai', 'emerging', 'reached', 'productivity', 'trough', 'dominates']","Gartner’s latest Hype Cycle has a distinct AI flavour, highlighting the technology’s importance over the next decade.
Of the 30 emerging technologies featured in Gartner’s latest Hype Cycle, nine are directly related to artificial intelligence:Generative adversarial networksAdaptive machine learningComposite AIGenerative AIResponsible AIAI-augmented developmentEmbedded AIExplainable AIAI-augmented designMost of the AI technologies are currently in the initial “Innovation Trigger” part of the Hype Cycle, where excitement builds the fastest.
Gartner’s Hype Cycle covers the next decade.
The current placings of most of the AI technologies on the Hype Cycle indicates that Gartner believes it won’t be until towards the end of the decade we’ll see the most benefits.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
19,https://artificialintelligence-news.com/2020/03/06/samsung-launches-ai-research-unit-for-semiconductor-demand-reports/,"

Samsung launches AI research unit for semiconductor demand – reports




 



 

By James Bourne |
        March 6, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Samsung,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




Samsung has launched its own AI research unit
under its device solutions division aimed at conducting research and creating AI
technologies designed to enhance the semiconductor manufacturing process.
The division, according
to sources cited by The Korea Herald, is not yet fully operational but will
be led by Shim Eun-soo, a former head of AI software research at the Samsung
Advanced Institute of Technology. Samsung Electronics is now in the process of
scouting for AI researchers with doctorates from universities including the
University of Tokyo and the State University of New York, the report added.
The company’s bets in artificial intelligence
continue. In
November, Samsung announced plans to increase its efforts in AI and 5G to
drive innovation across its business. During an AI forum held at the company’s
R&D Center, Samsung’s head of IT and mobile communications, Koh Dong-jin,
said: “In a hyperconnected society via 5G, AI and Internet of Things, a company
that innovates user experiences will be a global business leader. 5G, AI will
lay the ground for technology innovations for smartphones, wearables, speakers,
Internet of Things, augmented reality and virtual reality, and provide a
turning point for our everyday lives.”
In July,
 Samsung researchers successfully managed to develop an AI that 
generates realistic 3D renders of video scenes. The researchers, in a 
paper detailing the neural network behind AI, explained the inefficient 
process of creating virtual scenes in the modern day. Result of a 3D 
scene created by the AI showed that such a solution could one-day help 
game development, especially video game counterparts of movies that are 
already being filmed.






Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.





 






View Comments


Leave a comment




            One comment on “Samsung launches AI research unit for semiconductor demand – reports”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Samsung launches AI research unit for semiconductor demand – reports,2020-03-06,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['research', 'business', 'virtual', 'semiconductor', 'researchers', 'james', 'launches', 'ai', 'demand', '5g', 'reports', 'university', 'unit', 'samsung', 'video']","Samsung has launched its own AI research unit under its device solutions division aimed at conducting research and creating AI technologies designed to enhance the semiconductor manufacturing process.
The division, according to sources cited by The Korea Herald, is not yet fully operational but will be led by Shim Eun-soo, a former head of AI software research at the Samsung Advanced Institute of Technology.
Samsung Electronics is now in the process of scouting for AI researchers with doctorates from universities including the University of Tokyo and the State University of New York, the report added.
In November, Samsung announced plans to increase its efforts in AI and 5G to drive innovation across its business.
The researchers, in a paper detailing the neural network behind AI, explained the inefficient process of creating virtual scenes in the modern day.",AInews
20,https://artificialintelligence-news.com/2021/02/05/google-leaking-ai-talent-following-ethicist-controversial-firing/,"

Google is leaking AI talent following ethicist’s controversial firing




 






By Ryan Daws |
        February 5, 2021                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Google,
                                    Policy,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Some high-profile AI experts have departed Google after the controversial firing of leading ethicist Timnit Gebru.
Gebru was fired from Google after criticising the company’s practices in an email following a dispute over a paper she was told not to publish which questioned whether language models can be too big and whether they can increase prejudice and inequalities. In her email, Gebru also expressed frustration at the lack of progress in hiring women at Google.

I was fired by @JeffDean for my email to Brain women and Allies. My corp account has been cutoff. So I've been immediately fired 🙂— Timnit Gebru (@timnitGebru) December 3, 2020

Jeff Dean, Head of Google Research, rebuked some of Gebru’s claims in an email to employees. Dean claims Gebru only shared the paper a day before its deadline – when the internal review process requires two weeks – and then “instead of awaiting reviewer feedback, it was approved for submission and submitted.”
The letter hasn’t convinced all Googlers and many continue to express concerns about the company’s policies. Some have even decided they can no longer work at Google:

Yesterday was my last day at Google. I left because Google's mistreatment of @timnitGebru and @RealAbril crossed a personal red line I wrote down when I started the job. I know I gained a lot from Google, but I also gained a lot from both of their work, and they were wronged.— Vinesh Kannan (@vineshgkannan) February 3, 2021

Kannan went on to explain what the “personal red line” was and why he wrote it down:
""retaliation against a teammate who stands up for something I believe in""I wrote this red line because, between when I accepted my offer and when I started, Google retaliated against @mer__edith and @clairewaves. I was upset, because they were people who inspired me to join.— Vinesh Kannan (@vineshgkannan) February 4, 2021 
According to Reuters, engineering director David Baker also handed in his resignation after 16 years with Google.
In his letter, Baker said Gebru’s firing “extinguished [his] desire to continue as a Googler.” He added: “We cannot say we believe in diversity, and then ignore the conspicuous absence of many voices from within our walls.”
Similarities can be drawn to how at least a dozen Googlers opted to hand in their resignations after Google signed a contract with the Pentagon to develop AI technologies for military drones. Google ultimately dropped the controversial contract and it was picked up by Palantir instead.
It seems Google has a lot more work to do to restore trust and prevent further experts from taking their talents elsewhere.
(Photo by Jos Speetjens on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, ethics, Featured, Google, Society, timnit gebru






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google is leaking AI talent following ethicist’s controversial firing,2021-02-05,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['leaking', 'ethicists', 'email', 'fired', 'wrote', 'lot', 'gebru', 'work', 'red', 'expo', 'ai', 'following', 'google', 'firing', 'controversial', 'talent', 'line']","Some high-profile AI experts have departed Google after the controversial firing of leading ethicist Timnit Gebru.
In her email, Gebru also expressed frustration at the lack of progress in hiring women at Google.
I left because Google's mistreatment of @timnitGebru and @RealAbril crossed a personal red line I wrote down when I started the job.
It seems Google has a lot more work to do to restore trust and prevent further experts from taking their talents elsewhere.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
21,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
22,https://artificialintelligence-news.com/2020/10/02/facebook-ai-help-people-support-each-other/,"

Facebook uses AI to help people support each other




 






By Ryan Daws |
        October 2, 2020                    | TechForge Media

                            Categories:
                                    Facebook,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Facebook has deployed an AI system which matches people needing support with local heroes offering it.“United we stand, divided we fall” is a clichéd saying—but tackling a pandemic is a collective effort. While we’ve all seen people taking selfish actions, they’ve been more than balanced out by those helping to support their communities.
Facebook has been its usual blessing and a curse during the pandemic. On the one hand, it’s helped people to stay connected and organise community efforts. On the other, it’s allowed dangerous misinformation to spread like wildfire that’s led to the increase in anti-vaccine and anti-mask movements.
The social media giant is hoping that AI can help to swing the balance more towards Facebook having an overall benefit within our communities.
If a person has posted asking for help because they’re unable to leave the house, Facebook’s AI may automatically match that person with someone local who has recently said they’re willing to get things like groceries or prescriptions for people.

In a blog post, Facebook explains how it built its matching algorithm:
We built and deployed this matching algorithm using XLM-R, our open-source, cross-lingual understanding model that extends our work on XLM and RoBERTa, to produce a relevance score that ranks how closely a request for help matches the current offers for help in that community.The system then integrates the posts’ ranking score into a set of models trained on PyText, our open-source framework for natural language processing.
It’s a great idea which could go a long way to making a real positive impact on people in difficult times. Hopefully, we’ll see more of such efforts from Facebook to improve our communities.
(Photo by Bohdan Pyryn on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, coronavirus, covid-19, facebook, Featured, social media






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Facebook uses AI to help people support each other,2020-10-02,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['uses', 'support', 'theyre', 'expo', 'tech', 'ai', 'score', 'facebook', 'help', 'system', 'person']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
Facebook has deployed an AI system which matches people needing support with local heroes offering it.
While we’ve all seen people taking selfish actions, they’ve been more than balanced out by those helping to support their communities.
The social media giant is hoping that AI can help to swing the balance more towards Facebook having an overall benefit within our communities.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
23,https://artificialintelligence-news.com/2020/08/19/white-house-boost-ai-funding-30-percent/,"

The White House is set to boost AI funding by 30 percent




 






By Ryan Daws |
        August 19, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Applications,
                                    Funding,
                                    Government,
                                    Research,
                                    Society,
                                    USA,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A budget proposal from the White House would boost funding for AI by around 30 percent as the US aims to retain its technological supremacy.
Countries around the world are vastly increasing their budgets for AI, and with good reason. Just look at Gartner’s Hype Cycle released yesterday to see how important the technology is expected to be over the next decade.
Russian president Vladimir Putin famously said back in 2017 that the nation which leads in AI “will become the ruler of the world”. Putin said that AI offers unprecedented power, including military power, to any government that leads in the field.
China, the third global superpower, has also embarked on a major national AI strategy. In July 2017, The State Council of China released the “New Generation Artificial Intelligence Development Plan” to build a domestic AI industry worth around $150 billion over the next few years and to become the leading AI power by 2030.
Naturally, the US isn’t going to give that top podium spot to China without a fight.
The White House has proposed (PDF) a 30 percent hike in spending on AI and quantum computing. Around $1.5 billion would be allocated to AI funding and $699 million to quantum technology.
According to a report published by US national security think tank Center for a New American Security (CNAS), Chinese officials see an AI ‘arms race’ as a threat to global peace.
The fear of the CNAS is that integrating AI into military resources and communications may breach current international norms and lead to conflict-by-accident.
China and the US have been vying to become the top destination for AI investments. Figures published by ABI Research at the end of last year suggested that the US reclaimed the top spot for AI investments back from China, which overtook the Americans the year prior. ABI expects the US to reach a 70 percent share of global AI investments.
Lian Jye Su, Principal Analyst at ABI Research, said: 
“The United States is reaping the rewards from its diversified AI investment strategy. Top AI startups in the United States come from various sectors, including self-driving cars, industrial manufacturing, robotics process automation, data analytics, and cybersecurity.”
The UK, unable to match the levels of funding allocated to AI research as the likes of the US and China, is taking a different approach.
An index compiled by Oxford Insights last year ranked the UK number one for AI readiness in Europe and only second on the world stage behind Singapore. The US is in fourth place, while China only just makes the top 20.
The UK has focused on AI policy and harnessing the talent from its world-leading universities to ensure the country is ready to embrace the technology’s opportunities.
A dedicated AI council in the UK features:
Ocado’s Chief Technology Officer, Paul ClarkeDame Patricia Hodgson, Board Member of the Centre for Data Ethics and Innovation The Alan Turing Institute Chief Executive, Professor Adrian SmithAI for good founder Kriti SharmaUKRI chief executive Mark WalportFounding Director of the Edinburgh Centre for Robotics, Professor David Lane
British Digital Secretary Jeremy Wright stated: “Britain is already a leading authority in AI. We are home to some of the world’s finest academic institutions, landing record levels of investment to the sector, and attracting the best global tech talent. But we must not be complacent.”
Growing cooperation between the UK and US in a number of technological endeavours could help to harness the strengths of both nations if similarly applied to AI, helping to maintain the countries’ leaderships in the field.
(Photo by Louis Velazquez on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: america, artificial intelligence, Featured, funding, government, usa, white house






View Comments


Leave a comment




            One comment on “The White House is set to boost AI funding by 30 percent”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",The White House is set to boost AI funding by 30 percent,2020-08-19,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['30', 'research', 'house', 'set', 'uk', 'global', 'security', 'boost', 'expo', 'funding', 'ai', 'china', 'world', 'tech', 'white', 'power']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
A budget proposal from the White House would boost funding for AI by around 30 percent as the US aims to retain its technological supremacy.
The White House has proposed (PDF) a 30 percent hike in spending on AI and quantum computing.
ABI expects the US to reach a 70 percent share of global AI investments.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
24,https://artificialintelligence-news.com/2020/12/22/chinese-ai-chipmaker-horizon-raise-700m-rival-nvidia/,"

Chinese AI chipmaker Horizon endeavours to raise $700M to rival NVIDIA




 






By Ryan Daws |
        December 22, 2020                    | TechForge Media

                            Categories:
                                    China,
                                    Hardware,
                                    Robotics,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




AI chipmaker Horizon Robotics is seeking to raise $700 million in a new funding round.
Horizon is often seen as potentially becoming China’s equivalent of NVIDIA. The company is founded by Dr Kai Yu, a prominent industry figure with quite the credentials.
Yu led Baidu’s AI Research lab for three years, founded the Baidu Institute of Deep Learning, and launched the company’s autonomous driving business unit.
Furthermore, Yu has taught at Stanford University, published over 60 papers, and even won first place in the ImageNet challenge which evaluates algorithms for object detection and image classification.
China is yet to produce a chipset firm which can match the capabilities of Western equivalents.
With increasing US sanctions making it more difficult for Chinese firms to access American semiconductors, a number of homegrown companies are emerging and gaining attention from investors.
Horizon is just five-years-old and specialises in making AI chips for robots and autonomous vehicles. The company has already attracted significant funding.
Around two years ago, Horizon completed a $600 million funding round with a $3 billion valuation. The company has secured $150 million so far as part of this latest round.
While it’s likely the incoming Biden administration in the US will take a less strict approach to trade with China, it seems Beijing wants to build more homegrown alternatives which can match or surpass Western counterparts.
Chinese tech giants like Huawei are investing significant resources in their chip manufacturing capabilities to ensure the country has the tech it needs to power groundbreaking advancements like self-driving cars.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, China, chinese, devices, Featured, funding, hardware, horizon, horizon robotics, robotics






View Comments


Leave a comment




            One comment on “Chinese AI chipmaker Horizon endeavours to raise $700M to rival NVIDIA”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Chinese AI chipmaker Horizon endeavours to raise $700M to rival NVIDIA,2020-12-22,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['raise', 'significant', 'western', '700m', 'endeavours', 'rival', 'expo', 'ai', 'tech', 'million', 'horizon', 'yu', 'nvidia', 'match', 'making', 'chinese', 'company', 'chipmaker']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
AI chipmaker Horizon Robotics is seeking to raise $700 million in a new funding round.
Yu led Baidu’s AI Research lab for three years, founded the Baidu Institute of Deep Learning, and launched the company’s autonomous driving business unit.
Horizon is just five-years-old and specialises in making AI chips for robots and autonomous vehicles.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
25,https://artificialintelligence-news.com/categories/enterprise/,"



Opinion: What is real intelligent automation?










Intelligent automation reduces costs, improves efficiency and allows businesses to initiate change through technology. When applied to business operations or customer services, it has proven to be an invaluable piece of technology as it improves productivity thus saving time in the process with quicker responses. With intelligent automation, manufacturing giant Siemens has driven 10 times faster processes at a tenth of the cost.
However, some software vendors place commodity... 






        29 January 2021                    |
            Enterprise





",Enterprise Archives,,[],"['vendor', 'users', 'archives', 'paths', 'ai', 'view', 'vendors', 'buyer', 'enterprise', 'journey', 'report', 'understanding']","Research firm Strategy Analytics has argued in a new report that both vendors of AI products and their users can succeed with a 'thorough understanding' of customer journeys.
The report, 'Defining the AI Buyer Journey', aims to take a comprehensive view of the 'who, what, why and how long' issues in the buyer journey, from paths to selection, paths to adoption, and implementation.
The goal is to avoid all 'AI-washing' where possible.
This can occur on both the vendor...",AInews
26,https://artificialintelligence-news.com/2020/10/20/intel-ubotica-esa-launch-first-ai-satellite/,"

Intel, Ubotica, and the ESA launch the first AI satellite




 






By Ryan Daws |
        October 20, 2020                    | TechForge Media

                            Categories:
                                    Edge,
                                    Hardware,
                                    Intel,
                                    Space,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Intel, Ubotica, and the European Space Agency (ESA) have launched the first AI satellite into Earth’s orbit.
The PhiSat-1 satellite is about the size of a cereal box and was ejected from a rocket’s dispenser alongside 45 other satellites. The rocket launched from Guiana Space Centre on September 2nd.
Intel has integrated its Movidius Myriad 2 Vision Processing Unit (VPU) into PhiSat-1 – enabling large amounts of data to be processed on the device. This helps to prevent useless data being sent back to Earth and consuming precious bandwidth.
“The capability that sensors have to produce data increases by a factor of 100 every generation, while our capabilities to download data are increasing, but only by a factor of three, four, five per generation,” says Gianluca Furano, data systems and onboard computing lead at the ESA.
Around 30 percent data savings are expected by using AI at the edge on the PhiSat-1.
“Space is the ultimate edge,” says Aubrey Dunne, chief technology officer of Ubotica. “The Myriad was absolutely designed from the ground up to have an impressive compute capability but in a very low power envelope, and that really suits space applications.”
PhiSat-1 is currently in a sun-synchronous orbit around 329 miles (530 km) above Earth and travelling at over 17,000mph (27,500kmh).



The satellite’s mission is to assess things like polar ice for monitoring climate change, and soil moisture for the growth of crops. One day it could help to spot wildfires in minutes rather than hours or detect environmental accidents at sea.
A successor, PhiSat-2, is currently planned to test more of these possibilities. PhiSat-2 will also carry another Myriad 2.
Myriad 2 was not originally designed for use in orbit. Specialist chips which are protected against radiation are typically used for space missions and can be “up to two decades behind state-of-the-art commercial technology,” explains Dunne.
Incredibly, the Myriad 2 survived 36 straight hours of being blasted with radiation at CERN in late-2018 without any modifications.
ESA announced the joint team was “happy to reveal the first-ever hardware-accelerated AI inference of Earth observation images on an in-orbit satellite.”
PhiSat-1 and PhiSat-2 will be part of a future network with intersatellite communication systems.
(Image Credit: CERN/M. Brice)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, edge, esa, european space agency, Featured, intel, launch, movidius, myriad, phisat-1, phisat-2, satellite, space, ubotica






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






","Intel, Ubotica, and the ESA launch the first AI satellite",2020-10-20,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['space', 'data', 'technology', 'esa', 'satellite', 'ubotica', 'expo', 'myriad', 'ai', 'phisat2', 'intel', 'launch', 'tech', 'earth']","Intel, Ubotica, and the European Space Agency (ESA) have launched the first AI satellite into Earth’s orbit.
The PhiSat-1 satellite is about the size of a cereal box and was ejected from a rocket’s dispenser alongside 45 other satellites.
Around 30 percent data savings are expected by using AI at the edge on the PhiSat-1.
“Space is the ultimate edge,” says Aubrey Dunne, chief technology officer of Ubotica.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
27,https://artificialintelligence-news.com/2020/12/16/facebook-developing-news-summarising-ai-tldr/,"

Facebook is developing a news-summarising AI called TL;DR




 






By Ryan Daws |
        December 16, 2020                    | TechForge Media

                            Categories:
                                    Facebook,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Facebook is developing an AI called TL;DR which summarises news into shorter snippets.
Anyone who’s spent much time on the web will know what TL;DR stands for⁠—but, for everyone else, it’s an acronym for “Too Long, Didn’t Read”.
It’s an understandable sentiment we’ve all felt at some point. People lead busy lives. Some outlets now even specialise in short, at-a-glance news.
The problem is, it’s hard to get the full picture of a story in just a brief snippet.
In a world where fake news can be posted and spread like wildfire across social networks – almost completely unchecked – it feels even more dangerous to normalise “news” being delivered in short-form without full context.
There are two sides to most stories, and it’s hard to see how both can be summarised properly.
News folks are not going to love this. Some product manager announced internally a tool that FB is developing called ""TL;DR"". Basically, it will use AI to summarize long form articles and spit out bullet points so people don't have to read the full piece.What could go wrong!— Ryan Mac 🙃 (@RMac18) December 15, 2020 
However, the argument also goes the other way. When articles are too long, people have a natural habit of skim-reading them. Skimming in this way often means people then believe they’re fully informed on a topic… when we know that’s often not the case.
TL;DR needs to strike a healthy balance between summarising the news but not so much that people don’t get enough of the story. Otherwise, it could increase existing societal problems with misinformation, fake news, and lack of media trust.
According to BuzzFeed, Facebook showed off TL;DR during an internal meeting this week. 
Facebook appears to be planning to add an AI-powered assistant to TL;DR which can answer questions about the article. The assistant could help to clear up anything the reader is uncertain about, but it’s also going to have to prove it doesn’t suffer from any biases which arguably all current algorithms suffer from to some extent.
The AI is also going to have to be very careful in not taking things like quotes out-of-context and end up further automating the spread of misinformation.
There’s also going to be a debate over what sources Facebook should use. Should Facebook stick only to the “mainstream media” which many believe follow the agendas of certain powerful moguls? Or serve news from smaller outlets without much historic credibility? The answer probably lies somewhere in the middle, but it’s going to be difficult to get right.
Facebook continues to be a major source of misinformation – in large part driven by algorithms promoting such content – and it’s had little success so far in any news-related efforts. I think most people will be expecting this to be another disaster waiting to happen.
(Image Credit: Mark Zuckerberg by Alessio Jacona under CC BY-SA 2.0 license)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, assistant, ethics, facebook, Featured, News, Society, tl;dr, tldr






View Comments


Leave a comment




            One comment on “Facebook is developing a news-summarising AI called TL;DR”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Facebook is developing a news-summarising AI called TL;DR,2020-12-16,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['called', 'media', 'expo', 'world', 'ai', 'newssummarising', 'way', 'facebook', 'tldr', 'developing', 'tech', 'long', 'going']","Facebook is developing an AI called TL;DR which summarises news into shorter snippets.
Some product manager announced internally a tool that FB is developing called ""TL;DR"".
According to BuzzFeed, Facebook showed off TL;DR during an internal meeting this week.
Facebook appears to be planning to add an AI-powered assistant to TL;DR which can answer questions about the article.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
28,https://artificialintelligence-news.com/2020/05/05/microsoft-python-video-courses-ai-developers/,"

Microsoft releases two Python video courses which help aspiring AI developers




 






By Ryan Daws |
        May 5, 2020                    | TechForge Media

                            Categories:
                                    Developers,
                                    Education,
                                    Microsoft,
                                    TECHEX,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Microsoft has released two Python video courses to help AI developers get started in what could be a very lucrative career.
The new video courses assume the developer already has a basic standard of Python skills. If you don’t, I’m afraid you’ll need to brush up on those first. Fortunately, Microsoft released a 44-part “Python for Beginners” series last autumn (or “fall” for our American friends.)
For those with the Python skills, or if you’ve just consumed all 44-parts of Microsoft’s course in record time, the new courses are around three hours each. 
The first course, More Python for Beginners, features 20 videos and covers areas such as lambdas, inheritance, and asynchronous operations.
The second course, Even More Python for Beginners: Data Tools, consists of 31 videos and really dives into using Python for machine learning and data science. Students are taught how to use popular Python libraries for the aforementioned topics; along with using the Jupyter Notebooks browser-based development environment.
Each of the courses are still led by Christopher Harrison, senior program manager at Microsoft, and Susan Ibach, business development manager from Microsoft AI Gaming. 
“While we’re not going to get into conversations about choosing algorithms or building models, we are going to introduce what you’ll use when you begin the journey. We’ll highlight Jupyter Notebooks, the favorite tool of data scientists,” Harrison and Ibach wrote in a blog. 
As of writing, the first part in Microsoft’s Python course series has been viewed over 1.75 million times.
The course’s popularity is of little surprise given the huge interest in Python as AI talent becomes more in-demand; with six-figure salaries not unheard of. In last year’s GitHub Octoverse report, Python overtook Java to become the second most popular language on the world’s largest repository host.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, course, developers, development, microsoft, python






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Microsoft releases two Python video courses which help aspiring AI developers,2020-05-05,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['youll', 'data', 'developers', 'releases', 'courses', 'course', 'python', 'expo', 'series', 'ai', 'beginners', 'help', 'microsoft', 'aspiring', 'video']","Microsoft has released two Python video courses to help AI developers get started in what could be a very lucrative career.
Fortunately, Microsoft released a 44-part “Python for Beginners” series last autumn (or “fall” for our American friends.)
Each of the courses are still led by Christopher Harrison, senior program manager at Microsoft, and Susan Ibach, business development manager from Microsoft AI Gaming.
As of writing, the first part in Microsoft’s Python course series has been viewed over 1.75 million times.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
29,https://artificialintelligence-news.com/2021/01/20/boeing-sparkcognition-joint-venture-skygrid-deploys-ai-protect-drones/,"

Boeing-SparkCognition joint venture SkyGrid deploys AI to protect drones




 






By Ryan Daws |
        January 20, 2021                    | TechForge Media

                            Categories:
                                    Drones,
                                    Edge,
                                    IoT,
                                    Robotics,
                                    Security,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




SkyGrid, a Boeing-SparkCognition joint venture, has launched the world’s first AI-powered security for drones.
Drones are being used for increasingly critical purposes, including carrying vital medical supplies. Security is paramount to build the trust necessary to unlock the full potential of the emerging industry.
Amir Husain, CEO and founder of SparkCognition and SkyGrid, said:
“In the near future, we’ll essentially have a network of flying computers in the sky, and just like the computers we use today, drones can be hacked if not secured properly.In this emerging environment, traditional anti-malware technology won’t be adequate to detect these never-before-seen attacks. SkyGrid is taking a new, intelligent approach by using AI to more accurately detect and prevent cyberattacks from impacting a drone, a payload, or a ground station.”
SkyGrid is equipped with SparkCognition’s DeepArmor, which promises far more advanced security than traditional anti-malware detection. AI models are trained “on the DNA of malicious files” rather than detecting signatures relating to known threats.
Sridhar Sudarsan, Chief Technology Officer at SparkCognition, comments:
“We leveraged cutting-edge AI research and technology to build the DeepArmor product, which allows it to protect endpoints against 99.9% of never-before-seen threats.In addition, the product’s uniqueness lies in its ability to provide top-rate endpoint protection on the lowest footprint with minimal interference – all in varying degrees of connectivity. This is the true overarching security differentiator from which SkyGrid’s customers will see value.”
DeepArmour can be deployed directly on drones to function at the edge for when network connectivity is limited or even nonexistent.
A recent demonstration showed SkyGrid’s solution in action:



SparkCognition also recently added DeepArmor Industrial to its offerings, a solution built in collaboration with Siemens Energy to protect operational technology assets across the energy value chain.
(Image Credit: SkyGrid)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, boeing, cybersecurity, deeparmor, drone, drones, Featured, security, skygrid, sparkcognition






View Comments


Leave a comment




            One comment on “Boeing-SparkCognition joint venture SkyGrid deploys AI to protect drones”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Boeing-SparkCognition joint venture SkyGrid deploys AI to protect drones,2021-01-20,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['deeparmor', 'technology', 'traditional', 'solution', 'joint', 'security', 'sparkcognition', 'skygrids', 'boeingsparkcognition', 'skygrid', 'ai', 'expo', 'venture', 'deploys', 'tech', 'drones', 'protect']","SkyGrid, a Boeing-SparkCognition joint venture, has launched the world’s first AI-powered security for drones.
In this emerging environment, traditional anti-malware technology won’t be adequate to detect these never-before-seen attacks.
AI models are trained “on the DNA of malicious files” rather than detecting signatures relating to known threats.
Sridhar Sudarsan, Chief Technology Officer at SparkCognition, comments:“We leveraged cutting-edge AI research and technology to build the DeepArmor product, which allows it to protect endpoints against 99.9% of never-before-seen threats.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
30,https://artificialintelligence-news.com/categories/cloud/,"



Eggplant launches AI-powered software testing in the cloud










Automation specialists Eggplant have launched a new AI-powered software testing platform.
The cloud-based solution aims to help accelerate the delivery of software in a rapidly-changing world while maintaining a high bar of quality.
Gareth Smith, CTO of Eggplant, said:
“The launch of our cloud platform is a significant milestone in our mission to rid the world of bad software. In our new normal, delivering speed and agility at scale has never been more... 






        6 October 2020                    |
            Cloud





",Cloud Archives,,[],"['gpu', 'a100', 'users', 'cloud', 'archives', 'workloadsthe', 'trained', 'ai', 'google', 'nvidia', 'training']","Google Cloud users can now harness the power of NVIDIA’s Ampere GPUs for their AI workloads.
The specific GPU added to Google Cloud is the NVIDIA A100 Tensor Core which was announced just last month.
NVIDIA says the A100 “has come to the cloud faster than any NVIDIA GPU in history.”NVIDIA claims the A100 boosts training and inference performance by up to 20x over its predecessors.
Large AI models like BERT can be trained in just 37 minutes on a cluster of 1,024...",AInews
31,https://artificialintelligence-news.com/2020/07/31/ai-tool-detect-child-abuse-images-accuracy/,"

AI tool detects child abuse images with 99% accuracy




 






By Ryan Daws |
        July 31, 2020                    | TechForge Media

                            Categories:
                                    Applications,
                                    Law Enforcement,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A new AI-powered tool claims to detect child abuse images with around 99 percent accuracy.
The tool, called Safer, is developed by non-profit Thorn to assist businesses which do not have in-house filtering systems to detect and remove such images.
According to the Internet Watch Foundation in the UK, reports of child abuse images surged 50 percent during the COVID-19 lockdown. In the 11 weeks starting on 23rd March, its hotline logged 44,809 reports of images compared with 29,698 last year. Many of these images are from children who’ve spent more time online and been coerced into releasing images of themselves.
Andy Burrows, head of child safety online at the NSPCC, recently told the BBC: “Harm could have been lessened if social networks had done a better job of investing in technology, investing in safer design features heading into this crisis.”
Safer is one tool which could help with quickly flagging child abuse content to limit the harm caused.
The detection services of Safer include:
Image Hash Matching: The flagship service that generates cryptographic and perceptual hashes for images and compares those hashes to known CSAM hashes. At the time of publishing, the database includes 5.9M hashes. Hashing happens in the client’s infrastructure to maintain user privacy.CSAM Image Classifier: Machine learning classification model developed by Thorn and leveraged within Safer that returns a prediction for whether a file is CSAM. The classifier has been trained on datasets totaling hundreds of thousands images including adult pornography, CSAM, and various benign imagery and can aid in the identification of potentially new and unknown CSAM.Video Hash Matching: Service that generates cryptographic and perceptual hashes for video scenes and compares them to hashes representing scenes of suspected CSAM. At the time of publishing, the database includes over 650k hashes of suspected CSAM scenes.SaferList for Detection: Service for Safer customers to leverage the knowledge of the broader Safer community by matching against hash sets contributed by other Safer customers to broaden detection efforts. Customers can customise what hash sets they would like to include.
However, the problem doesn’t stop with flagging content. It’s been documented that moderators for social media platforms often require therapy or even commit suicide after being exposed day-in, day-out to some of the most disturbing content posted online.
Thorn claims Safer is built with the wellness of moderators in mind. To this end, content is automatically blurred (the company says this currently only works for images.)
Safer has APIs available for developers that “are built to broaden the shared knowledge of child abuse content by contributing hashes, scanning against other industry hashes, and sending feedback on false positives.”
One of Thorn’s most high-profile clients so far is Flickr. Using Safer, Flickr found an image of child abuse hosted on its platform which – following a law enforcement investigation – led to the recovery of 21 children ranging from 18 months to 14 years old, and the arrest of the perpetrator.
Safer is currently available for any company operating in the US. Thorn plans to expand to other countries next year after customising for each country’s national reporting requirements.
You can find out more about the tool and how to get started here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, child abuse, child exploitation, Featured, Safer, Thorn






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI tool detects child abuse images with 99% accuracy,2020-07-31,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['content', 'hash', 'hashes', 'tool', 'accuracy', '99', 'child', 'expo', 'images', 'ai', 'csam', 'safer', 'detects', 'abuse']","A new AI-powered tool claims to detect child abuse images with around 99 percent accuracy.
The tool, called Safer, is developed by non-profit Thorn to assist businesses which do not have in-house filtering systems to detect and remove such images.
According to the Internet Watch Foundation in the UK, reports of child abuse images surged 50 percent during the COVID-19 lockdown.
Many of these images are from children who’ve spent more time online and been coerced into releasing images of themselves.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
32,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
33,https://artificialintelligence-news.com/2020/09/14/nvidia-arm-world-class-ai-centre-cambridge/,"

Nvidia and ARM will open ‘world-class’ AI centre in Cambridge




 






By Ryan Daws |
        September 14, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Applications,
                                    Developers,
                                    Europe,
                                    Machine Learning,
                                    Nvidia,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Nvidia is already putting its $40 billion ARM acquisition to good use by opening a “world-class” AI centre in Cambridge.
British chip designer ARM’s technology is at the heart of most mobile devices. Meanwhile, Nvidia’s GPUs are increasingly being used for AI computation in servers, desktops, and even things like self-driving vehicles.
However, Nvidia was most interested in ARM’s presence in edge devices—which it estimates to be in the region of 180 billion.
Jensen Huang, CEO of Nvidia, said:
“ARM is an incredible company and it employs some of the greatest engineering minds in the world. But we believe we can make ARM even more incredible and take it to even higher levels.We want to propel it — and the UK — to global AI leadership.”
There were concerns Nvidia’s acquisition would lead to job losses, but the company has promised to keep the business in the UK. The company says it’s planning to hire more staff and retain ARM’s iconic brand.
Nvidia is going further in its commitment to the UK by opening a new AI centre in Cambridge, which is home to an increasing number of exciting startups in the field such as FiveAI, Prowler.io, Fetch.ai, and Darktrace.
“We will create an open centre of excellence in the area once home to giants like Isaac Newton and Alan Turing, for whom key NVIDIA technologies are named.Here, leading scientists, engineers and researchers from the UK and around the world will come to develop their ideas, collaborate and conduct their ground-breaking work in areas like healthcare, life sciences, self-driving cars, and other fields.”
The new centre will have five key features when it opens:
ARM/Nvidia-based supercomputer – set to be one of the most powerful AI supercomputers in the world.Research Fellowships and Partnerships – Nvidia will use the centre to establish new UK-based research partnerships, expanding on successful relationships already established with King’s College and Oxford.AI Training – Nvidia will make its AI curriculum available across the UK to help create job opportunities and prepare “the next generation of UK developers for AI leadership”Startup Accelerator – With so many of the world’s most exciting AI companies launching in the UK, the Nvidia Inception accelerator will help startups succeed by providing access to the aforementioned supercomputer, connections to researchers from NVIDIA and partners, technical training, and marketing promotion.Industry Collaboration – AI is still in its infancy but will impact every industry to some extent. Nvidia says its new research facility will be an open hub for industry collaboration, building on the company’s existing relationships with the likes of GSK, Oxford Nanopore, and other leaders in their fields.
The UK is Europe’s leader in AI and the British government is investing heavily in ensuring it maintains its pole position. Beyond funding, the UK is also aiming to ensure it’s among the best places to run an AI company.
Current EU rules, especially around data, are often seen as limiting the development of European AI companies when compared to elsewhere in the world. While the UK will have to avoid being accused of doing a so-called “bonfire of regulations” post-Brexit, data collection regulations is likely an area which will be relaxed.
In the UK’s historic trade deal signed with Japan last week, several enhancements were made over the blanket EU-Japan deal signed earlier this year. Among the perceived improvements is the “free flow of data” by not enforcing localisation requirements, and that algorithms can remain private.
UK trade secretary Liz Truss said: “The agreement we have negotiated – in record time and in challenging circumstances – goes far beyond the existing EU deal, as it secures new wins for British businesses in our great manufacturing, food and drink, and tech industries.”
Japan and the UK, as two global tech giants, are expected to deepen their collaboration in the coming years—building on the trade deal signed last week.
Shigeki Ishizuka, Chairman of the Japan Electronics and Information Technology Industries Association, said: “We are confident that this mutual relationship will be further strengthened as an ambitious agreement that will contribute to the promotion of cooperation in research and development, the promotion of innovation, and the further expansion of inter-company collaboration.”
Nvidia’s investment shows that it has confidence in the UK’s strong AI foundations continuing to gain momentum in the coming years.
(Photo by A Perry on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, ai centre, arm, artificial intelligence, britain, british, cambridge, europe, Featured, industry, Nvidia, research, Startups, training, uk, United Kingdom






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Nvidia and ARM will open ‘world-class’ AI centre in Cambridge,2020-09-14,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['promotion', 'research', 'uk', 'centre', 'worldclass', 'world', 'expo', 'cambridge', 'arm', 'ai', 'tech', 'industry', 'nvidia', 'open']","Nvidia is already putting its $40 billion ARM acquisition to good use by opening a “world-class” AI centre in Cambridge.
Nvidia is going further in its commitment to the UK by opening a new AI centre in Cambridge, which is home to an increasing number of exciting startups in the field such as FiveAI, Prowler.io, Fetch.ai, and Darktrace.
– Nvidia will use the centre to establish new UK-based research partnerships, expanding on successful relationships already established with King’s College and Oxford.
Industry Collaboration – AI is still in its infancy but will impact every industry to some extent.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
34,https://artificialintelligence-news.com/2020/09/21/google-human-youtube-moderators-ai-errors/,"

Google returns to using human YouTube moderators after AI errors




 






By Ryan Daws |
        September 21, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Ethics,
                                    Google,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Google is returning to using humans for YouTube moderation after repeated errors with its AI system.
Moderating a large network like YouTube is no easy task. Aside from the sheer volume of content uploaded every day, moderators are subjected to the worst of humanity and often end up requiring therapy. They’re the unsung heroes.
AI has been hailed as helping to deal with some of the aforementioned issues. Either by automating the moderation process entirely or by offering a helping hand to humans.
Google was left with little choice but to give more power to its AI moderators as the COVID-19 pandemic took hold… but it hasn’t been smooth sailing.
In late August, YouTube said that it had removed 11.4 million videos over the three months prior–the most since the site launched in 2005.
That figure alone should raise a few eyebrows. If a team of humans were removing that many videos, they probably deserve quite the pay rise.
Of course, most of the video removals weren’t done by humans. Many of the videos didn’t even violate the guidelines.
Neal Mohan, chief product officer at YouTube, told the Financial Times:
“One of the decisions we made [at the beginning of the COVID-19 pandemic] when it came to machines who couldn’t be as precise as humans, we were going to err on the side of making sure that our users were protected, even though that might have resulted in [a] slightly higher number of videos coming down.”
Some of the removals left content creators bewildered, angry, and out of pocket in some cases.
Around 320,000 of videos taken down were appealed, and half of the appealed videos were reinstated.
Deciding what content to ultimately remove feels like one of the many tasks which needs human involvement. Humans are much better at detecting nuances and things like sarcasm.
However, the sheer scale of content needing to be moderated also requires an AI to help automate some of that process.
“Over 50 percent of those 11 million videos were removed without a single view by an actual YouTube user and over 80 percent were removed with less than 10 views,” Mohan said. “That’s the power of machines.”
AIs can also help to protect humans from the worst of the content. Content detection systems are being built to automatically blur things like child abuse enough so that human moderators know what it is to remove it—but to limit their psychological impact.
Some believe AIs are better in helping to determine what content should be removed simply using logic rather than a human’s natural biases like their political-leaning, but we know human biases seep into algorithms.
In May, YouTube admitted to deleting messages critical of the Chinese Communist Party (CCP). YouTube later blamed an “error with our enforcement systems” for the mistakes. Senator Josh Hawley even wrote (PDF) to Google CEO Sundar Pichai seeking answers to “troubling reports that your company has resumed its long pattern of censorship at the behest of the Chinese Communist Party.”
Google appears to have quickly realised that replacing humans entirely with AI is rarely a good idea. The company says many of the human moderators who were “put offline” during the pandemic are now coming back.
(Photo by Rachit Tank on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, ethics, Featured, Google, moderation, Society, videos, youtube






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google returns to using human YouTube moderators after AI errors,2020-09-21,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['content', 'removed', 'human', 'using', 'youtube', 'humans', 'videos', 'pandemic', 'expo', 'ai', 'returns', 'google', 'errors', 'moderators']","Google is returning to using humans for YouTube moderation after repeated errors with its AI system.
Google was left with little choice but to give more power to its AI moderators as the COVID-19 pandemic took hold… but it hasn’t been smooth sailing.
Content detection systems are being built to automatically blur things like child abuse enough so that human moderators know what it is to remove it—but to limit their psychological impact.
The company says many of the human moderators who were “put offline” during the pandemic are now coming back.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
35,https://artificialintelligence-news.com/2020/12/04/google-fires-ethical-ai-researcher-timnit-gebru-email/,"

Google fires ethical AI researcher Timnit Gebru after critical email




 






By Ryan Daws |
        December 4, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Google,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A leading figure in ethical AI development has been fired by Google after criticising the company.
Timnit Gebru is considered a pioneer in the field and researched the risks and inequalities found in large language models.
Gebru claims she was fired by Google over an unpublished paper and sending an email critical of the company’s practices.
The paper questions whether language models can be too big, who benefits from them, and whether they can increase prejudice and inequalities. Some recent cases validate her claims about large models and datasets in general.
For example, MIT was forced to remove a large dataset earlier this year called 80 Million Tiny Images. The dataset is popular for training AIs but was found to contain images labelled with racist, misogynistic, and other unacceptable terms.
A statement on MIT’s website claims it was unaware of the offensive labels and they were “a consequence of the automated data collection procedure that relied on nouns from WordNet.”
The statement goes on to explain the 80 million images contained in the dataset – with sizes of just 32×32 pixels – meant that manual inspection would be almost impossible and couldn’t guarantee all offensive images would be removed.
Gebru reportedly sent an email to the Google Brain Women and Allies listserv that is “inconsistent with the expectations of a Google manager.”
In the email, Gebru expressed her frustration with a perceived lack of progress at Google in hiring women at Google. Gebru claimed she was also told not to publish a piece of research and advised employees to stop filling out diversity paperwork because it didn’t matter.
On top of the questionable reasons for her firing, Gebru says her former colleagues were emailed saying she offered her resignation—which she claims was not the case:

Apparently my manager’s manager sent an email my direct reports saying she accepted my resignation. I hadn’t resigned—I had asked for simple conditions first and said I would respond when I’m back from vacation. But I guess she decided for me 🙂 that’s the lawyer speak.— Timnit Gebru (@timnitGebru) December 3, 2020

Platformer obtained an email from Jeff Dean, Head of Google Research, which was sent to employees and offers his take on Gebru’s claims:
“We’ve approved dozens of papers that Timnit and/or the other Googlers have authored and then published, but as you know, papers often require changes during the internal review process (or are even deemed unsuitable for submission). Unfortunately, this particular paper was only shared with a day’s notice before its deadline — we require two weeks for this sort of review — and then instead of awaiting reviewer feedback, it was approved for submission and submitted.A cross functional team then reviewed the paper as part of our regular process and the authors were informed that it didn’t meet our bar for publication and were given feedback about why. It ignored too much relevant research — for example, it talked about the environmental impact of large models, but disregarded subsequent research showing much greater efficiencies. Similarly, it raised concerns about bias in language models, but didn’t take into account recent research to mitigate these issues.”
Dean goes on to claim Gebru made demands which included revealing the identities of the individuals he and Google Research VP of Engineering Megan Kacholia consulted with as part of the paper’s review. If the demands weren’t met, Gebru reportedly said she would leave the company.
It’s a case of one word against another, but – for a company already in the spotlight from both the public and regulators over questionable practices – being seen to fire an ethics researcher for calling out problems is not going to be good PR.
(Image Credit: Timnit Gebru by Kimberly White/Getty Images for TechCrunch under CC BY 2.0 license)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, equality, ethics, Featured, Google, research, Society, timnit gebru






View Comments


Leave a comment




            3 comments on “Google fires ethical AI researcher Timnit Gebru after critical email”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google fires ethical AI researcher Timnit Gebru after critical email,2020-12-04,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['claims', 'email', 'fires', 'research', 'researcher', 'gebru', 'models', 'expo', 'critical', 'ai', 'images', 'google', 'timnit', 'ethical', 'paper', 'large']","Timnit Gebru is considered a pioneer in the field and researched the risks and inequalities found in large language models.
Gebru claims she was fired by Google over an unpublished paper and sending an email critical of the company’s practices.
Some recent cases validate her claims about large models and datasets in general.
Gebru reportedly sent an email to the Google Brain Women and Allies listserv that is “inconsistent with the expectations of a Google manager.”In the email, Gebru expressed her frustration with a perceived lack of progress at Google in hiring women at Google.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
36,https://artificialintelligence-news.com/2020/08/10/darpa-ai-jet-fight-online-covid-19/,"

DARPA’s AI-powered jet fight will be held virtually due to COVID-19




 






By Ryan Daws |
        August 10, 2020                    | TechForge Media

                            Categories:
                                    Government,
                                    Machine Learning,
                                    Military,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




An upcoming event to display and test AI-powered jet fighters will now be held virtually due to COVID-19.
“We are still excited to see how the AI algorithms perform against each other as well as a Weapons School-trained human and hope that fighter pilots from across the Air Force, Navy, and Marine Corps, as well as military leaders and members of the AI tech community will register and watch online,” said Col. Dan Javorsek, program manager in DARPA’s Strategic Technology Office.
“It’s been amazing to see how far the teams have advanced AI for autonomous dogfighting in less than a year.”
DARPA (Defense Advanced Research Projects Agency) is using the AlphaDogfight Trial event to recruit more AI developers for its Air Combat Evolution (ACE) program.
The upcoming event is the final in a series of three and will finish with a bang as the AI-powered F-16 fighter planes virtually take on a human pilot.
“Regardless of whether the human or machine wins the final dogfight, the AlphaDogfight Trials is all about increasing trust in AI,” Javorsek added.
“If the champion AI earns the respect of an F-16 pilot, we’ll have come one step closer to achieving effective human-machine teaming in air combat, which is the goal of the ACE program.”
The first event was held in November last year with early algorithms:



A second event was held in January this year demonstrating the vast improvements made with the algorithms over a relatively short period of time. The algorithms took on adversaries created by the Johns Hopkins University Applied Physics Lab:



The third and final event will be streamed live from the Applied Physics Lab (APL) from August 18th-20th.
Eight teams will fly against five APL-developed adversary AI algorithms on day one. On day two, teams will fly against each other in a round-robin tournament.
Day three is when things get most exciting, with the top four teams competing in a single-elimination tournament for the AlphaDogfight Trials Championship. The winning team’s AI will then fly against a real F-16 pilot to test the AI’s abilities against a human.
ACE envisions future air combat eventually being conducted without putting human pilots at risk. In the meantime, DARPA hopes the initiative will help improve human pilots’ trust in fighting alongside AI.
Prior registration is required to view the event. Non-US citizens must register prior to August 11th while Americans have until August 17th.
You can register for the event here.
(Image Credit: DARPA)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ace, ai, air force, alphadogfight, artificial intelligence, combat, darpa, f-16, Featured, fighter plane, military, usa






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",DARPA’s AI-powered jet fight will be held virtually due to COVID-19,2020-08-10,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['event', 'human', 'jet', 'covid19', 'teams', 'virtually', 'air', 'algorithms', 'held', 'expo', 'upcoming', 'ai', 'tech', 'register', 'fight', 'aipowered', 'darpas']","An upcoming event to display and test AI-powered jet fighters will now be held virtually due to COVID-19.
The upcoming event is the final in a series of three and will finish with a bang as the AI-powered F-16 fighter planes virtually take on a human pilot.
Eight teams will fly against five APL-developed adversary AI algorithms on day one.
The winning team’s AI will then fly against a real F-16 pilot to test the AI’s abilities against a human.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
37,https://artificialintelligence-news.com/2020/10/13/south-korea-develop-50-types-ai-chips-2030/,"

South Korea wants to develop 50 types of AI chips by 2030




 






By Ryan Daws |
        October 13, 2020                    | TechForge Media

                            Categories:
                                    Government,
                                    Hardware,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




South Korea has set itself the ambitious national target of developing 50 types of AI chips within the next decade.
The country’s ICT ministry made the announcement this week as South Korea positions itself to move beyond its historic foothold in memory chips into artificial intelligence semiconductors.
South Korea is investing heavily in AI; especially in the hardware which makes it possible.
Around one trillion won ($871 million) will be spent on developing next-generation AI chips before 2029. The current plan is to be in a position to produce AI chips nationally by 2022 and build a 3,000-strong army of experts within the decade.
Last year, President Moon Jae-in announced a ‘National Strategy for Artificial Intelligence’ (PDF) and set out his desire for South Korea to lead in the technology.
In a foreword, President Moon Jae-in wrote:
“The era of the Fourth Industrial Revolution is indeed an age in which imagination can change the world. Korea is neither the first country to have ushered in the era of artificial intelligence nor the country with the best AI technology at present. However, the country has people capable of turning their imagination into reality and taking on challenges to pursue novelty.Even in the throes of the 1997 Asian financial crisis, the country led the Internet Revolution and now boasts world-class manufacturing competitiveness, globally unmatched ICT infrastructure and abundant data concerning e-government.If we link artificial intelligence primarily with the sectors in which we’ve accumulated extensive experience and competitiveness, such as manufacturing and semiconductors, we will be able to give birth to the smartest yet most human-like artificial intelligence. The Government will join forces with developers to help them fully utilize their imaginations and turn their ideas into reality.”
South Korea is home to tech giants such as Samsung and SK hynix which continue to offer global innovations. However, it’s understandable South Korea wants to ensure it secures a slice of what will be a lucrative market.
Analysts from McKinsey predict AI chips will generate around $67 billion in revenue by 2025 and capture around 20 percent of all semiconductor demand.
South Korea, for its part, wants to own 20 percent of the global AI chip market by the end of this decade.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, ai chips, artificial intelligence, Featured, government, hardware, south korea






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",South Korea wants to develop 50 types of AI chips by 2030,2020-10-13,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['country', '50', 'develop', 'chips', 'global', 'korea', '2030', 'expo', 'tech', 'ai', 'artificial', 'south', 'intelligence', 'types', 'wants']","South Korea has set itself the ambitious national target of developing 50 types of AI chips within the next decade.
Around one trillion won ($871 million) will be spent on developing next-generation AI chips before 2029.
However, it’s understandable South Korea wants to ensure it secures a slice of what will be a lucrative market.
South Korea, for its part, wants to own 20 percent of the global AI chip market by the end of this decade.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
38,https://artificialintelligence-news.com/2020/10/01/full-stack-ai-solution-singularitynet-ethereum-cardano/,"

Full-stack AI solution SingularityNET switches Ethereum for Cardano




 






By Ryan Daws |
        October 1, 2020                    | TechForge Media

                            Categories:
                                    AGI,
                                    Blockchain,
                                    Developers,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Full-stack AI solution SingularityNET is switching the Ethereum blockchain for peer-reviewed rival Cardano.
SingularityNET is a decentralised AI marketplace which has the ultimate goal of forming the basis for the emergence of the world’s first true Artificial General Intelligence (AGI).
One of the brightest and most respected minds in AI leads the SingularityNET project, Dr Ben Goertzel.
“Current speed and cost issues with the Ethereum blockchain have increased the urgency of exploring alternatives for SingluarityNET’s blockchain underpinning,” says Goertzel.
“The ambitious Ethereum 2.0 design holds promise but the timing of rollout of different aspects of this next-generation Ethereum remains unclear, along with many of the practical particulars.“
SingularityNET claims that Cardano has now reached a level of maturity which makes it possible to port such a complex project to the new blockchain.
Back in August, Goertzel gave a talk at the Cardano Summit on why functional programming – enabled by Cardano’s Haskell and new Plutus languages – is invaluable for blockchain-based AI:



Current AIs in the SingularityNET marketplace are designed for specific, relatively straightforward tasks like image/language processing, time series analysis, and genomics data analysis. The project’s Android SDK has been used for tasks like separating vocals from music in the SongSplitter app.
While useful, these AIs show the current limitations of the technology today. SingularityNET, true to its name, has far more ambitious plans.
The broader vision of SingularityNET is to decentralise AI away from “big tech” and prevent AIs from being siloed so that one AI can outsource work to others and use their specific expertise to solve problems. This will ultimately bring us a step closer to AGI which acts more like a human by seeking help where needed.
In a blog post, SingularityNET provides further technical details about its decision to switch to Cardano:
“There may also be synergies between SingularityNET-Cardano integration and the OpenCog Hyperon initiative, which is focused on creating a more scalable, flexible and usable successor to the current OpenCog AGI R&D platform (which underlies a handful of specialized AI agents currently running on the SingularityNET network).The OpenCog AGI design involves a metagraph knowledge store called the Atomspace, concurrently and cooperatively acted on by a number of different cognitive processes representing different learning and reasoning methods such as probabilistic logic, evolutionary learning, pattern mining and neural pattern recognition. Currently, to integrate OpenCog into SingularityNET, one creates a SingularityNET agent wrapping a whole OpenCog system with its own internal Atomspace and AI-process population.However, in a SingularityNET-on-Cardano approach, it may eventually be possible to take a more decentralized approach in which the Hyperon Atomspace is provided as a service to any SingularityNET agent who needs it, and many of the cognitive processes involved in the Hyperon design are represented as SingularityNET agents that interact with Atomspace via channels set up via SingularityNET protocols. Such an approach would exploit the deep commonalities between the new version of OpenCog’s Atomese language being created for Hyperon and the dependent type based API of APIs under current exploration. The result would be a more fundamentally decentralized approach to AGI design.”
A fascinating interview between Cardano founder Charles Hoskinson and Dr Goertzel can be viewed here:



Cardano vs Ethereum
Ethereum is currently the world’s largest decentralised platform but suffers from slow speeds and increasing transaction costs. A switch to a more efficient and environmentally-friendly Proof-of-Stake consensus is underway which – along with new scaling innovations – should address Ethereum’s issues. However, it’s expected to be several years before Ethereum 2.0 is fully rolled out.
Cardano has observed Ethereum’s problems and is taking its time to address them with a scientific and peer-reviewed approach; which brings legitimacy to the project that will be needed for enterprise adoption.
While it could appear from the outside like Cardano has been lazy and is far behind other projects – after all, it’s yet to even support smart contracts – this is far from the case. Cardano is often ranked top of all blockchain projects for development activity and has continued signing large partnerships.
“Cardano has gone from strength to strength this year, and having the backing of such a prominent organisation only reaffirms this,” comments Hoskinson. 
“SingularityNET is a project we’ve followed for a long time, and we’re excited to see how the Cardano blockchain can help SingularityNET realise its ambitious goals.”   
Smart contracts are due to launch on Cardano in the coming months as part of what it calls its ‘Goguen’ phase. Unlike Ethereum, Cardano is using Proof-of-Stake from the start and won’t have the speed, cost, and scalability problems of the current decentralised platform leader.
Cardano will even become the most decentralised network in the space following the recent successful launch of its ‘Shelley’ upgrade.
On its website, Cardano explains:
“We expect Cardano to be 50-100 times more decentralized than other large blockchain networks, with the incentives scheme designed to reach equilibrium around 1,000 stake pools.Current prominent blockchain networks are often controlled by less than 10 mining pools, exposing them to serious risk of compromise by malicious behavior – something which Cardano avoids with a system inherently designed to encourage greater decentralization.”
We’re already seeing groundbreaking projects like SingularityNET beginning to shift over to Cardano. While it may appear that Cardano has a long way to catch up with Ethereum, it’s worth remembering that – of Ethereum’s close to 3,000 apps – only a minority carry significant value or have many active users.
There is currently around $11 billion “locked up” in Ethereum’s much-vaunted DeFi projects. That’s nothing to be sniffed at, but it only takes some big projects to move to Cardano to put a big dent in Ethereum’s primary use case. It’s also worth remembering the whole space is very young with plenty of growth potential—the global legacy financial system is worth hundreds of trillions of dollars.
While multiple blockchain projects will likely co-exist, Cardano’s ability to “flip” Ethereum is looking more possible than ever.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: agi, ai, artificial general intelligence, artificial intelligence, ben goertzel, blockchain, cardano, charles hoskinson, ethereum, Featured, singularitynet






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Full-stack AI solution SingularityNET switches Ethereum for Cardano,2020-10-01,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['ethereum', 'solution', 'current', 'cardano', 'ethereums', 'projects', 'opencog', 'expo', 'ai', 'switches', 'blockchain', 'fullstack', 'singularitynet']","Full-stack AI solution SingularityNET is switching the Ethereum blockchain for peer-reviewed rival Cardano.
“Current speed and cost issues with the Ethereum blockchain have increased the urgency of exploring alternatives for SingluarityNET’s blockchain underpinning,” says Goertzel.
Unlike Ethereum, Cardano is using Proof-of-Stake from the start and won’t have the speed, cost, and scalability problems of the current decentralised platform leader.
While multiple blockchain projects will likely co-exist, Cardano’s ability to “flip” Ethereum is looking more possible than ever.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
39,https://artificialintelligence-news.com/2020/07/28/musk-predicts-ai-superior-humans-five-years/,"

Musk predicts AI will be superior to humans within five years




 






By Ryan Daws |
        July 28, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Deep Learning,
                                    Ethics,
                                    Machine Learning,
                                    OpenAI,
                                    Regulation,
                                    Reinforcement Learning,
                                    Research,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Elon Musk has made another of his trademark predictions – this time, it’s that AI will be superior to humans within five years.
Musk has been among the most vocal prominent figures in warning about the dangers of artificial intelligence. In 2018, for example, Musk famously warned that AI could become “an immortal dictator from which we would never escape” and that the technology is more dangerous than nuclear weapons.
Speaking in a New York Times interview, Musk said that current trends suggest AI could overtake humans by 2025. However, Musk adds “that doesn’t mean that everything goes to hell in five years. It just means that things get unstable or weird.”
If correct, the latest prediction from Musk would mean the so-called technological singularity – when machine intelligence overtakes human – is set to happen much sooner than other experts predict. Ray Kurzweil, a respected futurist, has previously estimated the aforementioned singularity to occur around 2045.
As the founder of Tesla, SpaceX, and Neuralink – three companies which use AI far more than most – Musk isn’t against the technology, but has called for it to be regulated.
Musk also founded OpenAI back in 2015 with the goal of researching and promoting ethical artificial intelligence. Following disagreements with the company’s direction, Musk left OpenAI in 2018.
Back in February, Musk responded to an MIT Technology Review profile of OpenAI saying that it “should be more open” and that all organisations “developing advanced AI should be regulated, including Tesla.”

OpenAI should be more open imo— Elon Musk (@elonmusk) February 17, 2020

Last year, OpenAI decided not to release a text generator which it believed to have dangerous implications in a world already struggling with fake news and disinformation campaigns.
Two graduates later recreated and released a similar generator to OpenAI’s, with one saying that it “allows everyone to have an important conversation about security, and researchers to help secure against future potential abuses.”
OpenAI has since provided select researchers access to their powerful text generator. The latest version, GPT-3, has been making headlines in recent weeks for the incredible things it can achieve with limited input.

Playing with GPT-3 feels like seeing the future. I’ve gotten it to write songs, stories, press releases, guitar tabs, interviews, essays, technical manuals. It's shockingly good. https://t.co/RvM6Qb3WIx— arram (@arram) July 9, 2020

GPT-3 offers 175 billion parameters compared to GTP-2’s 1.5 billion parameters – which shows the rapid pace of AI advancements. However, Musk’s prediction of the singularity happening within five years perhaps needs to be taken with a pinch of salt.
(Image Credit: Elon Musk by JD Lasica under CC BY 2.0 license)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: adoption, ai, artificial intelligence, elon musk, Featured, future, gpt-3, openai, prediction, singularity, Society






View Comments


Leave a comment




            2 comments on “Musk predicts AI will be superior to humans within five years”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Musk predicts AI will be superior to humans within five years,2020-07-28,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['technology', 'singularity', 'humans', 'things', 'musk', 'superior', 'expo', 'world', 'ai', 'predicts', 'openai', 'generator', 'intelligence']","Elon Musk has made another of his trademark predictions – this time, it’s that AI will be superior to humans within five years.
Speaking in a New York Times interview, Musk said that current trends suggest AI could overtake humans by 2025.
Musk also founded OpenAI back in 2015 with the goal of researching and promoting ethical artificial intelligence.
(Image Credit: Elon Musk by JD Lasica under CC BY 2.0 license)Interested in hearing industry leaders discuss subjects like this?
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
40,https://artificialintelligence-news.com/2020/12/07/nvidia-emulates-images-small-datasets-ai-training/,"

NVIDIA breakthrough emulates images from small datasets for groundbreaking AI training




 






By Ryan Daws |
        December 7, 2020                    | TechForge Media

                            Categories:
                                    Nvidia,
                                    Research,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




NVIDIA’s latest breakthrough emulates new images from existing small datasets with truly groundbreaking potential for AI training.
The company demonstrated its latest AI model using a small dataset – just a fraction of the size typically used for a Generative Adversarial Network (GAN) – of artwork from the Metropolitan Museum of Art.
From the dataset, NVIDIA’s AI was able to create new images which replicate the style of the original artist’s work. These images can then be used to help train further AI models.



The AI achieved this impressive feat by applying a breakthrough neural network training technique similar to the popular NVIDIA StyleGAN2 model. 
The technique is called Adaptive Discriminator Augmentation (ADA) and NVIDIA claims that it reduces the number of training images required by 10-20x while still getting great results.
David Luebke, VP of Graphics Research at NVIDIA, said:
“These results mean people can use GANs to tackle problems where vast quantities of data are too time-consuming or difficult to obtain.I can’t wait to see what artists, medical experts and researchers use it for.”
Healthcare is a particularly exciting field where NVIDIA’s research could be applied. For example, it could help to create cancer histology images to train other AI models.
The breakthrough will help with the issues around most current datasets.
Large datasets are often required for AI training but aren’t always available. On the other hand, large datasets are difficult to ensure their content is suitable and does not unintentionally lead to algorithmic bias.
Earlier this year, MIT was forced to remove a large dataset called 80 Million Tiny Images. The dataset is popular for training AIs but was found to contain images labelled with racist, misogynistic, and other unacceptable terms.
A statement on MIT’s website claims it was unaware of the offensive labels and they were “a consequence of the automated data collection procedure that relied on nouns from WordNet.”
The statement goes on to explain the 80 million images contained in the dataset – with sizes of just 32×32 pixels – meant that manual inspection would be almost impossible and couldn’t guarantee all offensive images would be removed.
By starting with a small dataset that can be feasibly checked manually, a technique like NVIDIA’s ADA could be used to create new images which emulate the originals and can scale up to the required size for training AI models.
In a blog post, NVIDIA wrote:
“It typically takes 50,000 to 100,000 training images to train a high-quality GAN. But in many cases, researchers simply don’t have tens or hundreds of thousands of sample images at their disposal.With just a couple thousand images for training, many GANs would falter at producing realistic results. This problem, called overfitting, occurs when the discriminator simply memorizes the training images and fails to provide useful feedback to the generator.”
You can find NVIDIA’s full research paper here (PDF). The paper is being presented at this year’s NeurIPS conference as one of a record 28 NVIDIA Research papers accepted to the prestigious conference.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: Adaptive Discriminator Augmentation, ai, ai model, artificial intelligence, dataset, Featured, GAN, Generative Adversarial Network, Nvidia, training






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",NVIDIA breakthrough emulates images from small datasets for groundbreaking AI training,2020-12-07,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['breakthrough', 'train', 'research', 'small', 'datasets', 'groundbreaking', 'dataset', 'emulates', 'expo', 'images', 'ai', 'nvidias', 'nvidia', 'training', 'used']","NVIDIA’s latest breakthrough emulates new images from existing small datasets with truly groundbreaking potential for AI training.
From the dataset, NVIDIA’s AI was able to create new images which replicate the style of the original artist’s work.
Large datasets are often required for AI training but aren’t always available.
In a blog post, NVIDIA wrote:“It typically takes 50,000 to 100,000 training images to train a high-quality GAN.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
41,https://artificialintelligence-news.com/2020/03/06/clearview-ai-lawyer-common-law-has-never-recognised-a-right-to-privacy-for-your-face/,"

Clearview AI lawyer: ‘Common law has never recognised a right to privacy for your face’




 






By Ryan Daws |
        March 6, 2020                    | TechForge Media

                            Categories:
                                    Face Recognition,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A lawyer for controversial facial recognition startup Clearview AI says your face has no right to privacy in common law.
Clearview’s facial recognition system is used by over 600 law 
enforcement agencies and a recent leak revealed its client list also 
includes the likes of Best Buy and Macy’s.
The system has been criticised due to its method of scraping the 
internet to gather images and storing them in a database. Privacy 
activists say the people in those images never gave consent.
“Common law has never recognised a right to privacy for your face,” 
Clearview AI lawyer Tor Ekeland said in a recent interview with CoinDesk. “It’s kind of a bizarre argument to make because [your face is the] most public thing out there.”
It’s a fair point, but it’s not exactly comforting knowing that your 
face could be stored on a database somewhere without giving explicit 
permission for it to be. Furthermore, Clearview AI isn’t exactly gaining
 a reputation for being a trustworthy custodian of people’s data.
Many people criticised Clearview AI’s response – or, lack thereof – 
to their recent data breach. The only response was the following 
statement posted by Ekeland: “Security is Clearview’s top priority. 
Unfortunately, data breaches are part of life in the 21st century. Our 
servers were never accessed. We patched the flaw, and continue to work 
to strengthen our security.”
Ekeland gained himself a reputation as “The Troll’s Lawyer,” a nickname given by Wired, for his past clients.
Among the first clients of Ekeland was self-described neo-Nazi troll 
Andrew Auernheimer who downloaded 114,000 email addresses from a public 
server without security on it. Ekeland defended Auernheimer by 
criticising the Computer Fraud and Abuse Act (CFAA) and saying that it 
fails to meet a reasonable standard of defining what’s prohibited.
Ekeland now expects the hacker responsible for leaking Clearview AI’s
 clients to be prosecuted under the CFAA. He argues that, while 
individuals like Auernheimer and companies like Clearview AI only 
accessed information left public on the web, whoever breached Clearview 
AI bypassed security to access something without permission.
Regardless, Clearview AI has now got Congress’ attention.
In a letter
 (PDF) to Clearview CEO Hoan Ton-That, US House of Representatives’ 
Committee on Science, Space &Technology chairwoman Eddie Bernice 
Johnson, and ranking member Frank D. Lucas, wrote:
“Clearview AI’s work appears 
subject to very little government oversight, despite the serious privacy
 questions raised by the intended use of Clearview AI’s technology. 
These concerns are compounded immensely by the knowledge that the firm 
has now been the subject of a successful hacking operation.”
The letter calls on Mr Ton-That to provide written answers to six questions by March 17th.






Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.





 






View Comments


Leave a comment




            One comment on “Clearview AI lawyer: ‘Common law has never recognised a right to privacy for your face’”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Clearview AI lawyer: ‘Common law has never recognised a right to privacy for your face’,2020-03-06,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['face', 'ais', 'public', 'security', 'recent', 'clearview', 'recognised', 'common', 'privacy', 'right', 'ai', 'law', 'lawyer', 'ekeland']","A lawyer for controversial facial recognition startup Clearview AI says your face has no right to privacy in common law.
“Common law has never recognised a right to privacy for your face,” Clearview AI lawyer Tor Ekeland said in a recent interview with CoinDesk.
Furthermore, Clearview AI isn’t exactly gaining a reputation for being a trustworthy custodian of people’s data.
He argues that, while individuals like Auernheimer and companies like Clearview AI only accessed information left public on the web, whoever breached Clearview AI bypassed security to access something without permission.
Regardless, Clearview AI has now got Congress’ attention.",AInews
42,https://artificialintelligence-news.com/2020/09/30/ai-helping-telcos-cope-pandemic-demand-surge/,"

AI is helping mobile operators to cope with pandemic demand




 






By Ryan Daws |
        September 30, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Machine Learning,
                                    Mobile,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Artificial intelligence is helping telecoms operators to boost the RAN capacity of their 4G networks by 15 percent.
More people than ever are relying on telecoms networks to work, play, and stay connected during the pandemic. Operators are doing all they can to ensure their existing networks have enough capacity to cope with demand.
Gorkem Yigit, Principal Analyst at Analysys Mason, said:
“Video streaming continues to experience high year on year growth and that has been exacerbated by the pandemic and resulting lock-downs,Yes, 5G grabs the spotlight, but 4G is carrying the brunt of this traffic. So, while investment in 5G infrastructure continues, operators need intelligent ways to maximize and extend existing 4G network capabilities in the short to medium term – keeping their CAPEX to a minimum.”
8 out of 10 of the world’s largest operator groups have deployed traffic management technology from the Openwave subsidiary of Swedish firm Enea. Many of these have since upgraded to include machine learning capabilities.
Openwave claims that, based on its figures, some operators faced a 90 percent surge in peak throughput during lockdowns.
Machine learning is helping to predict and identify congestion in the RAN (Radio Access Network) which resides between user equipment such as wireless devices and an operator’s core network.
John Giere, President of Enea Openwave, commented:
“Conventional mobile data management requires manual configuration and network investment – it is no longer fit for purpose.Machine Learning has given existing 4G networks the shot in the arm they needed. It can work dynamically without external probes or changes to the RAN, delivering additional capacity at a time that operators most need it.” 
The use of machine learning has increased operators’ 4G RAN capacity by 15 percent in congested locations—providing further evidence of how AI technology can be used to quickly tackle real-world problems.
(Photo by Adrian Schwarz on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: 4g, ai, artificial intelligence, Featured, lte, machine learning, mobile, openwave, ran, telecoms






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI is helping mobile operators to cope with pandemic demand,2020-09-30,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['helping', 'existing', 'cope', 'mobile', 'learning', 'operators', 'pandemic', '4g', 'expo', 'ran', 'ai', 'demand', 'capacity', 'networks', 'network', 'machine']","Artificial intelligence is helping telecoms operators to boost the RAN capacity of their 4G networks by 15 percent.
Operators are doing all they can to ensure their existing networks have enough capacity to cope with demand.
Many of these have since upgraded to include machine learning capabilities.
Machine Learning has given existing 4G networks the shot in the arm they needed.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
43,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
44,https://artificialintelligence-news.com/2020/04/03/google-latest-ai-prevent-deaths-incorrect-prescriptions/,"

Google’s latest AI could prevent deaths caused by incorrect prescriptions




 






By Ryan Daws |
        April 3, 2020                    | TechForge Media

                            Categories:
                                    Google,
                                    Healthcare,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A new AI system developed by researchers from Google and the University of California could prevent deaths caused by incorrect prescriptions.
While quite rare, prescriptions that are incorrect – or react badly to a patient’s existing medications – can result in hospitalisation or even death.
In a blog post today, Alvin Rajkomar MD, Research Scientist and Eyal Oren PhD, Product Manager, Google AI, set out their work on using AI for medical predictions.
The AI is able to predict which conditions a patient is being treated for based on certain parameters. “For example, if a doctor prescribed ceftriaxone and doxycycline for a patient with an elevated temperature, fever and cough, the model could identify these as signals that the patient was being treated for pneumonia,” the researchers wrote.
In the future, an AI could step in if a medication that’s being prescribed looks incorrect for a patient with a specific condition in their current situation.
“While no doctor, nurse, or pharmacist wants to make a mistake that harms a patient, research shows that 2% of hospitalized patients experience serious preventable medication-related incidents that can be life-threatening, cause permanent harm, or result in death,” the researchers wrote.
“However, determining which medications are appropriate for any given patient at any given time is complex — doctors and pharmacists train for years before acquiring the skill.”
The AI was trained on an anonymised data set featuring around three million records of medications issued from over 100,000 hospitalisations.
In their paper, the researchers wrote:
“Patient records vary significantly in length and density of data points (e.g., vital sign measurements in an intensive care unit vs outpatient clinic), so we formulated three deep learning neural network model architectures that take advantage of such data in different ways: one based on recurrent neural networks (long short-term memory (LSTM)), one on an attention-based TANN, and one on a neural network with boosted time-based decision stumps.We trained each architecture (three different ones) on each task (four tasks) and multiple time points (e.g., before admission, at admission, 24 h after admission and at discharge), but the results of each architecture were combined using ensembling.”
You can find the full paper in science journal Nature here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, Featured, Google, health, healthcare, medicine, prescriptions






View Comments


Leave a comment




            One comment on “Google’s latest AI could prevent deaths caused by incorrect prescriptions”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google’s latest AI could prevent deaths caused by incorrect prescriptions,2020-04-03,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['prevent', 'data', 'deaths', 'using', 'googles', 'researchers', 'prescriptions', 'incorrect', 'expo', 'latest', 'ai', 'patient', 'medications', 'admission', 'caused', 'neural']","A new AI system developed by researchers from Google and the University of California could prevent deaths caused by incorrect prescriptions.
While quite rare, prescriptions that are incorrect – or react badly to a patient’s existing medications – can result in hospitalisation or even death.
In a blog post today, Alvin Rajkomar MD, Research Scientist and Eyal Oren PhD, Product Manager, Google AI, set out their work on using AI for medical predictions.
The AI is able to predict which conditions a patient is being treated for based on certain parameters.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
45,https://artificialintelligence-news.com/2020/10/27/ibm-study-uptake-satisfaction-ai-chatbots/,"

IBM study highlights rapid uptake and satisfaction with AI chatbots




 






By Ryan Daws |
        October 27, 2020                    | TechForge Media

                            Categories:
                                    Bots,
                                    IBM,
                                    Society,
                                    Virtual Assistants,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A study by IBM released this week highlights the rapid uptake of AI chatbots in addition to increasing customer satisfaction.
Most of us are hardwired to hate not speaking directly to a human when we have a problem—following years of irritating voicemail systems. However, perhaps the only thing worse is being on hold for an uncertain amount of time due to overwhelmed call centres.
Chatbots have come a long way and can now quickly handle most queries within minutes. Where a human is required, the reduced demand through using virtual agent technology (VAT) means customers can get the assistance they need more quickly.

The COVID-19 pandemic has greatly increased the adoption of VAT as businesses seek to maintain customer service through such a challenging time.
According to IBM’s study, 99 percent of organisations reported increased customer satisfaction by integrating virtual agents. Human agents also report increased satisfaction and IBM says those “who feel valued and empowered with the proper tools and support are more likely to deliver a better experience to customers.”
68 percent of leaders cite improving the human agent experience as being among their key reasons for adopting VAT. There’s also economic incentive, with the cost of replacing a dissatisfied agent who leaves a business estimated at as much as 33 percent of the exiting employee’s salary.
IBM claims that VAT performance in the past has only been studied through individual case studies. The company set out, alongside Oxford Economics, to change that by surveying 1,005 respondents from companies using VAT daily.
Businesses wondering whether virtual assistants are worth the investment may be interested to know that 96 percent of the respondents “exceeded, achieved, or expect to achieve” their anticipated return.
On average, companies which have implemented VAT have increased their revenue by three percent.IBM is one of the leading providers of chatbots through its Watson Assistant solution. While there’s little reason to doubt the claims made in the report, it’s worth keeping in mind that it’s not entirely unbiased.
Watson Assistant has gone from strength-to-strength and appears to have been among the few things which benefited from the pandemic. Between February and August, Watson Assistant usage increased by 65 percent.
You can download a full copy of IBM’s report here.
(Photo by Volodymyr Hryshchenko on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, assistant, bots, chatbots, Featured, ibm, report, research, study, virtual assistant, watson, watson assistant






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",IBM study highlights rapid uptake and satisfaction with AI chatbots,2020-10-27,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['human', 'customer', 'highlights', 'virtual', 'ibm', 'uptake', 'assistant', 'worth', 'vat', 'satisfaction', 'expo', 'agent', 'ai', 'increased', 'study', 'rapid', 'report', 'chatbots']","A study by IBM released this week highlights the rapid uptake of AI chatbots in addition to increasing customer satisfaction.
Where a human is required, the reduced demand through using virtual agent technology (VAT) means customers can get the assistance they need more quickly.
According to IBM’s study, 99 percent of organisations reported increased customer satisfaction by integrating virtual agents.
While there’s little reason to doubt the claims made in the report, it’s worth keeping in mind that it’s not entirely unbiased.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
46,https://artificialintelligence-news.com/2020/11/17/ai-patients-more-rest-reducing-staff-workload/,"

AI helps patients to get more rest while reducing staff workload




 






By Ryan Daws |
        November 17, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Research,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A team from Feinstein Institutes for Research thinks AI could be key to helping patients get more rest while reducing the burden on healthcare staff.
Everyone knows how important adequate sleep is for recovery. However, patients in pain – or just insomniacs like me – can struggle to get the sleep they need.
“Rest is a critical element to a patient’s care, and it has been well-documented that disrupted sleep is a common complaint that could delay discharge and recovery,” said Theodoros Zanos, Assistant Professor at Feinstein Institutes’ Institute of Bioelectronic Medicine.
When a patient finally gets some shut-eye, the last thing they want is to be woken up to have their vitals checked—but such measurements are, well, vital.
In a paper published in Nature Partner Journals, the researchers detailed how they developed a deep-learning predictive tool which predicts a patient’s stability overnight. This prevents multiple unnecessary checks being carried out.
Vital sign measurements from 2.13 million patient visits at Northwell Health hospitals in New York between 2012 and 2019 were used to train the AI. Data included heart rate, systolic blood pressure, body temperature, respiratory rate, and age. A total of 24.3 million vital signs were used.
When tested, the AI misdiagnosed just two of 10,000 patients in overnight stays. The researchers noted how nurses on their usual rounds would be able to account for the two misdiagnosed cases.
According to the paper, around 20-35 percent of a nurse’s time is spent keeping records of patients’ vitals. Around 10 percent of their time is spent collecting vitals. On average, a nurse currently has to collect a patient’s vitals every four to five hours.
With that in mind, it’s little wonder medical staff feel so overburdened and stressed. These people want to provide the best care they can but only have two hands. Using AI to free up more time for their heroic duties while simultaneously improving patient care can only be a good thing.
The AI tool is being rolled out across several of Northwell Health’s hospitals.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, Featured, Feinstein Institutes for Research, healthcare, hospital, paper, patient care, research, study






View Comments


Leave a comment




            One comment on “AI helps patients to get more rest while reducing staff workload”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI helps patients to get more rest while reducing staff workload,2020-11-17,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['workload', 'tool', 'spent', 'reducing', 'helps', 'expo', 'ai', 'sleep', 'care', 'rest', 'patient', 'tech', 'patients', 'vitals', 'staff']","A team from Feinstein Institutes for Research thinks AI could be key to helping patients get more rest while reducing the burden on healthcare staff.
According to the paper, around 20-35 percent of a nurse’s time is spent keeping records of patients’ vitals.
On average, a nurse currently has to collect a patient’s vitals every four to five hours.
The AI tool is being rolled out across several of Northwell Health’s hospitals.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
47,https://artificialintelligence-news.com/2020/08/28/how-can-ai-powered-humanitarian-engineering-tackle-the-biggest-threats-facing-our-planet/,"

How can AI-powered humanitarian engineering tackle the biggest threats facing our planet?




 






By Sampathkumar Veeraraghavan |
        August 28, 2020
https://sight.ieee.org/ 
                            Categories:
                                    Agriculture,
                                    Education,
                                    Ethics,
                                    Government,
                                    Machine Learning,
                                    Research,
                                    Society,
                        


Sampathkumar Veeraraghavan currently serves as the global chairman of the IEEE Special Interest Group on Humanitarian Technology (SIGHT) managing the portfolio of sustainable development programs globally. He serves as an expert in the Broadband commission working group on school connectivity that is co-chaired by UNESCO, UNICEF and ITU to drive “GIGA’, a Global School Connectivity Initiative. Currently, he is the founder and president of the technology-based humanitarian program “The Brahmam”, that aims to deliver next generation social innovations to achieve SDGs and benefit the marginalized communities globally.

Sampathkumar is the recipient of the 2020 IEEE Theodore W.Hissey Outstanding Young Professional Award “for inspiring leadership, exemplary innovations, and pioneering contributions to addressing global challenges through technology-driven IEEE humanitarian programs.""




Humanitarian engineering programs bring together engineers, policy makers, non-profit organisations, and local communities to leverage technology for the greater good of humanity.
The intersection of technology, community, and sustainability offers a plethora of opportunities to innovate. We still live in an era where millions of people are under extreme poverty, lacking access to clean water, basic sanitation, electricity, internet, quality education, and healthcare.
Clearly, we need global solutions to tackle the grandest challenges facing our planet. So how can artificial intelligence (AI) assist in addressing key humanitarian and sustainable development challenges?
To begin with, the United Nations Sustainable Development Goals (SDGs) represent a collection of 17 global goals that aim to address pressing global challenges, achieve inclusive development, and foster peace and prosperity in a sustainable manner by 2030. AI enables the building of smart systems that imitate human intelligence to solve real-world problems. 
Recent advancements in AI have radically changed the way we think, live, and collaborate. Our daily lives are centred around AI-powered solutions with smart speakers playing wakeup alarms, smart watches tracking steps in our morning walk, smart refrigerators recommending breakfast recipes, smart TVs providing personalised content recommendations, and navigation mobile apps recommending the best route based on real-time traffic. Clearly, the age of AI is here. How can we leverage this transformative technology to amplify the impact for social good?
Accelerating AI-powered social innovations
AI core capabilities like machine learning (ML), computer vision, natural language understanding, and speech recognition offer new approaches to address humanitarian challenges and amplify the positive impact on underserved communities. ML enables machines to process massive amounts of data, interconnect underlying patterns, and derive meaningful insights for decision making. ML techniques like deep learning offer the powerful capability to create sophisticated AI models based on artificial neural networks. 
Such models can be used for numerous real-world situations, like pandemic forecasting. AI tools can model and predict the spread of outbreaks like Covid-19 in low-resource settings using recent outbreak trends, treatment data, and travel history. This will help governmental and healthcare agencies to identify high-risk areas, manage demand and supply of essential medical supplies, and formulate localised remedial measures to control an outbreak.
Computer vision techniques process visual information in digital images and videos to generate valuable inference. Trained AI models assist medical practitioners to examine clinical images and identify hidden patterns of malignant tumors supporting expediated decision-making and a treatment plan for patients. Most recently, smart speakers have extended their conversational AI capabilities for healthcare use cases like chronic illness management, prescription ordering, and urgent-care appointments. 
This advancement opens up the possibility to drive healthcare innovations that will break down access barriers and deliver quality healthcare to a marginalised population. Similarly, global educational programs aimed to connect the digitally unconnected can leverage satellite images and ML algorithms to map school locations. AI-powered learning products are increasingly launched to provide personalised experiences to train young children in math and science. 
The convergence of AI with the Internet of Things (IoT) facilitates rapid development of meaningful solutions for agriculture to monitor soil health, assess crop damage, and optimise use of pesticides. This empowers local farmers to model different scenarios and choose the right crop that is likely to maximise the quality and yield, and it contributes toward zero hunger and economic empowerment SDGs.
Decoding best program practices
To deliver high social impact, AI-driven humanitarian programs should follow a “bottom-up” approach. One should always work backwards from needs of the end-user, drive clarity on the targeted community/user, their major pain points, the opportunity to innovate, and expected user experience. 
Most importantly, always check whether AI is relevant to the problem at hand or investigate if a meaningful alternative approach exists. Understand how an AI-powered solution will deliver value to various stakeholders involved and positively contribute toward achieving SDG for local communities. Define a suite of metrics to measure various dimensions of program success. Data acquisition is central to building robust AI models that require access to meaningful and quality data. 
Delivering effective AI solutions to the humanitarian landscape requires a clear understanding of the data required and relevant sources to acquire them. For instance, satellite images, electronic health records, census data, educational records, and public datasets are used to solve problems in education, healthcare, and climate change. Partnership with key field players is important for addressing data gaps for domains with sparsely available data.
Responsible use of AI in humanitarian programs can be achieved by enforcing standards and best practices to implement fairness, inclusiveness, security, and privacy controls. Always check models and datasets for bias and negative experiences. Techniques like data visualisation and clustering can evaluate a dataset’s distribution for fair representation of various stakeholders’ dimensions. Routine updates to training and testing datasets is essential to fairly account for diversity in users’ growing needs and usage patterns. Safeguard sensitive user information by implementing privacy controls like encrypting user data at rest and in transit, limit access to user data and critical production systems based on least-privilege access control, and enforce data retention and deletion policy on user datasets. Implement a robust threat model to handle possible system attacks and routine checks on infrastructure security vulnerabilities.
To conclude, AI-powered humanitarian programs offer a transformative opportunity to advance social innovations and build a better tomorrow for the benefit of humanity.
Photo by Elena Mozhvilo on Unsplash

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",How can AI-powered humanitarian engineering tackle the biggest threats facing our planet?,2020-08-28,"['Sampathkumar Veeraraghavan', 'Sampathkumar Veeraraghavan Currently Serves As The Global Chairman Of The Ieee Special Interest Group On Humanitarian Technology', 'Sight', 'Managing The Portfolio Of Sustainable Development Programs Globally. He Serves As An Expert In The Broadband Commission Working Group On School Connectivity That Is Co-Chaired Unesco', 'Unicef', 'Itu To Drive', 'Giga', 'A Global School Connectivity Initiative. Currently', 'He Is The Founder', 'President Of The Technology-Based Humanitarian Program']","['data', 'facing', 'global', 'programs', 'biggest', 'healthcare', 'planet', 'engineering', 'threats', 'smart', 'models', 'social', 'ai', 'user', 'aipowered', 'tackle', 'humanitarian']","Humanitarian engineering programs bring together engineers, policy makers, non-profit organisations, and local communities to leverage technology for the greater good of humanity.
ML techniques like deep learning offer the powerful capability to create sophisticated AI models based on artificial neural networks.
Decoding best program practicesTo deliver high social impact, AI-driven humanitarian programs should follow a “bottom-up” approach.
Safeguard sensitive user information by implementing privacy controls like encrypting user data at rest and in transit, limit access to user data and critical production systems based on least-privilege access control, and enforce data retention and deletion policy on user datasets.
To conclude, AI-powered humanitarian programs offer a transformative opportunity to advance social innovations and build a better tomorrow for the benefit of humanity.",AInews
48,https://artificialintelligence-news.com/2021/01/29/strategy-analytics-defines-path-to-ai-vendor-and-buyer-success-in-new-report/,"

Strategy Analytics defines path to AI vendor and buyer success in new report




 



 

By James Bourne |
        January 29, 2021                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Adoption,
                                    Enterprise,
                                    Research,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




Research firm Strategy Analytics has argued in a new report that both vendors of AI products and their users can succeed with a ‘thorough understanding’ of customer journeys.
The report, ‘Defining the AI Buyer Journey’, aims to take a comprehensive view of the ‘who, what, why and how long’ issues in the buyer journey, from paths to selection, paths to adoption, and implementation.
The goal is to avoid all ‘AI-washing’ where possible. This can occur on both the vendor side – misleadingly slapping the term AI or ML on an offering – and for users, misunderstanding the business capabilities required. “It is critical to look beneath the label at the nature of the activity that is involved,” Strategy puts it.
As a result, the report explores three questions:
Who is the interested party or prospect – such as line of business, or a functional group within an organisation, or IT?What is being purchased – a specific application or an AI platform?Why is the capability or application software being purchased?
All obvious lines of enquiry when doing due diligence, one may have thought – but organisations at different stages of the buyer journey may have conflicting priorities.
Strategy Analytics’ analysis indicates that just under a third (30%) of companies actively exploring AI solutions fall into the ‘early adopter’ category, with another 30% defined as ‘committed AI prospects’ a little further back. Of the early adopters, two thirds are adopting an applications development platform, compared to a third looking for application-specific software.
The initial journey usually progresses in a similar fashion. Naturally, addressing a practical problem and identifying a business case is ‘frequently the first milestone’ in the buyer journey, with initial interest turning to introductory exposure after around six months. Following this – eschewing budget for now – around 30% of adopters begin the decision process for both a potential application and an approach to development.
While this is an average position with early adopters, it has to be noted that other companies will not be as steadfast in their strategies. The report also notes that drivers for adoption and the journey for a specific company varies significantly.
Yet the report can be seen as a way to provide directional insights on buyer journeys and adoption paths, also covering drivers for AI application adoption, and business development.
“While AI is not exactly a nascent market, it is now realising more of its potential than ever before, which in turn is contributing to its significant growth,” said Harvey Cohen, president of Strategy Analytics and author of the report. “Establishing goals and a framework to achieve them is paramount to success, based on extensive project work and research performed by Strategy Analytics.”
You can read a report overview here (free, account required).
Photo by Pop & Zebra on Unsplash

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Strategy Analytics defines path to AI vendor and buyer success in new report,2021-01-29,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['defines', 'business', 'vendor', 'adoption', 'application', 'analytics', 'success', 'expo', 'ai', 'paths', 'buyer', 'path', 'journey', 'report', 'strategy']","Research firm Strategy Analytics has argued in a new report that both vendors of AI products and their users can succeed with a ‘thorough understanding’ of customer journeys.
The report, ‘Defining the AI Buyer Journey’, aims to take a comprehensive view of the ‘who, what, why and how long’ issues in the buyer journey, from paths to selection, paths to adoption, and implementation.
All obvious lines of enquiry when doing due diligence, one may have thought – but organisations at different stages of the buyer journey may have conflicting priorities.
Yet the report can be seen as a way to provide directional insights on buyer journeys and adoption paths, also covering drivers for AI application adoption, and business development.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
49,https://artificialintelligence-news.com/2020/07/29/researchers-create-ai-bot-protect-identities-blm-protesters/,"

Researchers create AI bot to protect the identities of BLM protesters




 






By Ryan Daws |
        July 29, 2020                    | TechForge Media

                            Categories:
                                    Bots,
                                    Face Recognition,
                                    Law Enforcement,
                                    Privacy,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers from Stanford have created an AI-powered bot to automatically cover up the faces of Black Lives Matter protesters in photos.
Everyone should have the right to protest. And, if done legally, to do so without fear of having things like their future job prospects ruined because they’ve been snapped at a demonstration – from which a select few may have gone on to do criminal acts such as arson and looting.
With images from the protests being widely shared on social media to raise awareness, police have been using the opportunity to add the people featured within them to facial recognition databases.
“Over the past weeks, we have seen an increasing number of arrests at BLM protests, with images circulating around the web enabling automatic identification of those individuals and subsequent arrests to hamper protest activity,” the researchers explain.
Software has been available for some time to blur faces, but recent AI advancements have proved that it’s possible to deblur such images.
Researchers from Stanford Machine Learning set out to develop an automated tool which prevents the real identity of those in an image from being revealed.
The result of their work is BLMPrivacyBot:

Need to protect protestors? Tweet at me to anonymize BLM protest photos! Original by @Official_TNIJ pic.twitter.com/Cx4mtvRlYo— #BlackLivesMatter (@BLMPrivacyBot) July 15, 2020

Rather than blur the faces, the bot automatically covers them up with the black fist emoji which has become synonymous with the Black Lives Matter movement. The researchers hope such a solution will be built-in to social media platforms, but admit it’s unlikely.
The researchers trained the model for their AI bot on a dataset consisting of around 1.2 million people called QNRF. However, they warn it’s not foolproof as an individual could be identified through other means such as what clothing they’re wearing.
To use the BLMPrivacyBot, you can either send an image to its Twitter handle or upload a photo to the web interface here. The open source repo is available if you want to look at the inner workings.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, black lives matter, blm, bot, face recognition, facial recognition, privacy, protest, surveillance






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Researchers create AI bot to protect the identities of BLM protesters,2020-07-29,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['create', 'faces', 'researchers', 'protesters', 'media', 'protest', 'black', 'expo', 'blm', 'ai', 'web', 'identities', 'tech', 'bot', 'protect']","Researchers from Stanford have created an AI-powered bot to automatically cover up the faces of Black Lives Matter protesters in photos.
Software has been available for some time to blur faces, but recent AI advancements have proved that it’s possible to deblur such images.
The researchers hope such a solution will be built-in to social media platforms, but admit it’s unlikely.
The researchers trained the model for their AI bot on a dataset consisting of around 1.2 million people called QNRF.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
50,https://artificialintelligence-news.com/2020/05/26/jack-dorsey-andrew-yang-ai-programming-jobs/,"

Jack Dorsey tells Andrew Yang that AI is ‘coming for programming jobs’




 






By Ryan Daws |
        May 26, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Developers,
                                    Ethics,
                                    Government,
                                    Society,
                                    TECHEX,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Twitter CEO Jack Dorsey recently told former 2020 US presidential candidate Andrew Yang that AI “is coming for programming jobs”.
There is still fierce debate about the impact that artificial intelligence will have on jobs. Some believe that AI will replace many jobs and lead to the requirement of a Universal Basic Income (UBI), while others claim it will primarily offer assistance to help workers be more productive.
Dorsey is a respected technologist with a deep understanding of emerging technologies. Aside from creating Twitter, he also founded Square which is currently pushing the mass adoption of blockchain-based digital currencies such as Bitcoin and Ethereum.
Yang was seen as the presidential candidate for technologists before he suspended his campaign in February, with The New York Times calling him “The Internet’s Favorite Candidate” and his campaign was noted for its “tech-friendly” nature. The entrepreneur, lawyer, and philanthropist founded Venture for America, a non-profit which aimed to create jobs in cities most affected by the Great Recession. In March, Yang announced the creation of the Humanity Forward non-profit which is dedicated to promoting the ideas during his presidential campaign.
Jobs are now very much at threat once again; with the coronavirus wiping out all job gains since the Great Recession over a period of just four weeks. If emerging technologies such as AI do pose a risk to jobs, it could only compound the problem further.
In an episode of the Yang Speaks podcast, Dorsey warns that AI will pose a particular threat to entry-level programming jobs. However, even seasoned programmers will have their worth devalued.



“A lot of the goals of machine learning and deep learning is to write the software itself over time so a lot of entry-level programming jobs will just not be as relevant anymore,” Dorsey told Yang.
Yang is a proponent of a UBI. Dorsey said that such free cash payments could provide a “floor” for if people lose their jobs due to automation. Such free cash wouldn’t allow for luxurious items and holidays, but would ensure that people can keep a roof over their heads and food on the table.
UBI would provide workers with “peace of mind” that they can “feed their children while they are learning how to transition into this new world,” Dorsey explains.
Critics of UBI argue that such a permanent scheme would be expensive.
The UK is finding that out to some extent currently with its coronavirus furlough scheme. Under the scheme, the state will pay 80 percent of a worker’s salary to prevent job losses during the crisis. However, it’s costing approximately £14 billion per month and is expected to be wound down in the coming months due to being unsustainable.
However, some kind of UBI system is appearing increasingly needed.
In November, the Brookings Institute published a report (PDF) which highlights the risk AI poses to jobs. 
“Workers with graduate or professional degrees will be almost four times as exposed to AI as workers with just a high school degree. Holders of bachelor’s degrees will be the most exposed by education level, more than five times as exposed to AI than workers with just a high school degree,” the paper says.
In their analysis, the Brookings Institute ranked professions by their risk from AI exposure. Computer programmers ranked third, backing Dorsey’s prediction, just behind market research analysts and sales managers.
(Image Credit: Jack Dorsey by Thierry Ehrmann under CC BY 2.0 license)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, andrew yang, artificial intelligence, careers, Featured, impact, jack dorsey, jobs, programming, report, research, universal basic income, yang speaks






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Jack Dorsey tells Andrew Yang that AI is ‘coming for programming jobs’,2020-05-26,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['coming', 'programming', 'risk', 'ubi', 'dorsey', 'times', 'workers', 'expo', 'jack', 'ai', 'andrew', 'scheme', 'yang', 'tells', 'jobs']","Twitter CEO Jack Dorsey recently told former 2020 US presidential candidate Andrew Yang that AI “is coming for programming jobs”.
If emerging technologies such as AI do pose a risk to jobs, it could only compound the problem further.
In an episode of the Yang Speaks podcast, Dorsey warns that AI will pose a particular threat to entry-level programming jobs.
In November, the Brookings Institute published a report (PDF) which highlights the risk AI poses to jobs.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
51,https://artificialintelligence-news.com/2021/02/09/opinion-how-can-public-sector-use-ai-identify-fraud/,"

How can the public sector use AI to identify fraud?




 






By Rachel Kirkham |
        February 9, 2021                    | MindBridge
https://www.mindbridge.ai/ 
                            Categories:
                                    Fintech,
                                    Society,
                        


Rachel was the former head of data analytics research at the UK National Audit Office and is now the director of AI solutions at MindBridge.




Accountability and transparency are essential for public sector audits. The public sector is under a watchful eye to ensure finances are being managed ethically and appropriately, whilst also being responsible for providing early warnings of financial pressures or failures. Due to COVID measures, there is currently a huge volume of funds being distributed to individuals or companies from the public ‘purse’, placing increased pressure on audits to ensure the funds are being used for their intended purpose. 
Using AI, public sector organisations can both identify and rectify potential issues before they become a problem, saving valuable money in the process and ensuring these precious public funds are being administered and used effectively. 
Introducing technology 
The latest warnings from the National Crime Agency suggested that coronavirus-related fraud could end up costing the taxpayer £4bn as a result of criminals seeking to capitalise on the COVID crisis. Fraudulent activities are ranging from an increase in company registrations to benefit from the Bounce Back loan, to misuse of the job retention (furlough) scheme; but how can government departments not only identify fraud and error, but also recoup the lost funds?
There was a need for these schemes to be deployed extremely quickly, and the government succeeded in that. But the speed at which the funds became available also created numerous opportunities for both systematic error and fraud. The peak of the financial crisis might be behind us, but businesses and individuals are still in need of ongoing financial support, so it is now essential for the public sector to learn valuable lessons to target fraudulent activity and minimise the potential loss of public funds in the future. 
Government now has an opportunity to strengthen internal controls and make sure the use of public funds is appropriate and technology has a key role to play here in detecting and preventing future fraud and error. 
AI in audit 
In order to remove the current levels of fraudulent activity and gain valuable insight into the primary areas to address, the public sector must use an intelligent, data-led approach. By using Artificial Intelligence (AI) within public sector IT systems, errors can be detected, fraud or mismanagement of funds can be spotted and the entire process can be streamlined to prevent further problems. 
Great work is currently being undertaken by HMRC, which has used its extensive experience in identifying and tackling tax fraud to address the misuse of the furlough scheme. If public money is to be safeguarded in the future, it is likely that a central government initiative will be required; other public sector bodies, especially smaller local authorities, are less likely to have the resources or skills in place to undertake the analysis required.
The use of data resources is key here as the government holds a vast amount of data; although, it is possible that the delivery speed of COVID-19 financial and funding responses will have created gaps in data collection which will need a rapid resolution. The priority must be to identify these gaps in existing data and simultaneously use Machine Learning (ML) to reveal anomalies that could be as a result of either systematic error or fraud.
Additionally, this insight from ML can also provide public sector bodies with a chance to move towards the use of predictive analytics to improve control and move away from a retrospective review. By developing an understanding of the key indicators of fraud, the application process can automatically raise an alert when a claim looks unusual, minimising the risk of such claims being processed and therefore drastically reducing the risk of fraud.
Invaluable insight 
It might seem daunting for many public sector bodies, but it is essential to take these steps quickly. Even at a time of crisis, good processes are important – failing to learn from the mistakes of the past few months will simply compound the problem and lead to greater misuse of public funds. The public sector, businesses, and individuals need to learn how to operate in this environment, and that requires the right people to spend time looking at the data, identifying problems and putting new controls in place. With an AI-led approach, these individuals will learn lessons about what worked and what didn’t work in this unprecedented release of public funds. And they will gain invaluable insight into the identification of fraud – something that will provide on-going benefit for all public sector bodies.
(Photo by Allef Vinicius on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, audit, Featured, finance, fintech






View Comments


Leave a comment




            One comment on “How can the public sector use AI to identify fraud?”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Opinion: How can the public sector use AI to identify fraud?,2021-02-09,"['Rachel Kirkham', 'Rachel Was The Former Head Of Data Analytics Research At The Uk National Audit Office', 'Is Now The Director Of Ai Solutions At Mindbridge.']","['data', 'opinion', 'public', 'need', 'individuals', 'fraud', 'sector', 'funds', 'expo', 'ai', 'learn', 'financial', 'identify']","Accountability and transparency are essential for public sector audits.
Using AI, public sector organisations can both identify and rectify potential issues before they become a problem, saving valuable money in the process and ensuring these precious public funds are being administered and used effectively.
Invaluable insightIt might seem daunting for many public sector bodies, but it is essential to take these steps quickly.
And they will gain invaluable insight into the identification of fraud – something that will provide on-going benefit for all public sector bodies.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
52,https://artificialintelligence-news.com/2020/11/16/nvidia-dgx-station-a100-ai-data-centre-box/,"

NVIDIA DGX Station A100 is an ‘AI data-centre-in-a-box’




 






By Ryan Daws |
        November 16, 2020                    | TechForge Media

                            Categories:
                                    Hardware,
                                    Machine Learning,
                                    Nvidia,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




NVIDIA has unveiled its DGX Station A100, an “AI data-centre-in-a-box” powered by up to four 80GB versions of the company’s record-setting GPU.
The A100 Tensor Core GPU set new MLPerf benchmark records last month—outperforming CPUs by up to 237x in data centre inference. In November, Amazon Web Services made eight A100 GPUs available in each of its P4d instances.
For those who prefer their hardware local, the DGX Station A100 is available in either four 80GB A100 GPUs or four 40GB configurations. The monstrous 80GB version of the A100 has twice the memory of when the GPU was originally unveiled just six months ago.
“We doubled everything in this system to make it more effective for customers,” said Paresh Kharya, senior director of product management for accelerated computing at NVIDIA.



NVIDIA says the two configurations provide options for data science and AI research teams to select a system according to their unique workloads and budgets.
Charlie Boyle, VP and GM of DGX systems at NVIDIA, commented:
“DGX Station A100 brings AI out of the data centre with a server-class system that can plug in anywhere.Teams of data science and AI researchers can accelerate their work using the same software stack as NVIDIA DGX A100 systems, enabling them to easily scale from development to deployment.”
The memory capacity of the DGX Station A100 powered by the 80GB GPUs is now 640GB, enabling much larger datasets and models.
“To power complex conversational AI models like BERT Large inference, DGX Station A100 is more than 4x faster than the previous generation DGX Station. It delivers nearly a 3x performance boost for BERT Large AI training,” NVIDIA wrote in a release.
DGX A100 640GB configurations can be integrated into the DGX SuperPOD Solution for Enterprise for unparalleled performance. Such “turnkey AI supercomputers” are available in units consisting of 20 DGX A100 systems.
Since acquiring ARM, NVIDIA continues to double-down on its investment in the UK and its local talent.
“We will create an open centre of excellence in the area once home to giants like Isaac Newton and Alan Turing, for whom key NVIDIA technologies are named,” Huang said in September. “We want to propel ARM – and the UK – to global AI leadership.”
NVIDIA’s latest supercomputer, the Cambridge-1, is being installed in the UK and will be one of the first SuperPODs with DGX A100 640GB systems. Cambridge-1 will initially be used by local pioneering companies to supercharge healthcare research.

Dr Kim Branson, SVP and Global Head of AI and ML at GSK, commented:
“Because of the massive size of the datasets we use for drug discovery, we need to push the boundaries of hardware and develop new machine learning software.We’re building new algorithms and approaches in addition to bringing together the best minds at the intersection of medicine, genetics, and artificial intelligence in the UK’s rich ecosystem.This new partnership with NVIDIA will also contribute additional computational power and state-of-the-art AI technology.”
The use of AI for healthcare research has received extra attention due to the coronavirus pandemic. A recent simulation of the coronavirus, the largest molecular simulation ever, simulated 305 million atoms and was powered by 27,000 NVIDIA GPUs.
Several promising COVID-19 vaccines in late-stage trials have emerged in recent days which have raised hopes that life could be mostly back to normal by summer, but we never know when the next pandemic may strike and there are still many challenges we all face both in and out of healthcare.
Systems like the DGX Station A100 help to ensure that – whatever challenges we face now and in the future – researchers have the power they need for their vital work.
Both configurations of the DGX Station A100 are expected to begin shipping this quarter.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: a100, ai, artificial intelligence, cambridge-1, dgx station, dgx station a100, Featured, gpu, Nvidia, supercomputer






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",NVIDIA DGX Station A100 is an ‘AI data-centre-in-a-box’,2020-11-16,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['80gb', 'station', 'data', 'uk', 'a100', 'configurations', 'datacentreinabox', 'dgx', 'expo', 'ai', 'nvidia']","NVIDIA has unveiled its DGX Station A100, an “AI data-centre-in-a-box” powered by up to four 80GB versions of the company’s record-setting GPU.
For those who prefer their hardware local, the DGX Station A100 is available in either four 80GB A100 GPUs or four 40GB configurations.
“To power complex conversational AI models like BERT Large inference, DGX Station A100 is more than 4x faster than the previous generation DGX Station.
DGX A100 640GB configurations can be integrated into the DGX SuperPOD Solution for Enterprise for unparalleled performance.
Both configurations of the DGX Station A100 are expected to begin shipping this quarter.",AInews
53,https://artificialintelligence-news.com/2020/12/10/algorithmia-ai-budgets-increasing-deployment-challenges-remain/,"

Algorithmia: AI budgets are increasing but deployment challenges remain




 






By Ryan Daws |
        December 10, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Enterprise,
                                    Machine Learning,
                                    Research,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A new report from Algorithmia has found that enterprise budgets for AI are rapidly increasing but significant deployment challenges remain.
Algorithmia’s 2021 Enterprise Trends in Machine Learning report features the views of 403 business leaders involved with machine learning initiatives.
Diego Oppenheimer, CEO of Algorithmia, says:
“COVID-19 has caused rapid change which has challenged our assumptions in many areas. In this rapidly changing environment, organisations are rethinking their investments and seeing the importance of AI/ML to drive revenue and efficiency during uncertain times.Before the pandemic, the top concern for organisations pursuing AI/ML initiatives was a lack of skilled in-house talent. Today, organisations are worrying more about how to get ML models into production faster and how to ensure their performance over time.While we don’t want to marginalise these issues, I am encouraged by the fact that the type of challenges have more to do with how to maximise the value of AI/ML investments as opposed to whether or not a company can pursue them at all.”
The main takeaway is that AI budgets are significantly increasing. 83 percent of respondents said they’ve increased their budgets compared to last year.
Despite a difficult year for many companies, business leaders are not being put off of AI investments—in fact, they’re doubling-down.
In Algorithmia’s summer survey, 50 percent of respondents said they plan to spend more on AI this year. Around one in five even said they “plan to spend a lot more.”
76 percent of businesses report they are now prioritising AI/ML over other IT initiatives. 64 percent say the priority of AI/ML has increased relative to other IT initiatives over the last 12 months.
With unemployment figures around the world at their highest for several years – even decades in some cases – it’s at least heartening to hear that 76 percent of respondents said they’ve not reduced the size of their AI/ML teams. 27 percent even report an increase.
43 percent say their AI/ML initiatives “matter way more than we thought” and close to one in four believe their AI/ML initiatives should have been their top priority sooner. Process automation and improving customer experiences are the two main areas for AI investments.
While it’s been all good news so far, there are AI deployment issues being faced by many companies which are yet to be addressed.
Governance is, by far, the biggest AI challenge being faced by companies. 56 percent of the businesses ranked governance, security, and auditability issues as a concern.
Regulatory compliance is vital but can be confusing, especially with different regulations between not just countries but even states. 67 percent of the organisations report having to comply with multiple regulations for their AI/ML deployments.
The next major challenge after governance is with basic deployment and organisational challenges. 
Basic integration issues were ranked by 49 percent of businesses as a problem. Furthermore, more job roles are being involved with AI deployment strategies than ever before—it’s no longer seen as just the domain of data scientists.
However, there’s perhaps some light at the end of the tunnel. Organisations are reporting improved outcomes when using dedicated, third-party MLOps solutions.
While keeping in mind Algorithmia is a third-party MLOps solution, the report claims organisations using such a platform spend an average of around 21 percent less on infrastructure costs. Furthermore, it also helps to free up their data scientists—who spend less time on model deployment.
You can find a full copy of Algorithmia’s report here (requires signup)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, algorithmia, artificial intelligence, enterprise, Featured, machine learning, mlops, research






View Comments


Leave a comment




            One comment on “Algorithmia: AI budgets are increasing but deployment challenges remain”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Algorithmia: AI budgets are increasing but deployment challenges remain,2020-12-10,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['algorithmia', 'issues', 'challenges', 'remain', 'aiml', 'respondents', 'report', 'expo', 'ai', 'spend', 'budgets', 'increasing', 'initiatives', 'organisations', 'deployment']","A new report from Algorithmia has found that enterprise budgets for AI are rapidly increasing but significant deployment challenges remain.
43 percent say their AI/ML initiatives “matter way more than we thought” and close to one in four believe their AI/ML initiatives should have been their top priority sooner.
While it’s been all good news so far, there are AI deployment issues being faced by many companies which are yet to be addressed.
Furthermore, more job roles are being involved with AI deployment strategies than ever before—it’s no longer seen as just the domain of data scientists.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
54,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
55,https://artificialintelligence-news.com/2020/06/25/aclu-uncovers-wrongful-arrest-ai-error/,"

The ACLU uncovers the first known wrongful arrest due to AI error




 






By Ryan Daws |
        June 25, 2020                    | TechForge Media

                            Categories:
                                    Face Recognition,
                                    Government,
                                    Law Enforcement,
                                    Policy,
                                    Privacy,
                                    Society,
                                    Surveillance,
                                    USA,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The ACLU (American Civil Liberties Union) has forced the police to acknowledge a wrongful arrest due to an erroneous algorithm.
While it’s been suspected that documented racial bias with facial recognition algorithms has led to false arrests, it’s been difficult to prove.
On Wednesday, the ACLU lodged a complaint against the Detroit police after black male Robert Williams was arrested on his front lawn “as his wife Melissa looked on and as his daughters wept from the trauma”. Williams was held in a “crowded and filthy” cell overnight without being given any reason.
Detroit Police arrested Williams for allegedly stealing five watches valued at $3800 from a store in October 2018. A blurry CCTV image was matched by a facial recognition algorithm to Williams’ driver’s license photo.
During an interrogation the day after his arrest, the police admitted that “the computer must have gotten it wrong”. Williams was kept incarcerated until after dark “at which point he was released out the front door, on a cold and rainy January night, where he was forced to wait outside on the curb for approximately an hour while his wife scrambled to find child care for the children so that she could come pick him up.”
Speaking to the NY Times, a Detroit police spokesperson said the department “does not make arrests based solely on facial recognition,” and claims witness interviews and a photo lineup were used.
However, a response from the Wayne County prosecutor’s office confirms the department used facial recognition to identify Williams using the security footage and an eyewitness to the crime was not shown the alleged photo lineup.
In its complaint, the ACLU demands that Detroit police end the use of facial recognition “as the facts of Mr. Williams’ case prove both that the technology is flawed and that DPD investigators are not competent in making use of such technology.”
This week, Boston became the latest city to ban facial recognition technology for municipal use. Boston follows an increasing number of cities like San Francisco, Oakland, and California who’ve banned the technology over human rights concerns.
“Facial recognition is inherently dangerous and inherently oppressive. It cannot be reformed or regulated. It must be abolished,” said Evan Greer, deputy director of the digital rights group Fight for the Future.
“Boston just became the latest major city to stop the use of this extraordinary and toxic surveillance technology. Every other city should follow suit.”
Cases like Mr Williams’ are certainly strengthening such calls. Over 1,000 experts signed an open letter this week against the use of AI for the next chilling step, crime prediction.
(Photo by ev on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: aclu, ai, arrest, artificial intelligence, detroit, face recognition, facial recognition, Featured, law enforcement, police, policing, privacy, surveillance






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",The ACLU uncovers the first known wrongful arrest due to AI error,2020-06-25,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['technology', 'error', 'recognition', 'williams', 'known', 'wrongful', 'arrest', 'expo', 'detroit', 'ai', 'wife', 'aclu', 'uncovers', 'city', 'facial', 'week']","The ACLU (American Civil Liberties Union) has forced the police to acknowledge a wrongful arrest due to an erroneous algorithm.
While it’s been suspected that documented racial bias with facial recognition algorithms has led to false arrests, it’s been difficult to prove.
A blurry CCTV image was matched by a facial recognition algorithm to Williams’ driver’s license photo.
“Facial recognition is inherently dangerous and inherently oppressive.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
56,https://artificialintelligence-news.com/categories/big-data/,"



Dorian Selz, CEO, Squirro: Why the AI revolution will take time










Imagine you are riding in a fully driverless car - with no human controls - down a narrow countryside road, with no lights or road markings. Upon emerging from a twisting bend a flock of sheep confront you. What happens next?
These types of situations are what programs such as the MIT-developed Moral Machine have been looking to unlock. The site has for the past four years canvassed public opinion by presenting a series of ethical dilemmas: should an autonomous car... 






        26 May 2020                    |
            Adoption





",Big Data Archives,,[],"['data', 'sheep', 'situations', 'unlock', 'site', 'car', 'archives', 'riding', 'big', 'road', 'series', 'twisting', 'types']","Imagine you are riding in a fully driverless car - with no human controls - down a narrow countryside road, with no lights or road markings.
Upon emerging from a twisting bend a flock of sheep confront you.
What happens next?
These types of situations are what programs such as the MIT-developed Moral Machine have been looking to unlock.
The site has for the past four years canvassed public opinion by presenting a series of ethical dilemmas: should an autonomous car...",AInews
57,https://artificialintelligence-news.com/categories/face-recognition/,"



Police use of Clearview AI’s facial recognition increased 26% after Capitol raid










Clearview AI reports that police use of the company’s highly-controversial facial recognition system jumped 26 percent following the raid on the Capitol.
The facial recognition system relies on scraping the data of people from across the web without their explicit consent, a practice which has naturally raised some eyebrows—including the ACLU’s which called it a “nightmare scenario” for privacy.
Around three billion images are said to have been scraped for... 






        11 January 2021                    |
            Face Recognition





",Face Recognition Archives,,[],"['face', 'raised', 'scenario', 'recognition', 'scraping', 'archives', 'relies', 'scraped', 'web', 'system', 'reports', 'facial']","Clearview AI reports that police use of the company’s highly-controversial facial recognition system jumped 26 percent following the raid on the Capitol.
The facial recognition system relies on scraping the data of people from across the web without their explicit consent, a practice which has naturally raised some eyebrows—including the ACLU’s which called it a “nightmare scenario” for privacy.
Around three billion images are said to have been scraped for...",AInews
58,https://artificialintelligence-news.com/categories/ibm/,"



IBM study highlights rapid uptake and satisfaction with AI chatbots










A study by IBM released this week highlights the rapid uptake of AI chatbots in addition to increasing customer satisfaction.
Most of us are hardwired to hate not speaking directly to a human when we have a problem—following years of irritating voicemail systems. However, perhaps the only thing worse is being on hold for an uncertain amount of time due to overwhelmed call centres.
Chatbots have come a long way and can now quickly handle most queries within minutes.... 






        27 October 2020                    |
            Bots





",IBM Archives,,[],"['uncertain', 'systems', 'ibm', 'voicemail', 'archives', 'uptake', 'speaking', 'worse', 'way', 'thing', 'study', 'week']","A study by IBM released this week highlights the rapid uptake of AI chatbots in addition to increasing customer satisfaction.
Most of us are hardwired to hate not speaking directly to a human when we have a problem—following years of irritating voicemail systems.
However, perhaps the only thing worse is being on hold for an uncertain amount of time due to overwhelmed call centres.
Chatbots have come a long way and can now quickly handle most queries within minutes....",AInews
59,https://artificialintelligence-news.com/categories/deepfakes/,"



Researchers find systems to counter deepfakes can be deceived










Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:
""Our work shows that attacks on deepfake detectors could be a real-world threat.More alarmingly, we demonstrate that it's... 






        10 February 2021                    |
            Deepfakes





",Deepfakes Archives,,[],"['diego', 'systems', 'student', 'researchers', 'wacv', 'archives', 'work', 'threatmore', 'deepfakes', 'university', 'uc', 'san']","Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:""Our work shows that attacks on deepfake detectors could be a real-world threat.
More alarmingly, we demonstrate that it's...",AInews
60,https://artificialintelligence-news.com/categories/drones/,"



Boeing-SparkCognition joint venture SkyGrid deploys AI to protect drones










SkyGrid, a Boeing-SparkCognition joint venture, has launched the world’s first AI-powered security for drones.
Drones are being used for increasingly critical purposes, including carrying vital medical supplies. Security is paramount to build the trust necessary to unlock the full potential of the emerging industry.
Amir Husain, CEO and founder of SparkCognition and SkyGrid, said:
“In the near future, we’ll essentially have a network of flying computers... 






        20 January 2021                    |
            Drones





",Drones Archives,,[],"['supplies', 'security', 'trust', 'unlock', 'sparkcognition', 'archives', 'worlds', 'skygrid', 'vital', 'drones', 'used', 'venture']","SkyGrid, a Boeing-SparkCognition joint venture, has launched the world’s first AI-powered security for drones.
Drones are being used for increasingly critical purposes, including carrying vital medical supplies.
Security is paramount to build the trust necessary to unlock the full potential of the emerging industry.
Amir Husain, CEO and founder of SparkCognition and SkyGrid, said:“In the near future, we’ll essentially have a network of flying computers...",AInews
61,https://artificialintelligence-news.com/2020/05/28/japan-bill-build-ai-super-cities-societal-issues/,"

Japan passes bill to build AI-powered ‘super cities’ addressing societal issues




 






By Ryan Daws |
        May 28, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Government,
                                    IoT,
                                    Japan,
                                    Machine Learning,
                                    Policy,
                                    Smart Cities,
                                    Society,
                                    TECHEX,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Japan has passed a bill to build “super cities” which address societal issues using emerging technologies such as AI.
The bill, passed on Wednesday, aims to accelerate the sweeping change of regulations across various fields to support the creation of such futuristic cities.
Addressing issues such as depopulation and an aging society will be the focus of the super cities. Technologies including big data and AI will be key to successfully tackling the challenging problems.
Large amounts of data will be collected and organised from across administrative organisations.
Local governments will be selected for the ambitious projects which will launch forums with the national government and private companies to take forward the plans.
Draft plans will be created from this deep public-private collaboration that will subsequently be submitted to the state government if approved by local residents.
As with many smart city plans, there are deep concerns about the collection of personal data and what it could mean for individual privacy. Local residents are sure to want assurance that any data collection is anonymous.
A similar bill was submitted to the Diet (Japan’s decision-making institution) last year. The bill was scrapped following calls from the ruling government to review it.
The revised bill was passed on Wednesday. Given the appetite for the project across the government; the plans are now expected to progress swiftly.
(Photo by Jezael Melgoza on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, Featured, iot, japan, smart cities, super cities






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Japan passes bill to build AI-powered ‘super cities’ addressing societal issues,2020-05-28,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'issues', 'societal', 'plans', 'bill', 'super', 'technologies', 'submitted', 'build', 'passes', 'local', 'expo', 'tech', 'addressing', 'cities', 'japan', 'aipowered', 'passed']","Japan has passed a bill to build “super cities” which address societal issues using emerging technologies such as AI.
The bill, passed on Wednesday, aims to accelerate the sweeping change of regulations across various fields to support the creation of such futuristic cities.
Addressing issues such as depopulation and an aging society will be the focus of the super cities.
A similar bill was submitted to the Diet (Japan’s decision-making institution) last year.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
62,https://artificialintelligence-news.com/categories/manufacturing/,"



Fetch.ai partners with FESTO on decentralised manufacturing marketplace










AI blockchain startup Fetch.ai is partnering with industry veteran FESTO to launch a decentralised marketplace for manufacturing.
Fetch.ai is based in Cambridge, UK and has built an impressive team of talent with experience from DeepMind, Siemens, Sony, and a number of esteemed academic institutions. The company is working on decentralised autonomous “agents” which perform real-world tasks.
FESTO was founded in 1925 and currently produces and sells pneumatic and... 






        12 February 2021                    |
            Blockchain





",Manufacturing Archives,,[],"['team', 'uk', 'startup', 'veteran', 'siemens', 'tasksfesto', 'archives', 'sony', 'manufacturing', 'decentralised', 'talent', 'working']","AI blockchain startup Fetch.ai is partnering with industry veteran FESTO to launch a decentralised marketplace for manufacturing.
Fetch.ai is based in Cambridge, UK and has built an impressive team of talent with experience from DeepMind, Siemens, Sony, and a number of esteemed academic institutions.
The company is working on decentralised autonomous “agents” which perform real-world tasks.
FESTO was founded in 1925 and currently produces and sells pneumatic and...",AInews
63,https://artificialintelligence-news.com/resources/,"



FREE ON-DEMAND WEBINAR: The AI & Automation Revolution; Humans & AI Working Together










Join our industry thought leaders in this live panel webinar, as they delve into the world of AI and the Automation Revolution. In this session you will:



Discover the latest innovations for AI and automation.Understand how humans and machines enable one another.Learn how to adopt and utilise AI for your business and learn from industry use-cases.A look at the future of the AI enabled workforce.



The industry experts speaking on this innovative topic include:



Ana Rollan,...                











",Resources Archive,,[],"['willdiscover', 'resources', 'utilise', 'webinar', 'topic', 'usecasesa', 'world', 'thought', 'ai', 'archive', 'workforcethe', 'industry']","Join our industry thought leaders in this live panel webinar, as they delve into the world of AI and the Automation Revolution.
In this session you will:Discover the latest innovations for AI and automation.Understand how humans and machines enable one another.Learn how to adopt and utilise AI for your business and learn from industry use-cases.A look at the future of the AI enabled workforce.
The industry experts speaking on this innovative topic include:Ana Rollan,...",AInews
64,https://artificialintelligence-news.com/tag/clearview-ai/,"



Police use of Clearview AI’s facial recognition increased 26% after Capitol raid










Clearview AI reports that police use of the company’s highly-controversial facial recognition system jumped 26 percent following the raid on the Capitol.
The facial recognition system relies on scraping the data of people from across the web without their explicit consent, a practice which has naturally raised some eyebrows—including the ACLU’s which called it a “nightmare scenario” for privacy.
Around three billion images are said to have been scraped for... 






        11 January 2021                    |
            Face Recognition





",clearview ai Archives,,[],"['raised', 'scenario', 'recognition', 'scraping', 'clearview', 'archives', 'relies', 'scraped', 'web', 'ai', 'system', 'reports', 'facial']","Clearview AI reports that police use of the company’s highly-controversial facial recognition system jumped 26 percent following the raid on the Capitol.
The facial recognition system relies on scraping the data of people from across the web without their explicit consent, a practice which has naturally raised some eyebrows—including the ACLU’s which called it a “nightmare scenario” for privacy.
Around three billion images are said to have been scraped for...",AInews
65,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
66,https://artificialintelligence-news.com/2020/05/13/ai-bot-had-to-unlearn-english-grammar-to-decipher-trump-speeches/,"

AI bot had to unlearn English grammar to decipher Trump speeches




 



 

By James Bourne |
        May 13, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Deep Learning,
                                    Deepfakes,
                                    Government,
                                    Machine Learning,
                                    TECHEX,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




A developer had to recalibrate his artificial intelligence bot to account for the unconventional grammar and syntax found in President Trump’s speeches.
As originally reported by the Los Angeles Times, Bill Frischling noticed in 2017 that his AI bot, Margaret, was struggling to transcribe part of the President’s speech from May 4 that year commemorating the 75th anniversary of the Battle of the Coral Sea. In particular, Margaret crashed after this 127-word section, featuring a multitude of sub-clauses and tense shifts:
“I know there are many active duty service personnel from both nations with us in the audience, and I want to express our gratitude to each and every one of you. We are privileged to be joined by many amazing veterans from our two countries, as well – and for really from so many different conflicts, there are so many conflicts that we fought on and worked on together – and by the way in all cases succeeded on – it’s nice to win.
“It’s nice to win, and we’ve won a lot, haven’t we Mr. Prime Minister? We’ve won a lot. We’re going to keep it going, by the way. You’ve given your love and loyalty to your nations, and tonight a room of grateful patriots says thank you.”
Frischling, in the words of the Times, ‘hired a computer expert with a PhD in machine punctuation to unteach Margaret normal grammar and syntax – and teach it to decipher Trump-speak instead.’ “It was still trying to punctuate it like it was English, versus trying to punctuate it like it was Trump,” he said.
Able to transcribe the President’s speeches unhindered after that, Margaret’s job is not just to keep a database of these remarks, but analyse behavioural patterns. According to Frischling, some of the behaviours Margaret has spotted include being ‘more comfortable’ telling falsehoods by talking quickly, as well as identifying when Trump is genuinely angry, as opposed to putting it on for show.
One example came at the White House coronavirus briefing on April 23, where Trump – against all medical advice – suggested patients should be injected with disinfectant to kill the virus. When a Washington Post reporter questioned this edict, Trump’s response, according to Margaret, was borne out of genuine anger. Yet Frischling added that for many of the President’s more pre-meditated attacks on ‘fake news’ – of which the Washington Post has been a frequent case – there is little palpable anger on show.
As this publication has previously reported, the lines between real and fake news continue to be blurred – with the President himself an obvious target. In January last year, a ‘deepfake’ video of a Trump speech was broadcast on a Fox-owned Seattle TV network, with an employee later sacked for the error. In February, the President outlined an executive order, titled ‘Maintaining American Leadership in Artificial Intelligence’ exploring five key principles.
President Trump is by no means the only world leader whose sentence construction could be considered off-beat. As reported in the Times (h/t @arusbridger) last week, UK Prime Minister Boris Johnson answered a question on coronavirus testing from Keir Starmer, the leader of the opposition, thus:
“As I think is readily apparent, Mr Speaker, to everybody who has studied the, er, the situation, and I think the scientists would, er, confirm, the difficulty in mid-March was that, er, the, er, tracing capacity that we had – it had been useful… in the containment phase of the epidemic er, that capacity was no longer useful or relevant since the, er, transmission from individuals within the UK um meant that it exceeded our capacity.
“As we get the new cases down, er, we will have a team that will genuinely be able to track and, er, trace hundreds of thousands of people across the country, and thereby to drive down the epidemic. And so, er, I mean, to put it in a nutshell, it is easier, er, to do now – now that we have built up the team on the, on the way out – than it was as er, the epidemic took off.”
One can only imagine what Margaret would have made of that transcription job.
Photo by Charles Deluvio on Unsplash

Interested in hearing industry leaders discuss subjects like this and their use cases? Attend the co-located AI & Big Data Expo events with upcoming shows in Silicon Valley, London, and Amsterdam to learn more. Co-located with the IoT Tech Expo, Blockchain Expo, and Cyber Security & Cloud Expo.
 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI bot had to unlearn English grammar to decipher Trump speeches,2020-05-13,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['grammar', 'english', 'unlearn', 'trump', 'decipher', 'margaret', 'times', 'james', 'expo', 'ai', 'speeches', 'way', 'president', 'reported', 'bot', 'er', 'presidents']","A developer had to recalibrate his artificial intelligence bot to account for the unconventional grammar and syntax found in President Trump’s speeches.
President Trump is by no means the only world leader whose sentence construction could be considered off-beat.
Photo by Charles Deluvio on UnsplashInterested in hearing industry leaders discuss subjects like this and their use cases?
Attend the co-located AI & Big Data Expo events with upcoming shows in Silicon Valley, London, and Amsterdam to learn more.
Co-located with the IoT Tech Expo, Blockchain Expo, and Cyber Security & Cloud Expo.",AInews
67,https://artificialintelligence-news.com/2020/12/11/former-nhs-surgeon-ai-virtual-patient-remote-training/,"

Former NHS surgeon creates AI ‘virtual patient’ for remote training




 






By Ryan Daws |
        December 11, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Society,
                                    Speech Recognition,
                                    UK,
                                    USA,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A former NHS surgeon has created an AI-powered “virtual patient” which helps to keep skills sharp during a time when most in-person training is on hold.
Dr Alex Young is a trained orthopaedic and trauma surgeon who founded Virti and set out to use emerging technologies to provide immersive training for both new healthcare professionals and experienced ones looking to hone their skills.
COVID-19 has put most in-person training on hold to minimise transmission risks. Hospitals and universities across the UK and US are now using the virtual patient as a replacement—including our fantastic local medics and surgeons at the Bristol NHS Foundation Trust.
The virtual patient uses Natural Language Processing (NLP) and ‘narrative branching’ to allow medics to roleplay lifelike clinical scenarios. Medics and trainees can interact with the virtual patient using their tablet, desktop, or even VR/AR headsets for a more immersive experience.
Dr Alex Young comments:
“We’ve been working with healthcare organisations for several years, but the pandemic has created really specific challenges that technology is helping to solve. It’s no longer safe or practicable to have 30 medics in a room with an actor, honing their clinical soft-skills. With our virtual patient technology, we’ve created an extremely realistic and repeatable experience that can provide feedback in real time. This means clinicians and students can continue to learn valuable skills.Right now, communication with patients can be very difficult. There’s a lot of PPE involved and patients are often on their own. Having healthcare staff who are skilled in handling these situations can therefore make a huge difference to that patient’s experience.”
Some of the supported scenarios include: breaking bad news, comforting a patient in distress, and communicating effectively whilst their faces are obscured by PPE. Virti’s technology was also used at the peak of the pandemic to train NHS staff in key skills required on the front line, such as how to safely use PPE, how to navigate an unfamiliar intensive care ward, how to engage with patients and their families, and how to use a ventilator.
Tom Woollard, West Suffolk Hospital Clinical Skills and Simulation Tutor, who used the Virti platform at the peak of the COVID pandemic, comments:
“We’ve been using Virti’s technology in our intensive care unit to help train staff who have been drafted in to deal with COVID-19 demand.The videos which we have created and uploaded are being accessed on the Virti platform by nursing staff, physiotherapists and Operational Department Practitioners (ODPs) to orient them in the new environment and reduce their anxiety.The tech has helped us to reach a large audience and deliver formerly labour-intensive training and teaching which is now impossible with social distancing.In the future, West Suffolk will consider applying Virti tech to other areas of hospital practice.”
The use of speech recognition, NLP, and ‘narrative branching’ provides a realistic simulation of how a patient would likely respond—providing lifelike responses in speech, body language, and mannerisms.
The AI delivers real-time feedback to the user so they can learn and improve. With upwards of 70 percent of complaints against health professionals and care providers attributable to poor communication, the virtual patient could help to deliver better care while reducing time spent handling complaints.
Virti’s groundbreaking technology has – quite rightly – been named one of TIME’s best inventions of 2020.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, augmented reality, Featured, health, healthcare, natural language processing, nhs, nlp, virti, virtual patient, virtual reality, vr






View Comments


Leave a comment




            One comment on “Former NHS surgeon creates AI ‘virtual patient’ for remote training”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Former NHS surgeon creates AI ‘virtual patient’ for remote training,2020-12-11,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['surgeon', 'technology', 'remote', 'creates', 'virtual', 'skills', 'expo', 'tech', 'ai', 'patients', 'patient', 'nhs', 'virti', 'training', 'staff']","A former NHS surgeon has created an AI-powered “virtual patient” which helps to keep skills sharp during a time when most in-person training is on hold.
The virtual patient uses Natural Language Processing (NLP) and ‘narrative branching’ to allow medics to roleplay lifelike clinical scenarios.
Medics and trainees can interact with the virtual patient using their tablet, desktop, or even VR/AR headsets for a more immersive experience.
With our virtual patient technology, we’ve created an extremely realistic and repeatable experience that can provide feedback in real time.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
68,https://artificialintelligence-news.com/2020/10/06/eggplant-ai-powered-software-testing-cloud/,"

Eggplant launches AI-powered software testing in the cloud




 






By Ryan Daws |
        October 6, 2020                    | TechForge Media

                            Categories:
                                    Cloud,
                                    Developers,
                                    Enterprise,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Automation specialists Eggplant have launched a new AI-powered software testing platform.
The cloud-based solution aims to help accelerate the delivery of software in a rapidly-changing world while maintaining a high bar of quality.
Gareth Smith, CTO of Eggplant, said:
“The launch of our cloud platform is a significant milestone in our mission to rid the world of bad software. In our new normal, delivering speed and agility at scale has never been more critical.Every business can easily tap into Eggplants’ AI-powered automation platform to accelerate the pace of delivery while ensuring a high-quality digital experience.” 
Enterprises have accelerated their shift to the cloud due to the pandemic and resulting increases in things such as home working.
Recent research from Centrify found that 51 percent of businesses which embraced a cloud-first model were able to handle the challenges presented by COVID-19 far more effectively.
Eggplant’s Digital Automation Intelligence (DAI) Platform features:
Cloud-based end-to-end automation: The scalable fusion engine provides frictionless and efficient continuous and parallel end-to-end testing in the cloud, for any apps and websites, and on any target platforms. Monitoring insights: The addition of advanced user experience (UX) data points and metrics, enables customers to benchmark their applications UX performance. These insights, added to the UX behaviour helps improve SEO. Fully automated self-healing test assets: The use of AI identifies the tests needed and builds and runs them automatically, under full user control. These tests are self-healing, and automatically adapt as the system-under-test evolves.   
The solution helps to support the “citizen developer” movement—using AI to enable no-code/low-code development for people with minimal programming knowledge.
Both cloud and AI ranked highly in a recent study (PDF) by Deloitte of the most relevant technologies “to operate in the new normal”. Cloud and cybersecurity were joint first with 80 percent of respondents, followed by cognitive and AI tools (73%) and the IoT (65%).
Eggplant’s combination of AI and cloud technologies should help businesses to deal with COVID-19’s unique challenges and beyond.
(Photo by CHUTTERSNAP on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, automation, cloud, coding, developers, development, eggplant, Featured, programming, software, testing






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Eggplant launches AI-powered software testing in the cloud,2020-10-06,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['ux', 'cloud', 'automation', 'launches', 'expo', 'world', 'ai', 'user', 'tests', 'software', 'platform', 'aipowered', 'testing', 'eggplant']","Automation specialists Eggplant have launched a new AI-powered software testing platform.
The cloud-based solution aims to help accelerate the delivery of software in a rapidly-changing world while maintaining a high bar of quality.
Gareth Smith, CTO of Eggplant, said:“The launch of our cloud platform is a significant milestone in our mission to rid the world of bad software.
Eggplant’s combination of AI and cloud technologies should help businesses to deal with COVID-19’s unique challenges and beyond.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
69,https://artificialintelligence-news.com/2020/07/02/mit-removed-dataset-misogynistic-racist-ai-models/,"

MIT has removed a dataset which leads to misogynistic, racist AI models




 






By Ryan Daws |
        July 2, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Machine Learning,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




MIT has apologised for, and taken offline, a dataset which trains AI models with misogynistic and racist tendencies.
The dataset in question is called 80 Million Tiny Images and was created in 2008. Designed for training AIs to detect objects, the dataset is a huge collection of pictures which are individually labelled based on what they feature.
Machine-learning models are trained using these images and their labels. An image of a street – when fed into an AI trained on such a dataset – could tell you about things it contains such as cars, streetlights, pedestrians, and bikes.
Two researchers – Vinay Prabhu, chief scientist at UnifyID, and Abeba Birhane, a PhD candidate at University College Dublin in Ireland – analysed the images and found thousands of concerning labels.
MIT’s training set was found to label women as “bitches” or “whores,” and people from BAME communities with the kind of derogatory terms I’m sure you don’t need me to write. The Register notes the dataset also contained close-up images of female genitalia labeled with the C-word.
The Register alerted MIT to the concerning issues found by Prabhu and Birhane with the dataset and the college promptly took it offline. MIT went a step further and urged anyone using the dataset to stop using it and delete any copies.
A statement on MIT’s website claims it was unaware of the offensive labels and they were “a consequence of the automated data collection procedure that relied on nouns from WordNet.”
The statement goes on to explain the 80 million images contained in the dataset, with sizes of just 32×32 pixels, means that manual inspection would be almost impossible and cannot guarantee all offensive images will be removed.
“Biases, offensive and prejudicial images, and derogatory terminology alienates an important part of our community – precisely those that we are making efforts to include. It also contributes to harmful biases in AI systems trained on such data,” wrote Antonio Torralba, Rob Fergus, and Bill Freeman from MIT.
“Additionally, the presence of such prejudicial images hurts efforts to foster a culture of inclusivity in the computer vision community. This is extremely unfortunate and runs counter to the values that we strive to uphold.”
You can find a full pre-print copy of Prabhu and Birhane’s paper here (PDF)
(Photo by Clay Banks on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, ai model, artificial intelligence, dataset, equality, Featured, machine learning, misogynistic, mit, racism, racist, training






View Comments


Leave a comment




            4 comments on “MIT has removed a dataset which leads to misogynistic, racist AI models”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






","MIT has removed a dataset which leads to misogynistic, racist AI models",2020-07-02,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['removed', 'data', 'prabhu', 'using', 'leads', 'dataset', 'models', 'trained', 'offensive', 'expo', 'images', 'ai', 'racist', 'training', 'misogynistic', 'mit']","MIT has apologised for, and taken offline, a dataset which trains AI models with misogynistic and racist tendencies.
Machine-learning models are trained using these images and their labels.
An image of a street – when fed into an AI trained on such a dataset – could tell you about things it contains such as cars, streetlights, pedestrians, and bikes.
MIT went a step further and urged anyone using the dataset to stop using it and delete any copies.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
70,https://artificialintelligence-news.com/2020/02/26/babylon-health-doctor-ai-chatbot-safety-concerns/,"

Babylon Health lashes out at doctor who raised AI chatbot safety concerns




 






By Ryan Daws |
        February 26, 2020                    | TechForge Media

                            Categories:
                                    Bots,
                                    Healthcare,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Controversial healthcare app maker Babylon Health has criticised the doctor who first raised concerns about the safety of their AI chatbot.
Babylon Health’s chatbot is available in the company’s GP at Hand app, a digital healthcare solution championed by health secretary Matt Hancock that was also integrated into Samsung Health since last year.
The chatbot aims to reduce the burden on GPs and A&E departments by automating the triage process to determine whether someone can treat themselves at home, should book an online or in-person GP appointment, or go straight to a hospital.
A Twitter user under the pseudonym of Dr Murphy first reached out to us back in 2018 alleging that Babylon Health’s chatbot was giving unsafe advice. Dr Murphy recently unveiled himself as Dr David Watkins and went public with his findings at The Royal Society of Medicine’s “Recent developments in AI and digital health 2020“ event in addition to appearing on a BBC Newsnight report.

Dr Murphy unmasked. Now for his positional statement. His driving force – patient safety. Can’t argue with that!! @DrMurphy11 #RSMDigiHealth @RoySocMed pic.twitter.com/hOC7kzlNz3— clive flashman (@cflashman) February 24, 2020

Over the past couple of years, Dr Watkins has provided many examples of the chatbot giving dangerous advice. In one example, an obese 48-year-old heavy smoker patient who presented himself with chest pains was suggested to book a consultation “in the next few hours”. Anyone with any common sense would have told you to dial an emergency number straight away.

Is this another negligent #Triage from the @babylonhealth #GPatHand #AI #Chatbot App?48yr old obese 30/day male smoker develops sudden onset central chest pain & sweating….I say call 999, the Babylon App says see your GP… pic.twitter.com/VcOqs9JOhP— Dr Murphy (aka David Watkins) (@DrMurphy11) March 22, 2018

This particular issue has since been rectified but Dr Watkins has highlighted many further examples over the years which show, very clearly, there are serious safety issues.
In a press release (PDF) on Monday, Babylon Health calls Dr Watkins a “troll” who has “targeted members of our staff, partners, clients, regulators and journalists and tweeted defamatory content about us”.
According to the release, Dr Watkins has conducted 2,400 tests of the chatbot in a bid to discredit the service while raising “fewer than 100 test results which he considered concerning”.
Babylon Health claims that in just 20 cases did Dr Watkins find genuine errors while others were “misrepresentations” or “mistakes,” according to Babylon’s own “panel of senior clinicians” who remain unnamed.
Speaking to TechCrunch, Dr Watkins called Babylon’s claims “utterly nonsense” and questions where the startup got its figures from as “there are certainly not 2,400 completed triage assessments”.
Dr Watkins estimates he has conducted between 800 and 900 full triages, some of which were repeat tests to see whether Babylon Health had fixed the issues he previously highlighted.
The doctor acknowledges Babylon Health’s chatbot has improved and has issues around the rate of around one in three instances. In 2018, when Dr Watkins first reached out to us and other outlets, he says this rate was “one in one”.
While it’s one account versus the other, the evidence shows that Babylon Health’s chatbot has issued dangerous advice on a number of occasions. Dr Watkins has dedicated many hours to highlighting these issues to Babylon Health in order to improve patient safety.
Rather than welcome his efforts and work with Dr Watkins to improve their service, it seems Babylon Health has decided to go on the offensive and “try and discredit someone raising patient safety concerns”.
In their press release, Babylon accuses Watkins of posting “over 6,000” misleading attacks but without giving details of where. Dr Watkins primarily uses Twitter to post his findings. His account, as of writing, has tweeted a total of 3,925 times and not just about Babylon’s service.
This isn’t the first time Babylon Health’s figures have come into question. Back in June 2018, Babylon Health held an event where it boasted its AI beat trainee GPs at the MRCGP exam used for testing their ability to diagnose medical problems. The average pass mark is 72 percent. “How did Babylon Health do?” said Dr Mobasher Butt at the event, a director at Babylon Health. “It got 82 percent.”
Given the number of dangerous suggestions to trivial ailments the chatbot has given, especially at the time, it’s hard to imagine the claim that it beats trainee GPs as being correct. Intriguingly, the video of the event has since been deleted from Babylon Health’s YouTube account and the company removed all links to coverage of it from the “Babylon in the news” part of its website.
When asked why it deleted the content, Babylon Health said in a statement: “As a fast-paced and dynamic health-tech company, Babylon is constantly refreshing the website with new information about our products and services. As such, older content is often removed to make way for the new.”
AI solutions like those offered by Babylon Health will help to reduce the demand on health services and ensure people have access to the right information and care whenever and wherever they need it. However, patient safety must come first.
Mistakes are less forgivable in healthcare due to the risk of potentially fatal or lifechanging consequences. The usual “move fast and break things” ethos in tech can’t apply here. 
There’s a general acceptance that rarely is a new technology going to be without its problems, but people want to see that best efforts are being made to limit and address those issues. Instead of welcoming those pointing out issues with their service before it leads to a serious incident, it seems Babylon Health would rather blame everyone else for its faults.

 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, babylon health, bots, chatbot, Featured, gp at hand, health, healthcare, medicine, safety






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Babylon Health lashes out at doctor who raised AI chatbot safety concerns,2020-02-26,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['chatbot', 'raised', 'watkins', 'healths', 'issues', 'babylon', 'safety', 'dr', 'expo', 'ai', 'health', 'patient', 'doctor', 'lashes', 'concerns']","Controversial healthcare app maker Babylon Health has criticised the doctor who first raised concerns about the safety of their AI chatbot.
The doctor acknowledges Babylon Health’s chatbot has improved and has issues around the rate of around one in three instances.
While it’s one account versus the other, the evidence shows that Babylon Health’s chatbot has issued dangerous advice on a number of occasions.
Dr Watkins has dedicated many hours to highlighting these issues to Babylon Health in order to improve patient safety.
“How did Babylon Health do?” said Dr Mobasher Butt at the event, a director at Babylon Health.",AInews
71,https://artificialintelligence-news.com/categories/hardware/,"



Chinese AI chipmaker Horizon endeavours to raise $700M to rival NVIDIA










AI chipmaker Horizon Robotics is seeking to raise $700 million in a new funding round.
Horizon is often seen as potentially becoming China’s equivalent of NVIDIA. The company is founded by Dr Kai Yu, a prominent industry figure with quite the credentials.
Yu led Baidu’s AI Research lab for three years, founded the Baidu Institute of Deep Learning, and launched the company’s autonomous driving business unit.
Furthermore, Yu has taught at Stanford... 






        22 December 2020                    |
            China





",Hardware Archives,,[],"['stanford', 'seeking', 'unitfurthermore', 'seen', 'archives', 'roundhorizon', 'yu', 'founded', 'ai', 'hardware', 'taught', 'robotics']","AI chipmaker Horizon Robotics is seeking to raise $700 million in a new funding round.
Horizon is often seen as potentially becoming China’s equivalent of NVIDIA.
The company is founded by Dr Kai Yu, a prominent industry figure with quite the credentials.
Yu led Baidu’s AI Research lab for three years, founded the Baidu Institute of Deep Learning, and launched the company’s autonomous driving business unit.
Furthermore, Yu has taught at Stanford...",AInews
72,https://artificialintelligence-news.com/2020/06/17/amazon-ai-displays-enforce-social-distancing-warehouses/,"

Amazon uses AI-powered displays to enforce social distancing in warehouses




 






By Ryan Daws |
        June 17, 2020                    | TechForge Media

                            Categories:
                                    Amazon,
                                    Applications,
                                    Ethics,
                                    Privacy,
                                    Space,
                                    Surveillance,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Amazon has turned to an AI-powered solution to help maintain social distancing in its vast warehouses.
Companies around the world are having to look at new ways of safely continuing business as we adapt to the “new normal” of life with the coronavirus.
Amazon has used its AI expertise to create what it calls the Distance Assistant. Using a time-of-flight sensor, often found in modern smartphones, the AI measures the distance between employees.



The AI is used to differentiate people from their background and what it sees is displayed on a 50-inch screen for workers to quickly see whether they’re adhering to keeping a safe distance.
Augmented reality is used to overlay either a green or red circle underneath each employee. As you can probably guess – a green circle means that the employee is a safe distance from others, while a red circle indicates that person needs to give others some personal space.
The whole solution is run locally and does not require access to the cloud to function. Amazon says it’s only deployed Distance Assistant in a handful of facilities so far but plans to roll out “hundreds” more “over the next few weeks.”
While the solution appears rather draconian, it’s a clever – and arguably necessary – way of helping to keep people safe until a vaccine for the virus is hopefully found. However, it will strengthen concerns that the coronavirus will be used to normalise increased surveillance and erode privacy.
Amazon claims it will be making Distance Assistant open-source to help other companies adapt to the coronavirus pandemic and keep their employees safe.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, Amazon, ar, artificial intelligence, augmented reality, coronavirus, covid 19, distance assistant, Featured, privacy, social distancing, warehouse






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Amazon uses AI-powered displays to enforce social distancing in warehouses,2020-06-17,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['warehouses', 'distancing', 'solution', 'uses', 'assistant', 'circle', 'enforce', 'expo', 'ai', 'world', 'safe', 'tech', 'displays', 'aipowered', 'amazon', 'distance', 'social', 'used']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
Amazon has turned to an AI-powered solution to help maintain social distancing in its vast warehouses.
Amazon has used its AI expertise to create what it calls the Distance Assistant.
Amazon claims it will be making Distance Assistant open-source to help other companies adapt to the coronavirus pandemic and keep their employees safe.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
73,https://artificialintelligence-news.com/2020/11/10/sony-new-ai-robotics-drone-division-airpeak/,"

Sony has a new ‘AI robotics’ drone division called Airpeak




 






By Ryan Daws |
        November 10, 2020                    | TechForge Media

                            Categories:
                                    Drones,
                                    Hardware,
                                    IoT,
                                    Robotics,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Sony’s latest division, Airpeak, is described as being “in the field of AI robotics” and will focus on next-generation drones.
Despite incidents of reckless flying, drones unlock huge opportunities. We regularly see beautiful photography and videography shot using drones—but, of course, they can do so much more.
Sony has built a stellar reputation in media capture. The company builds great cameras – both for itself and sensors it supplies to other manufacturers (like its new IMX686) – and its software like Vegas Pro is the defacto choice for many creative professionals.
In a press release, Sony wrote:
“Airpeak will support the creativity of video creators to the fullest extent possible, aiming to contribute to the further development of the entertainment industry as well as to improve efficiency and savings in various industries.Airpeak will also promote this project to enable drone-use with the highest level of safety and reliability in the environments where this has been difficult in the past.”
The focus on supporting video creators is to be expected from Sony, but the mention of various industries suggests the company has bigger plans.



In the photography/videography space alone, Sony will face stiff competition from established players like DJI.
Despite being the current industry leader, DJI has begun diversifying its products in recent years due to a decline in drone popularity for consumer purposes. This is mostly due to increasing restrictions in many countries around where drones can fly and even requiring permits (the FAA, for example, requires users to register all drones over a certain size.)
A patent granted to Sony back in January suggests the company may start relatively simple:

However, Sony could use its AI and robotics expertise to stand out in other exciting areas where drones have a lot of potential such as emergency response, delivering supplies, assisting in warehouses/factories, and even tackling small fires before they spread.
The language Sony uses suggests the company will target a wide range of customers from everyday consumers to large enterprise deployments.
Sony plans to reveal further details about Airpeak in the Spring of 2021.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, airpeak, artificial intelligence, drone, drones, Featured, hardware, robotics, sony






View Comments


Leave a comment




            One comment on “Sony has a new ‘AI robotics’ drone division called Airpeak”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Sony has a new ‘AI robotics’ drone division called Airpeak,2020-11-10,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['company', 'drone', 'airpeak', 'called', 'various', 'division', 'suggests', 'expo', 'ai', 'sony', 'video', 'robotics', 'industry', 'drones']","Sony’s latest division, Airpeak, is described as being “in the field of AI robotics” and will focus on next-generation drones.
In the photography/videography space alone, Sony will face stiff competition from established players like DJI.
The language Sony uses suggests the company will target a wide range of customers from everyday consumers to large enterprise deployments.
Sony plans to reveal further details about Airpeak in the Spring of 2021.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
74,https://artificialintelligence-news.com/2020/07/30/google-model-card-toolkit-ai/,"

Google’s Model Card Toolkit aims to bring transparency to AI




 






By Ryan Daws |
        July 30, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Developers,
                                    Ethics,
                                    Google,
                                    Machine Learning,
                                    Neural Network,
                                    Reinforcement Learning,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Google has released a toolkit which it hopes will bring some transparency to AI models.
People are wary of big tech companies like Google. People are also concerned about AI. Combine the two and you’ve got a general distrust which can hinder important advancements.
Model Card Toolkit aims to step in and facilitate AI model transparency reporting for developers, regulators, and downstream users.

Today we are sharing the Model Card Toolkit, a collection of tools that support ML developers in compiling the information that goes into a Model Card, and that aid in the creation of interfaces that will be useful for different audiences. Learn more at ↓ https://t.co/CXmEP6P6Pw— Google AI (@GoogleAI) July 29, 2020

Google launched Model Cards itself over the past year, something that the company first conceptualised in an October 2018 whitepaper.
Model Cards provide a structured framework for reporting on ML model provenance, usage, and ethics-informed evaluation and give a detailed overview of a model’s suggested uses and limitations. 
So far, Google has released Model Cards for open source models built on its MediaPipe platform as well as its commercial Cloud Vision API Face Detection and Object Detection services.
Google’s new toolkit for Model Cards will simplify the process of creating them for third parties by compiling the data and helping build interfaces orientated for specific audiences.
Here’s an example of a Model Card:

MediaPipe has published their Model Cards for each of their open-source models in their GitHub repository.
To demonstrate how the Model Cards Toolkit can be used in practice, Google has released a Colab tutorial that builds a Model Card for a simple classification model trained on the UCI Census Income dataset.
If you just want to dive right in, you can access the Model Cards Toolkit here.
(Photo by Marc Schulte on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, Featured, Google, model card, model card toolkit






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google’s Model Card Toolkit aims to bring transparency to AI,2020-07-30,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['released', 'transparency', 'model', 'googles', 'models', 'expo', 'tech', 'card', 'ai', 'google', 'aims', 'toolkit', 'cards', 'bring']","Google has released a toolkit which it hopes will bring some transparency to AI models.
Model Card Toolkit aims to step in and facilitate AI model transparency reporting for developers, regulators, and downstream users.
Today we are sharing the Model Card Toolkit, a collection of tools that support ML developers in compiling the information that goes into a Model Card, and that aid in the creation of interfaces that will be useful for different audiences.
If you just want to dive right in, you can access the Model Cards Toolkit here.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
75,https://artificialintelligence-news.com/2020/04/28/world-oldest-defence-think-tank-british-spies-ai/,"

World’s oldest defence think tank concludes British spies need AI




 






By Ryan Daws |
        April 28, 2020                    | TechForge Media

                            Categories:
                                    Adoption,
                                    Deepfakes,
                                    Ethics,
                                    Government,
                                    Law Enforcement,
                                    Privacy,
                                    Security,
                                    Society,
                                    Surveillance,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The Royal United Services Institute (RUSI) says in an intelligence report that British spies will need to use AI to counter threats.
Based in Westminster, the RUSI is the world’s oldest think tank on international defence and security. Founded in 1831 by the first Duke of Wellington, Sir Arthur Wellesley, the RUSI remains a highly respected institution that’s as relevant today as ever.
AI is rapidly advancing the capabilities of adversaries. In its report, the RUSI says that hackers – both state-sponsored and independent – are likely to use AI for cyberattacks on the web and political systems.
Adversaries “will undoubtedly seek to use AI to attack the UK”, the RUSI notes.
Threats could emerge in a variety of ways. Deepfakes, which use a neural network to generate convincing fake videos and images, are one example of a threat already being posed today. With the US elections coming up, there’s concerns deepfakes of political figures could be used for voter manipulation.
AI could also be used for powerful new malware which mutates to avoid detection. Such malware could even infect and take control of emerging technologies such as driverless cars, smart city infrastructure, and drones.
The RUSI believes that humans will struggle to counter AI threats alone and will need the assistance of automation.
“Adoption of AI is not just important to help intelligence agencies manage the technical challenge of information overload,” said Alexander Babuta, one of the report’s authors. “It is highly likely that malicious actors will use AI to attack the UK in numerous ways, and the intelligence community will need to develop new AI-based defence measures.”
GCHQ, the UK’s service which focuses on signals intelligence , commissioned the RUSI’s independent report. Ken McCallum, the new head of MI5 – the UK’s domestic counter-intelligence and security agency – has already said that greater use of AI will be one of his priorities.
The RUSI believes AI will be of little value for “predictive intelligence” to do things such as predicting when a terrorist act is likely to occur before it happens. Highlighting counter-terrorism specifically, the RUSI says such cases are too infrequent to look for patterns compared to other criminal acts. Reasons for terrorist acts can also change very quickly dependent on world events.
All of this raises concerns about the automation of discrimination. The RUSI calls for more of an “augmented” intelligence – whereby technology assists sifting through large amounts of data, but decisions are ultimately taken by humans – rather than leaving it all up to the machines.
In terms of global positioning, the RUSI recognises the UK’s strength in AI with talent emerging from the country’s world-leading universities and capabilities in the GCHQ, bodies like the Alan Turing Institute, the Centre for Data Ethics and Innovation, and even more in the private sector.
While it’s widely-acknowledged countries like the US and China have far more resources overall to throw at AI advancements, the RUSI believes the UK has the potential to be a leader in the technology within a much-needed ethical framework. However, they say it’s important not to be too preoccupied with the possible downsides.
“There is a risk of stifling innovation if we become overly-focused on hypothetical worst-case outcomes and speculations over some dystopian future AI-driven surveillance network,” argues Babuta.
“Legitimate ethical concerns will be overshadowed unless we focus on likely and realistic uses of AI in the short-to-medium term.”
You can find a copy of the RUSI’s full report here (PDF)
(Photo by Chris Yang on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, defence, defense, Featured, intelligence, report, rusi, surveillance, think tank, uk






View Comments


Leave a comment




            One comment on “World’s oldest defence think tank concludes British spies need AI”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",World’s oldest defence think tank concludes British spies need AI,2020-04-28,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['likely', 'oldest', 'think', 'british', 'uk', 'spies', 'defence', 'rusi', 'need', 'security', 'worlds', 'concludes', 'expo', 'report', 'ai', 'tank', 'intelligence', 'uks']","The Royal United Services Institute (RUSI) says in an intelligence report that British spies will need to use AI to counter threats.
Based in Westminster, the RUSI is the world’s oldest think tank on international defence and security.
In its report, the RUSI says that hackers – both state-sponsored and independent – are likely to use AI for cyberattacks on the web and political systems.
The RUSI believes that humans will struggle to counter AI threats alone and will need the assistance of automation.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
76,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
77,https://artificialintelligence-news.com/2020/04/01/babylon-health-ai-achieve-triage-accuracy/,"

Babylon Health says its AI can appropriately triage 85% of patients




 






By Ryan Daws |
        April 1, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Reinforcement Learning,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




AI healthcare startup Babylon Health believes it can appropriately triage patients in 85 percent of cases.
Babylon Health is best known for GP at Hand, a service which is supported by UK health secretary Matt Hancock and integrated into Samsung Health.
GP at Hand links patients with health experts 24/7 using video calls and can facilitate any prescriptions to be sent to local pharmacies. The service, however, has been criticised for an AI chatbot which repeatedly gave unsafe advice and for only taking on healthier, often younger individuals while redirecting cash away from local surgeries relied on by older and sicker patients.
Correct triaging is essential to ensure patients receive the appropriate care. As the world responds to the coronavirus pandemic, many of us will have seen the harrowing headlines from the worst-hit countries like Italy where doctors are having to essentially decide who is worth trying to save due to limited resources.
Having to make such decisions, on top of all the other pressures medical professionals are currently facing, is unimaginable. An automated system would help to reduce the mental impact from any doubt their decisions are correct.
The company used reinforcement learning, which uses rewards for completing tasks to incentivise an agent, to create their AI system.
Babylon Health’s agent learned “an optimised policy” based on 1,374 clinical vignettes crafted by experts. Each vignette was supported by 3.36 expert triage decisions on average, and each was independently reviewed by two clinicians.
The best performing model achieved an appropriateness score of 85 percent and a safety score of 93 percent, which is around the same for humans (84 percent appropriateness and 93 percent safety.)
If true, it’s an impressive result, but Babylon Health’s studies have been called into question in the past. Just three years ago, the company tried and failed to get a legal injunction to block the publication of a report from the NHS care standards watchdog.
In 2018, Babylon Health published a paper which claimed that its AI could diagnose common diseases as well as human physicians. The Royal College of General Practitioners, the British Medical Association, Fraser and Wong, and the Royal College of Physicians all issued statements disputing the paper’s claims.
As with the rest of Babylon Health’s solutions, there’s a lot of promise in what they’re aiming to do. However, the company’s history casts some doubt over whether these latest claims are as impressive as they seem.
You can find Babylon Health’s full paper on arXiv here (PDF)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, babylon health, Featured, health, healthcare






View Comments


Leave a comment




            One comment on “Babylon Health says its AI can appropriately triage 85% of patients”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Babylon Health says its AI can appropriately triage 85% of patients,2020-04-01,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['decisions', '85', 'healths', 'babylon', 'appropriately', 'hand', 'triage', 'expo', 'ai', 'world', 'patients', 'health']","AI healthcare startup Babylon Health believes it can appropriately triage patients in 85 percent of cases.
Babylon Health is best known for GP at Hand, a service which is supported by UK health secretary Matt Hancock and integrated into Samsung Health.
In 2018, Babylon Health published a paper which claimed that its AI could diagnose common diseases as well as human physicians.
You can find Babylon Health’s full paper on arXiv here (PDF)Interested in hearing industry leaders discuss subjects like this?
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
78,https://artificialintelligence-news.com/2020/10/22/nvidia-sets-another-ai-inference-record-mlperf/,"

NVIDIA sets another AI inference record in MLPerf




 






By Ryan Daws |
        October 22, 2020                    | TechForge Media

                            Categories:
                                    Benchmark,
                                    Hardware,
                                    Machine Learning,
                                    Neural Network,
                                    Nvidia,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




NVIDIA has set yet another record for AI inference in MLPerf with its A100 Tensor Core GPUs.
MLPerf consists of five inference benchmarks which cover the main three AI applications today: image classification, object detection, and translation.
“Industry-standard MLPerf benchmarks provide relevant performance data on widely used AI networks and help make informed AI platform buying decisions,” said Rangan Majumder, VP of Search and AI at Microsoft.
Last year, NVIDIA led all five benchmarks for both server and offline data centre scenarios with its Turing GPUs. A dozen companies participated.
23 companies participated in this year’s MLPerf but NVIDIA maintained its lead with the A100 outperforming CPUs by up to 237x in data centre inference.

For perspective, NVIDIA notes that a single NVIDIA DGX A100 system – with eight A100 GPUs – provides the same performance as nearly 1,000 dual-socket CPU servers on some AI applications.
“We’re at a tipping point as every industry seeks better ways to apply AI to offer new services and grow their business,” said Ian Buck, Vice President of Accelerated Computing at NVIDIA.
“The work we’ve done to achieve these results on MLPerf gives companies a new level of AI performance to improve our everyday lives.”
The widespread availability of NVIDIA’s AI platform through every major cloud and data centre infrastructure provider is unlocking huge potential for companies across various industries to improve their operations.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: a100, ai, ai inference, artificial intelligence, benchmark, cloud, data centre, Featured, gpu, inference, mlperf, Nvidia, tensor core






View Comments


Leave a comment




            One comment on “NVIDIA sets another AI inference record in MLPerf”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",NVIDIA sets another AI inference record in MLPerf,2020-10-22,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'performance', 'record', 'inference', 'a100', 'centre', 'benchmarks', 'expo', 'ai', 'companies', 'mlperf', 'nvidia', 'sets']","NVIDIA has set yet another record for AI inference in MLPerf with its A100 Tensor Core GPUs.
MLPerf consists of five inference benchmarks which cover the main three AI applications today: image classification, object detection, and translation.
“Industry-standard MLPerf benchmarks provide relevant performance data on widely used AI networks and help make informed AI platform buying decisions,” said Rangan Majumder, VP of Search and AI at Microsoft.
23 companies participated in this year’s MLPerf but NVIDIA maintained its lead with the A100 outperforming CPUs by up to 237x in data centre inference.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
79,https://artificialintelligence-news.com/2020/10/23/ibm-ai-predicts-alzheimers-better-standard-tests/,"

IBM’s latest AI predicts Alzheimer’s better than standard tests




 






By Ryan Daws |
        October 23, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    IBM,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




IBM has developed a new AI model which predicts the onset of Alzheimer’s better than standard clinical tests.
The AI is designed to be non-invasive and uses a short language sample from a verbal cognitive test given to a patient. Using this sample, the AI model is able to predict the onset of Alzheimer’s with around 71 percent accuracy.
For comparison, standard clinical tests are correct approximately 59 percent of the time and take much longer to diagnose. Current tests analyse the descriptive abilities of people as they age for potential warning signs.



In a paper detailing IBM’s model, the company says it used data from the Framingham Heart Study.
The study first began in 1948 and spans the multiple generations required for building an AI to predict Alzheimer’s in healthy individuals with no other risk factors. 5,000 participants from Massachusetts and their families have been studied.
703 samples from 270 of the study’s participants were collected and analysed to create a dataset consisting of a single sample from 80 participants—half of whom developed Alzheimer’s symptoms before they reached 85.
The AI was trained on this dataset to spot Alzheimer’s signals such as the repetition of words and using short sentences with poor grammatical structures. IBM’s AI was able to correctly predict the onset of Alzheimer’s in every seven of ten cases.
IBM intends to expand the training of their model using more data to better reflect society including socioeconomic, racial, and geographic factors. The Alzheimer’s research is part of a broader IBM effort to better understand neurological health and chronic illnesses through biomarkers and signals in speech and language.
Around 5.5 million people in America alone are estimated to have Alzheimer’s, and some studies suggest it’s the third leading cause of death behind heart disease and cancer.
While there is no cure or prevention for Alzheimer’s yet, earlier diagnosis helps to prepare individuals and their families as much as possible. If treatments become available, Alzheimer’s will almost certainly be more effectively treated when caught earlier.
IBM published its research in The Lancet’s science journal EClinicalMedicine. Pfizer was disclosed as providing funding to obtain data from the Framingham Heart Study Consortium and supporting IBM Research’s involvement.
(Image: Jeff Rogers, global research lead for IBM Research’s Digital Health platform, at work in the IBM Home Health Lab.)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, alzheimers, artificial intelligence, diagnosis, disease, Featured, health, healthcare, ibm, predict, test






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",IBM’s latest AI predicts Alzheimer’s better than standard tests,2020-10-23,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'research', 'ibms', 'model', 'using', 'sample', 'ibm', 'predict', 'expo', 'standard', 'latest', 'predicts', 'tests', 'ai', 'better', 'alzheimers']","IBM has developed a new AI model which predicts the onset of Alzheimer’s better than standard clinical tests.
Using this sample, the AI model is able to predict the onset of Alzheimer’s with around 71 percent accuracy.
The study first began in 1948 and spans the multiple generations required for building an AI to predict Alzheimer’s in healthy individuals with no other risk factors.
The Alzheimer’s research is part of a broader IBM effort to better understand neurological health and chronic illnesses through biomarkers and signals in speech and language.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
80,https://artificialintelligence-news.com/2020/06/04/m3-alibaba-covid-19-pneumonia-minute/,"

M3: Alibaba’s AI detects COVID-19 pneumonia in under a minute




 






By Ryan Daws |
        June 4, 2020                    | TechForge Media

                            Categories:
                                    China,
                                    Healthcare,
                                    Japan,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




M3, a medical web portal backed by Sony, claims Alibaba’s AI technology has allowed it to develop a powerful COVID-19 diagnosis tool.
The AI-powered tool is able to analyse CT scans for signs of COVID-19 infection to help quickly diagnose the novel coronavirus which has caused havoc around the world.
With heroic medical staff under more pressure than ever caring for the huge influx of people suffering with COVID-19 – in addition to all the other ailments they have to treat – such an AI-powered tool could help to free up significant amounts of time.
M3 has been testing the solution in Japan since the end of March; with the aim of deploying it across hundreds of locations. 
Hospitals will send CT scans to M3’s system which will then return the results with a 1-5 scale indicating the likelihood of COVID-19 pneumonia.
Alibaba’s system has been used in Chinese hospitals – including in Wuhan, the expected source of the COVID-19 outbreak – for a while now. The Chinese tech giant claims its AI can diagnose COVID-19 within 20 seconds with an accuracy of 90 percent or higher.
On average, a doctor takes around 20 minutes to make a diagnosis once a CT scan is available. M3 has found that the system typically diagnoses in under a minute.
While finding the accuracy to be relatively high, M3 reports the accuracy falls short of the 90 percent claimed by Alibaba. Even at 90 percent, 100 patients in every 1000 risk being misdiagnosed.
However, reading COVID-19 scans is reportedly even tricky for skilled physicians – especially as the virus is still relatively new. An AI-powered system which frees up clinical time is sure to be welcomed by all hospitals.
Catching the smaller signs of COVID-19 early could even help with providing treatment to those who need it before they get seriously ill.
This isn’t the first time AI has been looked to for assistance in tackling the COVID-19 pandemic.
Earlier this week, researchers from WVU Medicine and the Rockefeller Neuroscience Institute said they were able to predict the onset of COVID-19 symptoms three days early using AI to analyse data from Oura’s wearable rings.
Back in April, researchers from Carnegie Mellon University launched an AI-powered voice analysis system which aims to determine whether someone is suffering from COVID-19 using just a website.
While it seems likely we’re going to be living with COVID-19 in our lives for the foreseeable future, AI technologies look ready to step in and help.
(Photo by Robina Weermeijer on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, alibaba, artificial intelligence, coronavirus, covid 19, diagnosis, Featured, health, healthcare, m3, medical, pneumonia, test






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",M3: Alibaba’s AI detects COVID-19 pneumonia in under a minute,2020-06-04,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['m3', 'minute', 'accuracy', 'expo', 'tech', 'ai', 'alibabas', 'system', 'detects', 'scans', 'help', 'aipowered', 'ct', 'covid19', 'pneumonia']","M3, a medical web portal backed by Sony, claims Alibaba’s AI technology has allowed it to develop a powerful COVID-19 diagnosis tool.
Hospitals will send CT scans to M3’s system which will then return the results with a 1-5 scale indicating the likelihood of COVID-19 pneumonia.
However, reading COVID-19 scans is reportedly even tricky for skilled physicians – especially as the virus is still relatively new.
An AI-powered system which frees up clinical time is sure to be welcomed by all hospitals.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
81,https://artificialintelligence-news.com/2021/02/12/fetch-ai-partners-festo-decentralised-manufacturing-marketplace/,"

Fetch.ai partners with FESTO on decentralised manufacturing marketplace




 






By Ryan Daws |
        February 12, 2021                    | TechForge Media

                            Categories:
                                    Blockchain,
                                    Bots,
                                    Manufacturing,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




AI blockchain startup Fetch.ai is partnering with industry veteran FESTO to launch a decentralised marketplace for manufacturing.
Fetch.ai is based in Cambridge, UK and has built an impressive team of talent with experience from DeepMind, Siemens, Sony, and a number of esteemed academic institutions. The company is working on decentralised autonomous “agents” which perform real-world tasks.
FESTO was founded in 1925 and currently produces and sells pneumatic and electrical control and drive technology. The company has continued to thrive over the years through consistent reinvention and likes to show off around once a year by developing bionic robots like its ‘flying fox’ which uses machine learning to optimise its flight behaviour with every manoeuvre:



The partnership with Fetch.ai is FESTO’s first foray into blockchain and shows how the company aims to remain at the cutting-edge of technological developments.
Fetch.ai will develop a decentralised manufacturing marketplace for FESTO to help transform the company’s existing control systems and make them more efficient.
Maria Minaricova, Director of Business Development at Fetch.ai, said:
“We are delighted to be able to announce a collaboration with such an advanced technology company like FESTO.With FESTO’s contribution, we will be able to demonstrate in real life the benefits of autonomous AI agents in manufacturing and supply chain.We look forward to working further with FESTO to bring about the wide adoption of these ground-breaking manufacturing innovations.”
The marketplace will make use of Fetch.ai’s technology stack and its ‘Multi-Agent’ architecture. FESTO hopes the marketplace will help to avoid some of the challenges with existing centralised manufacturing process likes demand fluctuations and uneven utilisation of capacity.
Fetch.ai explained the advantages of switching to a decentralised solution:
“The advantages of an agent-based-approach within a decentralised manufacturing framework have the potential to lead to supply-chain optimisation based on real-time information, increasing the responsiveness of the enterprise to the market requirements, a higher degree of autonomy in manufacturing, and delivering personalised, tailored orders to customers.”
A report from TrendMicro last year found that 65 percent of manufacturing environments are using outdated systems even when more secure and efficient options are available.
“Industry 4.0 offers unparalleled opportunities to increase productivity, enhance process efficiencies, and realise on-demand manufacturing,” said Steve Quane, Executive Vice President, Network Defense and Hybrid Cloud Security for Trend Micro.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, blockchain, decentralisation, decentralization, Featured, festo, fetch.ai, industry, manufacturing, marketplace






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Fetch.ai partners with FESTO on decentralised manufacturing marketplace,2021-02-12,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['marketplace', 'technology', 'fetchai', 'expo', 'partners', 'blockchain', 'manufacturing', 'festo', 'decentralised', 'company', 'working']","AI blockchain startup Fetch.ai is partnering with industry veteran FESTO to launch a decentralised marketplace for manufacturing.
Fetch.ai will develop a decentralised manufacturing marketplace for FESTO to help transform the company’s existing control systems and make them more efficient.
Maria Minaricova, Director of Business Development at Fetch.ai, said:“We are delighted to be able to announce a collaboration with such an advanced technology company like FESTO.
FESTO hopes the marketplace will help to avoid some of the challenges with existing centralised manufacturing process likes demand fluctuations and uneven utilisation of capacity.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
82,https://artificialintelligence-news.com/2020/10/05/gtc-2020-ai-help-covid19-rear-view-mirror/,"

GTC 2020: Using AI to help put COVID-19 in the rear-view mirror




 






By Ryan Daws |
        October 5, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Nvidia,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




This year’s GTC is Nvidia’s biggest event yet, but – like the rest of the world – it’s had to adapt to the unusual circumstances we all find ourselves in. Huang swapped his usual big stage for nine clips with such exotic backdrops as his kitchen.
AI is helping with COVID-19 research around the world and much of it is being powered by NVIDIA GPUs. It’s a daunting task, new drugs often cost over $2.5 billion in research and development — doubling every nine years — and 90 percent of efforts fail.
Nvidia wants to help speed up discoveries of vital medicines while reducing costs
“COVID-19 hits home this urgency [for new tools],” Huang says.
Huang announced NVIDIA Clara Discovery—a suite of tools for assisting scientists in discovering lifesaving new drugs.
NVIDIA Clara combines imaging, radiology, and genomics to help develop healthcare AI applications. Pre-trained AI models and application-specific frameworks help researchers to find targets, build compounds, and develop responses.
Dr Hal Barron, Chief Scientific Officer and President of R&D at GSK, commented:
“AI and machine learning are like a new microscope that will help scientists to see things that they couldn’t see otherwise.NVIDIA’s investment in computing, combined with the power of deep learning, will enable solutions to some of the life sciences industry’s greatest challenges and help us continue to deliver transformational medicines and vaccines to patients.Together with GSK’s new AI lab in London, I am delighted that these advanced technologies will now be available to help the UK’s outstanding scientists.”
Researchers can now use biomedical-specific language models for their work, thanks to a breakthrough in natural language processing. This means researchers can organise and activate large datasets, research literature, and sort through papers or patents on existing treatments and other vital real-world data.
“Where there are popular industry tools, our computer scientists accelerate them,” Huang said. “Where no tools exist, we develop them—like NVIDIA Parabricks, Clara Imaging, BioMegatron, BioBERT, NVIDIA RAPIDS.”
We’re all hoping COVID-19 research – using such powerful new tools available to scientists – can lead to a vaccine within a year or two, when they have often taken a decade or longer to create.
“The use of big data, supercomputing, and artificial intelligence has the potential to transform research and development; from target identification through clinical research and all the way to the launch of new medicines,” commented James Weatherall, Ph.D., Head of Data Science and AI at AstraZeneca.
During his keynote, Huang provided more details about NVIDIA’s effort to build the UK’s fastest supercomputer – which will be used to further healthcare research – the Cambridge-1.
NVIDIA has established partnerships with companies leading the fight against COVID-19 and other viruses including AstraZeneca, GSK, King’s College London, the Guy’s and St Thomas’ NHS Foundation Trust, and startup Oxford Nanopore. These partners can harness Cambridge-1 for their vital research.
“Tackling the world’s most pressing challenges in healthcare requires massively powerful computing resources to harness the capabilities of AI,” said Huang. “The Cambridge-1 supercomputer will serve as a hub of innovation for the UK and further the groundbreaking work being done by the nation’s researchers in critical healthcare and drug discovery.”
And, for organisations wanting to set up their own AI supercomputers, NVIDIA has announced DGX SuperPODs as the world’s first turnkey AI infrastructure. The solution was developed from years of research for NVIDIA’s own work in healthcare, automotive, healthcare, conversational AI, recommender systems, data science and computer graphics.
While Huang has a nice kitchen, I’m sure he’d like to be back on the big stage for his GTC 2021 keynote. We’d certainly all love COVID-19 to be well and truly in the rear-view mirror.
(Photo by Elwin de Witte on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, astrazeneca, cambridge-1, clara discovery, coronavirus, covid-19, Featured, gsk, gtc, gtc 2020, health, healthcare, jensen huang, Nvidia, research, supercomputer, uk, vaccine






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",GTC 2020: Using AI to help put COVID-19 in the rear-view mirror,2020-10-05,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['scientists', 'research', 'using', 'mirror', '2020', 'healthcare', 'gtc', 'tools', 'expo', 'ai', 'help', 'huang', 'nvidia', 'nvidias', 'rearview', 'covid19']","AI is helping with COVID-19 research around the world and much of it is being powered by NVIDIA GPUs.
Nvidia wants to help speed up discoveries of vital medicines while reducing costs“COVID-19 hits home this urgency [for new tools],” Huang says.
NVIDIA Clara combines imaging, radiology, and genomics to help develop healthcare AI applications.
Dr Hal Barron, Chief Scientific Officer and President of R&D at GSK, commented:“AI and machine learning are like a new microscope that will help scientists to see things that they couldn’t see otherwise.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
83,https://artificialintelligence-news.com/2020/09/25/what-happens-google-bot-chats-with-chatbot/,"

What happens when Google’s chatty bot chats with a chatbot?




 






By Ryan Daws |
        September 25, 2020                    | TechForge Media

                            Categories:
                                    Bots,
                                    Google,
                                    Society,
                                    Speech Recognition,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Google Duplex impressed and scared the world in equal parts when it was unveiled, and now we’ve seen how a conversation goes with another chatbot.
Duplex, for a quick primer, is Google’s AI-powered voice bot which can call businesses on a person’s behalf for things such as booking hair appointments. It’s so realistic that everyone has decided that bots must declare themselves as such before chatting with a human.
A company known as PolyAI – which specialises in “enterprise-ready voice assistants” – has posted an account of what happened when Duplex called one of its restaurant assistants.
Duplex was calling businesses over the summer to update opening hours on Google Maps. This is how the conversation went:



Nikola Mrkšić, Co-Founder and CEO of PolyAI, wrote in a blog post:
“As far as we’re aware, this is the first naturally-occurring conversation between AI voice assistants in the wild.I have never seen anything like this before, and I’m incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.”
Mrkšić humbly admits that Duplex sounds far more human-like than PolyAI’s assistant. However, he also makes a valid reference to the “uncanny valley” theory.
The uncanny valley theory suggests that people are more positive towards something which sounds like a human, up until a point. When it sounds too much like a human then it becomes creepy—a sentiment which many have certainly shared about Duplex.
(Photo by Jeffery Ho on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, assistant, chatbot, duplex, Featured, Google, polyai, voice assistant






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",What happens when Google’s chatty bot chats with a chatbot?,2020-09-25,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['chatbot', 'happens', 'googles', 'chatty', 'voice', 'conversation', 'uncanny', 'expo', 'duplex', 'polyai', 'world', 'tech', 'valley', 'bot', 'chats', 'sounds']","Google Duplex impressed and scared the world in equal parts when it was unveiled, and now we’ve seen how a conversation goes with another chatbot.
Duplex, for a quick primer, is Google’s AI-powered voice bot which can call businesses on a person’s behalf for things such as booking hair appointments.
However, he also makes a valid reference to the “uncanny valley” theory.
The uncanny valley theory suggests that people are more positive towards something which sounds like a human, up until a point.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
84,https://artificialintelligence-news.com/2020/05/22/google-no-longer-build-ai-fossil-fuel-industry/,"

Google pledges to no longer build AIs for the fossil fuel industry




 






By Ryan Daws |
        May 22, 2020                    | TechForge Media

                            Categories:
                                    Energy,
                                    Google,
                                    Machine Learning,
                                    Policy,
                                    Society,
                                    TECHEX,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Google has pledged to no longer build AIs for the fossil fuel industry as it further distances itself from controversial developments.
A report from Greenpeace earlier this month exposed Google as being one of the top three developers of AI tools for the fossil fuel industry. Greenpeace found AI technologies boost production levels by as much as five percent.
In an interview with CUBE’s John Furrier, the leader of Google’s CTO office, Will Grannis, said that Google will “no longer develop artificial intelligence (AI) software and tools for oil and gas drilling operations.”



The pledge from Google Cloud is welcome, but it must be taken in a wider context.
In 2019, Google Cloud’s revenue from oil and gas was approximately $65 million. A hefty sum, but less than one percent of all Google Cloud revenues. Furthermore, Google Cloud’s revenue from oil and gas decreased by about 11 percent despite overall revenue growing by 53 percent.
While Google Cloud’s revenue from the oil and gas industry was declining, the public’s intolerance towards big polluters is increasing. The reputational damage caused to Google of continuing its relationship with polluters would likely have been more costly over the long-term.
This isn’t the first time Google has cut-off an AI-related relationship with a controversial industry to preserve its reputation.
Back in 2018, Google was forced into ending a contract with the Pentagon called Project Maven to build AI technologies for drones. Over 4,000 Google employees signed a petition demanding their management cease the project and never again “build warfare technology.”
Following the Project Maven backlash, Google CEO Sundar Pichai promised in a blog post the company will not develop technologies or weapons that cause harm, or anything which can be used for surveillance violating “internationally accepted norms” or “widely accepted principles of international law and human rights”.
Back in January, Pichai called for sensible AI regulation that does not limit the potential societal benefits.
PAX, a Dutch NGO, ranked Google among the safest companies developing AI while slamming rivals such as Amazon and Microsoft for being among the “highest risk” tech firms in the world.
(Photo by Zbynek Burival on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, climate change, environment, Featured, fossil fuels, Google, greenpeace






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Google pledges to no longer build AIs for the fossil fuel industry,2020-05-22,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['longer', 'ais', 'oil', 'technologies', 'build', 'revenue', 'fuel', 'fossil', 'pledges', 'ai', 'expo', 'google', 'gas', 'tech', 'industry', 'project']","Google has pledged to no longer build AIs for the fossil fuel industry as it further distances itself from controversial developments.
A report from Greenpeace earlier this month exposed Google as being one of the top three developers of AI tools for the fossil fuel industry.
While Google Cloud’s revenue from the oil and gas industry was declining, the public’s intolerance towards big polluters is increasing.
Back in 2018, Google was forced into ending a contract with the Pentagon called Project Maven to build AI technologies for drones.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
85,https://artificialintelligence-news.com/2020/07/09/neuralink-share-progress-linking-human-brains-ai/,"

Neuralink will share progress on linking human brains with AI next month




 






By Ryan Daws |
        July 9, 2020                    | TechForge Media

                            Categories:
                                    Hardware,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Elon Musk’s startup Neuralink says it will share progress next month on the company’s mission to link human brains with AI.
Musk made the announcement of the announcement on Twitter:

Progress update August 28— Elon Musk (@elonmusk) July 9, 2020

When Musk appeared on Joe Rogan’s podcast in September 2018, the CEO told Rogan that Neuralink’s long-term goal is to enable human brains to be “symbiotic with AI”, adding that the company would have “something interesting to announce in a few months, that’s at least an order of magnitude better than anything else; probably better than anyone thinks is possible”.
Neuralink held an event in San Francisco in July last year, during simpler times, where the company said it aims to insert electrodes into the brains of monkeys and humans to enable them to control computers.
“Threads” which are covered in the electrodes are implanted in the brain near the neurons and synapses by a robot surgeon. These threads record the information being transmitted onto a sensor called the N1.
That, of course, is a very simplified version of a rather complex task. During the event, Neuralink demonstrated that the company’s tech had already been successfully inserted into the brain of a rat and was able to record the information being transmitted by its neurons.
At the time, Musk said he wanted Neuralink to start human trials this year.
Neuralink went quiet since the event last year, with its Twitter account not making a single tweet since then. Now, it seems, the company is ready to share some notable progress.
(Photo by Robina Weermeijer on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, elon musk, Featured, neuralink






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Neuralink will share progress on linking human brains with AI next month,2020-07-09,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['event', 'human', 'brains', 'month', 'progress', 'neuralink', 'musk', 'transmitted', 'expo', 'share', 'ai', 'tech', 'linking', 'company']","Elon Musk’s startup Neuralink says it will share progress next month on the company’s mission to link human brains with AI.
At the time, Musk said he wanted Neuralink to start human trials this year.
Neuralink went quiet since the event last year, with its Twitter account not making a single tweet since then.
Now, it seems, the company is ready to share some notable progress.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
86,https://artificialintelligence-news.com/2020/02/21/mit-researchers-use-ai-to-discover-a-welcome-new-antibiotic/,"

MIT researchers use AI to discover a welcome new antibiotic




 






By Ryan Daws |
        February 21, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Machine Learning,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A team of MIT researchers have used AI to discover a welcome new antibiotic to help in the fight against increasing resistance.
Using a machine learning algorithm, the MIT researchers were able to discover a new antibiotic compound which did not develop any resistance during a 30-day treatment period on mice.
The algorithm was trained using around 2,500 molecules – including about 1,700 FDA-approved drugs and a set of 800 natural products – to seek out chemical features that make molecules effective at killing bacteria. 
After the model was trained, the researchers tested it on a library of about 6,000 compounds known as the Broad Institute’s Drug Repurposing Hub.
“We wanted to develop a platform that would allow us to harness the power of artificial intelligence to usher in a new age of antibiotic drug discovery,” explains James Collins, the Termeer Professor of Medical Engineering and Science in MIT’s Institute for Medical Engineering and Science (IMES) and Department of Biological Engineering.
“Our approach revealed this amazing molecule which is arguably one of the more powerful antibiotics that has been discovered.”
Antibiotic resistance is terrifying. Researchers have already discovered bacterias that are immune to current antibiotics and we’re very much in danger of illnesses that have become simple to treat becoming deadly once more.
Data from the Centers for Disease Control and Prevention (CDC) already indicates that antibiotic-resistant bacteria and antimicrobial-resistant fungi cause more than 2.8 million infections and 35,000 deaths a year in the United States alone.
“We’re facing a growing crisis around antibiotic resistance, and this situation is being generated by both an increasing number of pathogens becoming resistant to existing antibiotics, and an anaemic pipeline in the biotech and pharmaceutical industries for new antibiotics,” Collins says.
The recent coronavirus outbreak leaves many patients with pneumonia. With antibiotics, pneumonia is not often fatal nowadays unless a patient has a substantially weakened immune system. The current death toll for coronavirus would be much higher if antibiotic resistance essentially sets healthcare back to the 1930s.
MIT’s researchers claim their AI is able to check more than 100 million chemical compounds in a matter of days to pick out potential antibiotics that kill bacteria. This rapid checking reduces the time it takes to discover new lifesaving treatments and begins to swing the odds back in our favour.
The newly discovered molecule is called halicin – after the AI named Hal in the film 2001: A Space Odyssey – and has been found to be effective against E.coli. The team is now hoping to develop halicin for human use (a separate machine learning model has already indicated that it should have low toxicity to humans, so early signs are positive.)

 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, antibiotic resistance, antibiotics, artificial intelligence, Featured, health, healthcare, machine learning, medicine, mit, research






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",MIT researchers use AI to discover a welcome new antibiotic,2020-02-21,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['antibiotics', 'develop', 'researchers', 'trained', 'expo', 'resistance', 'ai', 'discover', 'tech', 'welcome', 'antibiotic', 'mit']","A team of MIT researchers have used AI to discover a welcome new antibiotic to help in the fight against increasing resistance.
Using a machine learning algorithm, the MIT researchers were able to discover a new antibiotic compound which did not develop any resistance during a 30-day treatment period on mice.
After the model was trained, the researchers tested it on a library of about 6,000 compounds known as the Broad Institute’s Drug Repurposing Hub.
The current death toll for coronavirus would be much higher if antibiotic resistance essentially sets healthcare back to the 1930s.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
87,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
88,https://artificialintelligence-news.com/categories/ethics/,"



Google is leaking AI talent following ethicist’s controversial firing










Some high-profile AI experts have departed Google after the controversial firing of leading ethicist Timnit Gebru.
Gebru was fired from Google after criticising the company’s practices in an email following a dispute over a paper she was told not to publish which questioned whether language models can be too big and whether they can increase prejudice and inequalities. In her email, Gebru also expressed frustration at the lack of progress in hiring women at... 






        5 February 2021                    |
            Ethics





",Ethics Archives,,[],"['scientists', 'topics', 'suggest', 'telling', 'archives', 'sensitive', 'ethics', 'spin', 'technologya', 'ai', 'review', 'google']","Google has reportedly been telling its scientists to give AI a “positive” spin in research papers.
Documents obtained by Reuters suggest that, in at least three cases, Google’s researchers were requested to refrain from being critical of AI technology.
A “sensitive topics” review was established by Google earlier this year to catch papers which cast a negative light on AI ahead of their publication.
Google asks its scientists to consult with legal,...",AInews
89,https://artificialintelligence-news.com/2020/10/19/microsoft-new-ai-auto-captions-images-visually-impaired/,"

Microsoft’s new AI auto-captions images for the visually impaired




 






By Ryan Daws |
        October 19, 2020                    | TechForge Media

                            Categories:
                                    Applications,
                                    Machine Learning,
                                    Microsoft,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A new AI from Microsoft aims to automatically caption images in documents and emails so that software for visual impairments can read it out.
Researchers from Microsoft explained their machine learning model in a paper on preprint repository arXiv.
The model uses VIsual VOcabulary pre-training (VIVO) which leverages large amounts of paired image-tag data to learn a visual vocabulary.
A second dataset of properly captioned images is then used to help teach the AI how to best describe the pictures.
“Ideally, everyone would include alt text for all images in documents, on the web, in social media – as this enables people who are blind to access the content and participate in the conversation. But, alas, people don’t,” said Saqib Shaikh, a software engineering manager with Microsoft’s AI platform group.
Overall, the researchers expect the AI to deliver twice the performance of Microsoft’s existing captioning system.
In order to benchmark the performance of their new AI, the researchers entered it into the ‘nocaps’ challenge. As of writing, Microsoft’s AI now ranks first on its leaderboard.
“The nocaps challenge is really how are you able to describe those novel objects that you haven’t seen in your training data?” commented Lijuan Wang, a principal research manager in Microsoft’s research lab.
Developers wanting to get started with building apps using Microsoft’s auto-captioning AI can already do so as it’s available in Azure Cognitive Services’ Computer Vision package.
Microsoft’s impressive SeeingAI application – which uses computer vision to describe an individual’s surroundings for people suffering from vision loss – will be updated with features using the new AI.
“Image captioning is one of the core computer vision capabilities that can enable a broad range of services,” said Xuedong Huang, Microsoft CTO of Azure AI Cognitive Services.
“We’re taking this AI breakthrough to Azure as a platform to serve a broader set of customers,” Huang continued. “It is not just a breakthrough on the research; the time it took to turn that breakthrough into production on Azure is also a breakthrough.”
The improved auto-captioning feature is also expected to be available in Outlook, Word, and PowerPoint later this year.
(Photo by K8 on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: artificial intelligence, arxiv, auto caption, azure, caption, cognitive services, computer vision, Featured, machine learning, microsoft, Model, paper, research, seeing ai, vivo






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Microsoft’s new AI auto-captions images for the visually impaired,2020-10-19,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['impaired', 'data', 'research', 'visual', 'autocaptions', 'microsofts', 'visually', 'images', 'ai', 'expo', 'microsoft', 'vision', 'azure']","A new AI from Microsoft aims to automatically caption images in documents and emails so that software for visual impairments can read it out.
A second dataset of properly captioned images is then used to help teach the AI how to best describe the pictures.
But, alas, people don’t,” said Saqib Shaikh, a software engineering manager with Microsoft’s AI platform group.
As of writing, Microsoft’s AI now ranks first on its leaderboard.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
90,https://artificialintelligence-news.com/2020/08/06/university-college-london-experts-deepfakes-ai-crime-threat/,"

University College London: Deepfakes are the ‘most serious’ AI crime threat




 






By Ryan Daws |
        August 6, 2020                    | TechForge Media

                            Categories:
                                    Deepfakes,
                                    Ethics,
                                    Machine Learning,
                                    Privacy,
                                    Research,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers from University College London have released a ranking of what experts believe to be the most serious AI crime threats.
The researchers first created a list of 20 expected ways AI will be used by criminals within the next 15 years. 31 experts were then asked to rank them by potential severity.
Deepfakes – AI-generated images, videos, and articles – ranked top of the list as the most serious threat.
New and dangerous territory
It’s of little surprise to see deepfakes rank so highly, given the existing issues with disinformation campaigns.
Most fake content today at least must be created by humans, such as those working in the likes of Russia’s infamous “troll farms”. Human-generated disinformation campaigns take time to produce to a convincing standard and often have patterns which make them easier to trace. 
Automating the production of fake content en masse, to influence things such as democratic votes and public opinion, is entering into new and dangerous territory.
One of the most high-profile deepfake cases so far was that of US house speaker Nancy Pelosi. In 2018, a deepfake video circulated on social media which made Pelosi appear drunk and slurring her words. Pelosi criticised Facebook’s response, or lack thereof, and later told California’s KQED: “I think they have proven — by not taking down something they know is false — that they were willing enablers of the Russian interference in our election.”
The deepfake of Pelosi was unsophisticated and likely created to be amusing rather than malicious, but it’s an early warning of how such fakes could be used to cause reputational damage – or worse. Just imagine the potential consequences a fake video of the president announcing an imminent strike on somewhere like North Korea could have.
Deepfakes also have obvious potential to be used for fraud purposes, to pretend to be someone else to access things like bank accounts and sensitive information.
Then there’s the issue of blackmail. Deep learning has already been used to put the faces of celebrities on adult performers. While fake, the threat to release such videos – and the embarrassment caused – could lead to some paying a ransom to keep it from being made public.
“People now conduct large parts of their lives online and their online activity can make and break reputations,” comments first author Dr Matthew Caldwell of UCL Computer Science. “Such an online environment, where data is property and information power, is ideally suited for exploitation by AI-based criminal activity.”
All in all, it’s easy to see why experts are so concerned about deepfakes.
As part of a bid to persuade Facebook to change its policies on deepfakes, Israeli startup Canny AI created a deepfake of Facebook CEO Mark Zuckerberg last year which made it appear like he said: “Imagine this for a second: One man, with total control of billions of people’s stolen data, all their secrets, their lives, their futures.”
Other AI crime threats
There were four other major AI crime threats identified by the researchers: the use of driverless cars as weapons, automated spear fishing, harvesting information for blackmail, and the disruption of AI-controlled systems.
“As the capabilities of AI-based technologies expand, so too has their potential for criminal exploitation,” explained senior author Professor Lewis Griffin of UCL Computer Science. “To adequately prepare for possible AI threats, we need to identify what these threats might be, and how they may impact our lives.”
Of medium concern were of things such as the sale of items and services wrongly called AI, such as security screening and targeted advertising solutions. The researchers believe leading people to believe they’re AI-powered could be lucrative.
Among the lesser concerns is things such as so-called “burglar bots” which could get in through access points of a property to unlock them or search for data. The researchers believe this poses less of a threat because they can be easily prevented through methods such as letterbox cages.
Similarly, the researchers note the potential for AI-based stalking is damaging for individuals but isn’t considered a major threat as it could not operate at scale.
You can find the researchers’ full paper in the Crime Science Journal here.
(Photo by Bill Oxford on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, crime, deepfakes, Featured, law, legal, privacy, research, Society, threats, university college london






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",University College London: Deepfakes are the ‘most serious’ AI crime threat,2020-08-06,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'pelosi', 'fake', 'crime', 'researchers', 'serious', 'things', 'deepfake', 'expo', 'london', 'deepfakes', 'university', 'ai', 'potential', 'college', 'threat', 'used']","Researchers from University College London have released a ranking of what experts believe to be the most serious AI crime threats.
The researchers first created a list of 20 expected ways AI will be used by criminals within the next 15 years.
Deepfakes – AI-generated images, videos, and articles – ranked top of the list as the most serious threat.
New and dangerous territoryIt’s of little surprise to see deepfakes rank so highly, given the existing issues with disinformation campaigns.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
91,https://artificialintelligence-news.com/2020/06/02/ai-data-oura-wearables-predict-covid19-three-days-early/,"

AI uses data from Oura wearables to predict COVID-19 three days early




 






By Ryan Daws |
        June 2, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers have successfully used AI to analyse data from Oura’s wearable rings and predict COVID-19 symptoms three days early.
The researchers, from WVU Medicine and the Rockefeller Neuroscience Institute, first announced the potentially groundbreaking project in April.
At the time, the researchers found they could predict COVID-19 symptoms – including fever, cough, and fatigue – up to 24 hours before their onset.
“The holistic and integrated neuroscience platform developed by the RNI continuously monitors the human operating system, which allows for the accurate prediction of the onset of viral infection symptoms associated with COVID-19,” said Ali Rezai, M.D., executive chair of the WVU Rockefeller Neuroscience Institute.
“We feel this platform will be integral to protecting our healthcare workers, first responders, and communities as we adjust to life in the COVID-19 era.”
Participants in the study were asked to log neurological symptoms like stress and anxiety in an app. The Oura ring, meanwhile, automatically tracks physiological data like body temperature, heart rate, and sleep patterns.
“We are hopeful that Oura’s technology will advance how people identify and understand our body’s most nuanced physiological signals and warning signs, as they relate to infectious diseases like COVID-19,” explained Harpreet Rai, CEO of Oura Health.
“Partnering with the Rockefeller Neuroscience Institute on this important study helps fulfil Oura’s vision of offering data for the public good and empowering individuals with the personal insights needed to lead healthier lives.”  
Using an AI prediction model, the researchers have improved their ability to track COVID-19 symptoms from 24 hours before their onset to three days.
The accuracy rate for the current system is 90 percent. While impressive, that does mean 100 people in every 1000 patients could be misdiagnosed if such a system was widely rolled out.
This isn’t the only research into the use of wearables to help tackle the COVID-19 pandemic – Fitbit is also conducting a large study into whether its popular wearables can detect markers which may indicate that a user is infected with the novel coronavirus and should therefore quarantine and seek a professional test.
With the COVID-19 pandemic looking set to disrupt our lives for the foreseeable future, it seems AI and wearables provide some hope of diagnosing cases earlier, limiting reinfection, and helping people return to some degree of normality.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, coronavirus, covid 19, Featured, health, healthcare, neuroscience, research, rockefeller neuroscience, science, study, symptoms, wearables, wvu medicine






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI uses data from Oura wearables to predict COVID-19 three days early,2020-06-02,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['early', 'data', 'uses', 'rockefeller', 'neuroscience', 'wearables', 'predict', 'expo', 'ai', 'symptoms', 'days', 'system', 'study', 'covid19', 'oura']","Researchers have successfully used AI to analyse data from Oura’s wearable rings and predict COVID-19 symptoms three days early.
The researchers, from WVU Medicine and the Rockefeller Neuroscience Institute, first announced the potentially groundbreaking project in April.
At the time, the researchers found they could predict COVID-19 symptoms – including fever, cough, and fatigue – up to 24 hours before their onset.
The Oura ring, meanwhile, automatically tracks physiological data like body temperature, heart rate, and sleep patterns.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
92,https://artificialintelligence-news.com/categories/google/,"



Google is leaking AI talent following ethicist’s controversial firing










Some high-profile AI experts have departed Google after the controversial firing of leading ethicist Timnit Gebru.
Gebru was fired from Google after criticising the company’s practices in an email following a dispute over a paper she was told not to publish which questioned whether language models can be too big and whether they can increase prejudice and inequalities. In her email, Gebru also expressed frustration at the lack of progress in hiring women at... 






        5 February 2021                    |
            Ethics





",Google Archives,,[],"['scientists', 'topics', 'suggest', 'telling', 'archives', 'sensitive', 'spin', 'technologya', 'ai', 'review', 'google']","Google has reportedly been telling its scientists to give AI a “positive” spin in research papers.
Documents obtained by Reuters suggest that, in at least three cases, Google’s researchers were requested to refrain from being critical of AI technology.
A “sensitive topics” review was established by Google earlier this year to catch papers which cast a negative light on AI ahead of their publication.
Google asks its scientists to consult with legal,...",AInews
93,https://artificialintelligence-news.com/2020/04/08/clearview-ai-found-extensive-ties-far-right/,"

Clearview AI has been found to have extensive far-right ties




 






By Ryan Daws |
        April 8, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Face Recognition,
                                    Law Enforcement,
                                    Privacy,
                                    Society,
                                    Surveillance,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Controversial facial recognition firm Clearview AI has been found to have extensive ties to far-right individuals and movements.
Clearview AI has come under scrutiny for scraping billions of photos from across the internet and storing them in a database for powerful facial recognition services. Privacy activists criticise the practice as the people in those images never gave their consent.
“Common law has never recognised a right to privacy for your face,” Clearview AI lawyer Tor Ekeland said recently. “It’s kind of a bizarre argument to make because [your face is the] most public thing out there.”
The company’s facial recognition system is used by over 600 law enforcement agencies. Furthermore, a recent leak revealed its client list also includes commercial businesses like Best Buy and Macy’s.
As if the company’s system wasn’t dystopian enough, an extensive investigation by The Huffington Post has revealed extensive links to some rather unsavoury people and movements.
Clearview AI founder Hoan Ton-That reportedly attended a 2016 dinner with white supremacist Richard Spencer that was organised by Jeff Giesea, a financier of the “alt-right” and associate of Palantir founder Peter Thiel.
Ton-That was also part of a Slack channel run by far-right activist Chuck Johnson, known for running crowdfunding platform WeSearchr that was predominately used by white supremacists. The Slack channel also included the webmaster of neo-Nazi website Daily Stormer, conspiracy theorist Mike Cernovich, and self-avowed “internet troll” Andrew Auernheimer (Auernheimer was among the first clients of Clearview AI lawyer Ekeland).
In January 2017, Chuck Johnson bragged on Facebook that he was “building algorithms to ID all the illegal immigrants for the deportation squads.” A source for Huffington Post said they’d seen Johnson discussing that project with a “bunch of really important people” at Trump’s hotel in DC and introducing them to a man that was likely Ton-That.
According to ex-Breitbart editor and former alt-right member Katie McHugh, Johnson asked to be put in touch with Trump advisor Stephen Miller to pitch a “way to identify every illegal alien in the country.”
Back when Clearview AI was known as Smartcheckr, the firm contracted Douglass Mackey who pitched the company’s technology to anti-Semitic congressional candidate Paul Nehlen for extreme campaign opposition research. Mackey was later found to be the overseer of a racist propaganda operation under the pseudonym of Ricky Vaughn. Ton-That told Huffington Post that Mackey was only contracted for three weeks and wasn’t authorised to make the offer to Nehlen.
An employee of Clearview AI, Marko Jukic, marketed the company’s technology to police departments. Jukic “published many thousands of extremist words on neoreactionary blogs,” according to Huffington Post.
Jukic’s publishings advocated the segregation of Jews, the “generous use” of racial profiling, using military force to “pacify” the “ghettos,” normalising the use of racist terminology, the replacement of democracy with authoritarianism, the assassination of journalists, and praising the ethnonationalism of Putin’s Russia while musing the collapse of the US because of “America’s diversity problem”.
As the founder of Clearview AI, Ton-That claims to have disassociated from far-right views, movements, and individuals. He told Huffington Post that growing up on the internet did not “serve him well” and “there was a period when I explored a range of ideas—not out of belief in any of them, but out of a desire to search for self and place in the world. I have finally found it, and the mission to help make America a safer place.”
You can read Huffington Post’s full investigation into Clearview AI’s far-right links here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: clearview ai, facial recognition, far right, Featured, privacy, Society, surveillance






View Comments


Leave a comment




            One comment on “Clearview AI has been found to have extensive far-right ties”        




 



                                                yurii on
                        
 April 27th, 2020 - 8:29am 



“praising the ethnonationalism of Putin’s Russia” Lol, Putin’s Russia is the second in the world by number of migrants, there’s about 2 million musilms in Moscow alone and far right parties and movements are almost completely banned.

Log in to Reply 






Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Clearview AI has been found to have extensive far-right ties,2020-04-08,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It."", 'Yurii On']","['huffington', 'recognition', 'clearview', 'tonthat', 'farright', 'expo', 'ai', 'companys', 'post', 'ties', 'johnson', 'extensive']","Controversial facial recognition firm Clearview AI has been found to have extensive ties to far-right individuals and movements.
Clearview AI has come under scrutiny for scraping billions of photos from across the internet and storing them in a database for powerful facial recognition services.
“Common law has never recognised a right to privacy for your face,” Clearview AI lawyer Tor Ekeland said recently.
As the founder of Clearview AI, Ton-That claims to have disassociated from far-right views, movements, and individuals.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
94,https://artificialintelligence-news.com/2020/07/21/deepcode-ai-code-reviews-four-million-developers/,"

DeepCode provides AI code reviews for over four million developers




 






By Ryan Daws |
        July 21, 2020                    | TechForge Media

                            Categories:
                                    Applications,
                                    Developers,
                                    Machine Learning,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




AI-powered code reviewer DeepCode has announced it’s checked the code of over four million developers.
DeepCode’s machine learning-based bot is fluent in JavaScript, TypeScript, Java, C/C++, and Python.
“Our data shows that over 50% of repositories have critical issues and every second pull-request has warnings about issues that need to be fixed,” said Boris Paskalev, CEO and co-founder of DeepCode.
“By using DeepCode, these issues are automatically identified and logically explained as suggestions are made about how to fix them before code is deployed.”



Over the past few months, DeepCode has focused on improving the JavaScript skills of the bot. JavaScript frameworks and libraries such as Vue.js and React are supported. A demo of DeepCode’s analysis of React can be found here.
DeepCode claims its bot is now “up to 50x faster and finding more than double the number of serious bugs over all other tools combined while maintaining over 80% accuracy.”
The bot has been trained using machine learning to analyse hundreds of millions of commits across the vast number of open source projects freely available. DeepCode says it’s able to identify bugs before they happen.
A recent survey by DeepCode found that 85 percent of people want software companies to focus less on new features and more on fixing bugs and security issues.
“Too many software companies still believe that new features are what users want the most,” commented Paskalev. “As this survey shows, what people really want is quality software that is safe to use.”

DeepCode is free for open source software and commercial teams of up to 30 developers. You can start analysing your code by connecting your GitHub, BitBucket, or GitLab account here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, code review, coding, deepcode, developer, Featured, machine learning, software






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",DeepCode provides AI code reviews for over four million developers,2020-07-21,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['provides', 'issues', 'code', 'developers', 'using', 'reviews', 'million', 'expo', 'ai', 'tech', 'software', 'javascript', 'bot', 'deepcode', 'bugs']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
AI-powered code reviewer DeepCode has announced it’s checked the code of over four million developers.
“By using DeepCode, these issues are automatically identified and logically explained as suggestions are made about how to fix them before code is deployed.”Over the past few months, DeepCode has focused on improving the JavaScript skills of the bot.
You can start analysing your code by connecting your GitHub, BitBucket, or GitLab account here.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
95,https://artificialintelligence-news.com/2020/04/01/ai-project-diagnose-covid-19-voice-analysis/,"

AI project aims to diagnose COVID-19 using voice analysis




 






By Ryan Daws |
        April 1, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Society,
                                    Speech Recognition,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers from Carnegie Mellon University are developing an AI-powered voice analysis system for diagnosing COVID-19.
Governments around the world are racing to obtain sufficient and effective testing kits to diagnose COVID-19. The current widely-used test requires a thin cotton swab to be put up the nasal cavity and reach to the back of the throat. It’s not a painful procedure, but it’s invasive and uncomfortable.
COVID-19 tests which only require a finger prick are starting to be rolled out but obtaining sufficient numbers of any test is proving difficult. On Tuesday, British cabinet minister Michael Gove said the UK was being hindered by the global shortage of chemical reagents needed for testing.
If the researchers from Carnegie Mellon are successful, a test that could be taken at home instantly could be rolled out. While it’s unlikely to ever be as accurate as a full test, it could help to prioritise where limited resources should be allocated and determine which households are more likely to be suffering from seasonal flu.
Speaking to Futurism, Benjamin Striner, a graduate working on the project, said: “I’ve seen a lot of competition for the cheapest, fastest diagnosis you can have.”
“And there are some pretty good ones that are actually really cheap and pretty accurate, but nothing’s ever going to be as cheap and as easy as speaking into a phone.”
Coronavirus is a respiratory illness and therefore affects breathing patterns and other vital parameters. The AI system analyses a person’s voice and provides a score on the likelihood that the individual has coronavirus based on markers observed from known sufferers.
The researchers are currently asking both healthy and infected people to share a recording of their voice to help improve the algorithm.
Yours truly has already submitted his voice. The process takes around five minutes and requires the following seven steps:
Submit basic demographic information.Cough three times.Say ‘a’ for as long as you can.Say ‘o’ for as long as you can.Say ‘e’ for as long as you can.Count to 20.Say the alphabet.
Be aware the app is still in its early stages and is not yet approved by agencies like the FDA or CDC. The app should also not be used as a substitute for a proper medical test or examination if you’re concerned you may have COVID-19.
If you’re interested, you can access the COVID Voice Detector here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, carnegie mellon, coronavirus, covid 19, diagnose, Featured, health, healthcare






View Comments


Leave a comment




            One comment on “AI project aims to diagnose COVID-19 using voice analysis”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI project aims to diagnose COVID-19 using voice analysis,2020-04-01,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['rolled', 'using', 'test', 'voice', 'sufficient', 'analysis', 'expo', 'world', 'ai', 'tech', 'youre', 'system', 'long', 'covid19', 'aims', 'project', 'diagnose']","Researchers from Carnegie Mellon University are developing an AI-powered voice analysis system for diagnosing COVID-19.
Governments around the world are racing to obtain sufficient and effective testing kits to diagnose COVID-19.
COVID-19 tests which only require a finger prick are starting to be rolled out but obtaining sufficient numbers of any test is proving difficult.
The AI system analyses a person’s voice and provides a score on the likelihood that the individual has coronavirus based on markers observed from known sufferers.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
96,https://artificialintelligence-news.com/tag/artificial-intelligence/,"



Researchers find systems to counter deepfakes can be deceived










Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:
""Our work shows that attacks on deepfake detectors could be a real-world threat.More alarmingly, we demonstrate that it's... 






        10 February 2021                    |
            Deepfakes





",artificial intelligence Archives,,[],"['diego', 'systems', 'student', 'researchers', 'wacv', 'archives', 'work', 'threatmore', 'university', 'artificial', 'intelligence', 'uc', 'san']","Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:""Our work shows that attacks on deepfake detectors could be a real-world threat.
More alarmingly, we demonstrate that it's...",AInews
97,https://artificialintelligence-news.com/events/,"









Data Centre Congress 2021 – 4th March 2021

04 March 2021 - 04 March 2021



",Events Archive,,[],"['virgin', 'saint', 'united', 'republic', 'guinea', 'sudan', 'archive', 'events', 'island', 'south', 'french', 'islands']","Country *Country United Kingdom United States Afghanistan Albania Algeria American Samoa Andorra Angola Anguilla Antarctica Antigua and Barbuda Argentina Armenia Aruba Australia Austria Azerbaijan Bahamas Bahrain Bangladesh Barbados Belarus Belgium Belize Benin Bermuda Bhutan Bolivia Bonaire, Sint Eustatius and Saba Bosnia and Herzegovina Botswana Bouvet Island Brazil British Indian Ocean Territory Brunei Darussalam Bulgaria Burkina Faso Burundi Cambodia Cameroon Canada Cape Verde Cayman Islands Central African Republic Chad Chile China Christmas Island Cocos Islands Colombia Comoros Congo, Democratic Republic of the Congo, Republic of the Cook Islands Costa Rica Croatia Cuba Curaçao Cyprus Czech Republic Côte d'Ivoire Denmark Djibouti Dominica Dominican Republic Ecuador Egypt El Salvador Equatorial Guinea Eritrea Estonia Eswatini (Swaziland) Ethiopia Falkland Islands Faroe Islands Fiji Finland France French Guiana French Polynesia French Southern Territories Gabon Gambia Georgia Germany Ghana Gibraltar Greece Greenland Grenada Guadeloupe Guam Guatemala Guernsey Guinea Guinea-Bissau Guyana Haiti Heard and McDonald Islands Holy See Honduras Hong Kong Hungary Iceland India Indonesia Iran Iraq Ireland Isle of Man Israel Italy Jamaica Japan Jersey Jordan Kazakhstan Kenya Kiribati Kuwait Kyrgyzstan Lao People's Democratic Republic Latvia Lebanon Lesotho Liberia Libya Liechtenstein Lithuania Luxembourg Macau Macedonia Madagascar Malawi Malaysia Maldives Mali Malta Marshall Islands Martinique Mauritania Mauritius Mayotte Mexico Micronesia Moldova Monaco Mongolia Montenegro Montserrat Morocco Mozambique Myanmar Namibia Nauru Nepal Netherlands New Caledonia New Zealand Nicaragua Niger Nigeria Niue Norfolk Island North Korea Northern Mariana Islands Norway Oman Pakistan Palau Palestine, State of Panama Papua New Guinea Paraguay Peru Philippines Pitcairn Poland Portugal Puerto Rico Qatar Romania Russia Rwanda Réunion Saint Barthélemy Saint Helena Saint Kitts and Nevis Saint Lucia Saint Martin Saint Pierre and Miquelon Saint Vincent and the Grenadines Samoa San Marino Sao Tome and Principe Saudi Arabia Senegal Serbia Seychelles Sierra Leone Singapore Sint Maarten Slovakia Slovenia Solomon Islands Somalia South Africa South Georgia South Korea South Sudan Spain Sri Lanka Sudan Suriname Svalbard and Jan Mayen Islands Sweden Switzerland Syria Taiwan Tajikistan Tanzania Thailand Timor-Leste Togo Tokelau Tonga Trinidad and Tobago Tunisia Turkey Turkmenistan Turks and Caicos Islands Tuvalu US Minor Outlying Islands Uganda Ukraine United Arab Emirates Uruguay Uzbekistan Vanuatu Venezuela Vietnam Virgin Islands, British Virgin Islands, U.S. Wallis and Futuna Western Sahara Yemen Zambia Zimbabwe Åland Islands",AInews
98,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
99,https://artificialintelligence-news.com/author/ryan/,"



Researchers find systems to counter deepfakes can be deceived










Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:
""Our work shows that attacks on deepfake detectors could be a real-world threat.More alarmingly, we demonstrate that it's... 






        10 February 2021                    |
            Deepfakes





","Ryan Daws, Author at AI News",,['Ryan Daws'],"['diego', 'systems', 'student', 'researchers', 'wacv', 'work', 'threatmore', 'ai', 'ryan', 'author', 'university', 'daws', 'uc', 'san']","Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California - San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:""Our work shows that attacks on deepfake detectors could be a real-world threat.
More alarmingly, we demonstrate that it's...",AInews
100,https://artificialintelligence-news.com/2021/01/18/nhs-use-ai-improve-covid19-treatment-shorten-hospital-stays/,"

NHS will use AI to improve COVID-19 treatment and shorten hospital stays




 






By Ryan Daws |
        January 18, 2021                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Society,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The UK’s NHS (National Health Service) will use AI to help improve the outcome for COVID-19 patients and reduce their time spent in hospital.
While the UK’s vaccine rollout is among the fastest in the world – certainly in comparison to its European peers – a series of late lockdowns and initial lack of PPE equipment has put the health service under immense pressure and left the country with one of the highest COVID-19 deaths rates per capita.
The latest lockdown was imposed after ministers were warned the NHS would collapse within a few weeks, leaving Britons unable to access care for any reason. Paramedics have already reported patients dying in ambulances queued outside of hospitals and research from King’s College London suggests around half of ICU staff are suffering from PTSD and problem drinking due to the scenes they’ve witnessed and pressure they’re under.
NHSX, the digital innovation arm of the health service, is now providing access to the National COVID-19 Chest Imaging Database (NCCID) to hospitals and universities across the country to help speed up the diagnosis of the virus and help to reduce the pressure on the health service. 
Clinicians at Addenbrooke’s Hospital in Cambridge are developing an algorithm based on the NCCID images to help inform a more accurate diagnosis of patients when they present to hospital with potential COVID-19 symptoms and have not yet had a confirmed test.
Matt Hancock, Secretary of State for Health and Social Care, said:
“The use of artificial intelligence is already beginning to transform patient care by making the NHS a more predictive, preventive, and personalised health and care service.It is vital we always search for new ways to improve care, especially as we fight the pandemic with the recovery beyond. This excellent work is testament to how technology can help to save lives in the UK.”
The ability of clinicians to identify the virus in its earliest stages greatly increases the chance that interventions will prevent a progression to severe complications which require longer stays, extra resources, cause more suffering, and will inevitably lead to further deaths.
Carola-Bibiane Schönlieb, Professor of Applied Mathematics and head of the Cambridge Image Analysis group at the University of Cambridge, explained:
“The NCCID has been invaluable in accelerating our research and provided us with a diverse, well-curated, dataset of UK patients to use in our algorithm development.The ability to access the data for 18 different trusts centrally has increased our efficiency and ensures we can focus most of our time on designing and implementing the algorithms for use in the clinic for the benefit of patients.By understanding in the early stages of disease, whether a patient is likely to deteriorate, we can intervene earlier to change the course of their disease and potentially save lives as a result.”
Beyond COVID-19, the AI tools being developed are expected to help spot signs of other conditions. A ‘national AI imaging platform’ is being explored to help spot things such as cancers and heart disease in their earliest and most treatable forms.
A £140 million AI award has been established this year in collaboration with the Accelerated Access Collaborative (AAC) and National Institute for Health Research (NIHR) to speed up the deployment of AI technologies to benefit patients and staff across health and care.
Dominic Cushnan, Head of AI Imaging at NHSX, commented: “The industrial scale collaboration of the NHS, research and innovators on this project alone has demonstrated the huge potential and benefits of technology in transforming care.”
(Photo by Grooveland Designs on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, coronavirus, covid, covid-19, Featured, nhs, uk






View Comments


Leave a comment




            One comment on “NHS will use AI to improve COVID-19 treatment and shorten hospital stays”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",NHS will use AI to improve COVID-19 treatment and shorten hospital stays,2021-01-18,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['improve', 'treatment', 'research', 'covid19', 'service', 'care', 'expo', 'ai', 'hospital', 'help', 'shorten', 'nhs', 'patients', 'health', 'stays']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
The UK’s NHS (National Health Service) will use AI to help improve the outcome for COVID-19 patients and reduce their time spent in hospital.
Matt Hancock, Secretary of State for Health and Social Care, said:“The use of artificial intelligence is already beginning to transform patient care by making the NHS a more predictive, preventive, and personalised health and care service.
It is vital we always search for new ways to improve care, especially as we fight the pandemic with the recovery beyond.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
101,https://artificialintelligence-news.com/2020/07/15/british-ai-graphcore-nvidia-gc200-processor/,"

British AI chipmaker Graphcore claims Nvidia’s crown with GC200 processor




 






By Ryan Daws |
        July 15, 2020                    | TechForge Media

                            Categories:
                                    Hardware,
                                    UK,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Graphcore, a British AI chipmaker, has unveiled a powerful new processor which takes Nvidia’s crown.
Bristol-based Graphcore ranked number one on Fast Company’s top 10 most innovative AI companies of 2020 list. Nvidia, for comparison, ranked fifth.
Fast Company’s confidence in Graphcore clearly isn’t misplaced. Announcing its GC200 processor, Graphcore says its new chip is the world’s most complex.
The GC200 processor boasts 59.4 billion transistors and takes the crown from Nvidia’s A100 as the world’s largest. The A100 was announced by Nvidia earlier this year and features 54 billion transistors.



Each GC200 chip has 1,472 independent processor cores and 8,832 separate parallel threads, all supported by 900MB of in-processor RAM.
Graphcore says that up to 64,000 of the 7nm GC200 chips can be linked to create a massive parallel processor with around 16 exaflops of computational power and petabytes of power. Such a system would be able to support AI models with trillions of parameters.
“We are impressed with Graphcore’s technology for energy-efficient construction and execution of large, next-generation ML models, and we expect significant performance gains for several of our AI-oriented research projects in medical imaging and cardiac simulations,” comments Are Magnus Bruaset, Research Director at Simula Research Laboratory.
“We are also pursuing other avenues of research that can push the envelope for Graphcore’s multi-IPU systems, such as how to efficiently conduct large-scale, sparse linear algebra operations commonly found in physics-based HPC workloads.”
The GC200 is just the second chip to be launched by Graphcore. Compared to the first generation, the GC200 delivers an up to 9.3x performance increase.

Graphcore’s founders believe the IPU approach that the company is taking is more efficient than Nvidia’s GPU route. The ability to scale up to thousands of IPU processors in existing compute infrastructures could mean that the cost could be 10-20x lower than using GPUs.
Back in February, Graphcore announced that it had raised $150 million in funding for its R&D. The company’s total valuation is $1.95 billion.
Graphcore was fortunate to have secured its cash before the COVID-19 pandemic really hit – with many startups reporting difficulties obtaining vital funding where there was previous interest. Undoubtedly, the GC200 will help to power research to get us through this pandemic and all the other challenges the world faces now and in the future.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, chip, Featured, gc200, graphcore, hardware, processor, uk






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",British AI chipmaker Graphcore claims Nvidia’s crown with GC200 processor,2020-07-15,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['claims', 'british', 'gc200', 'research', 'power', 'crown', 'chip', 'graphcore', 'expo', 'companys', 'ai', 'nvidias', 'chipmaker', 'processor']","Graphcore, a British AI chipmaker, has unveiled a powerful new processor which takes Nvidia’s crown.
Announcing its GC200 processor, Graphcore says its new chip is the world’s most complex.
The GC200 processor boasts 59.4 billion transistors and takes the crown from Nvidia’s A100 as the world’s largest.
Each GC200 chip has 1,472 independent processor cores and 8,832 separate parallel threads, all supported by 900MB of in-processor RAM.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
102,https://artificialintelligence-news.com/2020/04/09/apple-acquires-voysis-to-boost-siris-language-skills/,"

Apple acquires Voysis to boost Siri’s language skills




 



 

By James Bourne |
        April 9, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Apple,
                                    Speech Recognition,
                                    Virtual Assistants,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




Apple has reportedly acquired Irish AI startup Voysis, with the move set to help enhance Siri’s skill at natural language understanding.
Voysis specialises in improving digital assistants inside online shopping applications wherein the software could respond more precisely to voice commands. According to the start-up, its technology could narrow product search results by processing shopping phrases like “I need a new LED TV” and “My budget is $1,000.” This AI was provided to other companies for use in their own applications and voice assistants.
The acquisition of Voysis would give Siri an edge to perform better than the Google Assistant, which many in the industry say has a notable lead in natural language comprehension and processing.
Voysis uses an AI-based method called WaveNets to create more human-like computer speech. In 2018, co-founder Peter Cahill had said that his company managed to shrink its system to the point where, once the AI is trained, the software uses as little as 25MB of memory, which makes it easier to run on smartphones without an internet connection.
This is not the first instance where Apple has made a big bet in this space. In January, Apple acquired Seattle-based edge AI specialist Xnor.ai for approximately $200m. Xnor.ai is the same company that once powered the person-detection feature on Wyze’s popular cameras. The Cupertino-based tech giant has been on something of an AI acquisition spree in recent years. A report by CBInsights found that Apple acquired more AI firms (20) than any other leading tech company in 2019.
This time last year, Apple acquired AI company Laserlike to add to its growing roster of in-house talent. Laserlike is known for its AI-powered app which makes it easier for users to follow news topics. Most notably, it was founded by former Google engineers.
Photo by Medhat Dawoud on Unsplash

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, apple, Voysis






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Apple acquires Voysis to boost Siri’s language skills,2020-04-09,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['xnorai', 'acquired', 'language', 'skills', 'acquires', 'boost', 'voysis', 'james', 'expo', 'tech', 'ai', 'world', 'siris', 'company', 'apple']","Apple has reportedly acquired Irish AI startup Voysis, with the move set to help enhance Siri’s skill at natural language understanding.
In January, Apple acquired Seattle-based edge AI specialist Xnor.ai for approximately $200m.
A report by CBInsights found that Apple acquired more AI firms (20) than any other leading tech company in 2019.
This time last year, Apple acquired AI company Laserlike to add to its growing roster of in-house talent.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
103,https://artificialintelligence-news.com/2020/04/23/qa-anton-fedotov-airband-technologies-on-how-ai-is-tackling-air-pollution/,"

Q&A: Anton Fedotov, Airband Technologies: On how AI is tackling air pollution




 



 

By James Bourne |
        April 23, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Adoption,
                                    Energy,
                                    Government,
                                    TECHEX,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




The ongoing Covid-19 pandemic has been described, in the words of one executive in the air pollution space, as ‘the biggest single global intervention you will ever see.’ Cars almost entirely remain in their garages; commercial aeroplanes lay dormant.
When the crisis ends, it will in some ways be a statistician’s dream. The amount of data which will be able to be extrapolated will be huge, for both scientists and businesses working in this field.
One such business is Airband Technologies. The UK- based company urges businesses, consumers and governments to ‘take the cleaner path’ through a smart, wearable air sensor. The sensor aims to help monitor air pollution and use intelligent routing with real-time data.

AI News caught up with Anton Fedotov (left), co-founder of Airband Technologies, to discuss his company’s vision for cleaner air, as well as the artificial intelligence (AI) technologies being employed to make it happen.
—
AI News: Hi Anton. Tell me about your career to date and role and responsibilities at Airband?
Anton Fedotov: I began Airband with a group of co-founders a little over a year ago. We began with an idea, and have spent the year working hard on developing it into something real and physical. Throughout that time, I have been leading the process as CEO of the company – I am involved both in the development of our product, as well as the development of our business, including reaching out and finding prospective investors and clients.
AI: How did the concept for Airband come about?
AF: Our lead engineer was doing research on a project about air pollution, which led him to realise the sheer lack of data which is out there – there is almost nothing aside from a few stationary monitoring sites spread out across larger city. Even data which can be purchased comes from modelling the spread starting from a relatively small dataset. Seeing the development of IoT, crowdsourced, and wearable technologies was our inspiration for a wearable air sensor, which can contribute to a massive granular dataset and help solve the pollution problem.
AI: Tell us about Airband’s wearable air pollution monitor and how AI technologies are being used for it?
AF: Our wearable pollution monitor is a revolutionary device which measures the quality of the air around the user, rather than a fixed space. It provides personalised pollution readings for the area and for the day to people, and it helps employers keep track of and manage their employees’ exposure for high-risk jobs. Airband makes use of AI to maximise sensor potential and extrapolate data, as well as maintaining calibration across the network. Finally, our predictive AQI technology uses AI to predict air quality in gaps of the network, making it the most detailed map of air pollution ever.
AI: What are some of the partnerships Airband is putting together with other companies in this space and how important are partnerships in achieving your goals?
AF: Airband is always on the lookout for partnerships, which will be fundamental to achieving our goals. We are looking at partnerships with service and hardware providers in the IoT sphere to help us develop and deploy both our product and future products across industries. We also are looking for partners in the data science sphere in order to maximise the potential of the data we collect, and help complement our dataset with existing monitoring solutions.
AI: What other initiatives are interesting to you in the green tech space and why?
AF: There are many amazing initiatives in the green tech space which are going on at the moment – some companies are aiming to directly reduce pollution by creating air “Scrubbers” which could serve to clean up the air around busy streets. Other companies are working on making plastics recyclable or even entirely bio-degradable. Perhaps one of the most interesting angles is the companies bringing easier choices to environmentally minded consumers, by providing either information or alternatives when buying reusable products or travelling.
AI: What can we expect from Airband (on the basis of business as usual) for the next 12 months and beyond?
AF: In the next 12 months, Airband hopes to deliver to initial business clients for businesses interested in protecting their employees. The development of our product and data network will be ongoing, and we should be able to start generating meaningful data, showcasing the utility of our product. Over the next 2-3 years, we hope to also expand into the consumer sector, and make the wearable air quality sensor available for all, at an affordable price.
Photo by Thomas Millot on Unsplash

Interested in hearing industry leaders like Airband discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






","Q&A: Anton Fedotov, Airband Technologies: On how AI is tackling air pollution",2020-04-23,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['space', 'data', 'business', 'pollution', 'technologies', 'air', 'airband', 'expo', 'ai', 'sensor', 'tackling', 'fedotov', 'wearable', 'qa', 'anton']","The UK- based company urges businesses, consumers and governments to ‘take the cleaner path’ through a smart, wearable air sensor.
AI News caught up with Anton Fedotov (left), co-founder of Airband Technologies, to discuss his company’s vision for cleaner air, as well as the artificial intelligence (AI) technologies being employed to make it happen.
AI: Tell us about Airband’s wearable air pollution monitor and how AI technologies are being used for it?
Finally, our predictive AQI technology uses AI to predict air quality in gaps of the network, making it the most detailed map of air pollution ever.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
104,https://artificialintelligence-news.com/categories/intel/,"



Intel, Ubotica, and the ESA launch the first AI satellite










Intel, Ubotica, and the European Space Agency (ESA) have launched the first AI satellite into Earth’s orbit.
The PhiSat-1 satellite is about the size of a cereal box and was ejected from a rocket’s dispenser alongside 45 other satellites. The rocket launched from Guiana Space Centre on September 2nd.
Intel has integrated its Movidius Myriad 2 Vision Processing Unit (VPU) into PhiSat-1 – enabling large amounts of data to be processed on the device. This helps to... 






        20 October 2020                    |
            Edge





",Intel Archives,,[],"['space', 'phisat1', 'satellite', 'launched', 'unit', 'archives', 'ubotica', 'satellites', 'intel', 'vision', 'vpu', 'size']","Intel, Ubotica, and the European Space Agency (ESA) have launched the first AI satellite into Earth’s orbit.
The PhiSat-1 satellite is about the size of a cereal box and was ejected from a rocket’s dispenser alongside 45 other satellites.
The rocket launched from Guiana Space Centre on September 2nd.
Intel has integrated its Movidius Myriad 2 Vision Processing Unit (VPU) into PhiSat-1 – enabling large amounts of data to be processed on the device.
This helps to...",AInews
105,https://artificialintelligence-news.com/categories/agi/,"



Full-stack AI solution SingularityNET switches Ethereum for Cardano










Full-stack AI solution SingularityNET is switching the Ethereum blockchain for peer-reviewed rival Cardano.
SingularityNET is a decentralised AI marketplace which has the ultimate goal of forming the basis for the emergence of the world’s first true Artificial General Intelligence (AGI).
One of the brightest and most respected minds in AI leads the SingularityNET project, Dr Ben Goertzel.
“Current speed and cost issues with the Ethereum blockchain have... 






        1 October 2020                    |
            AGI





",AGI Archives,,[],"['true', 'ethereum', 'speed', 'solution', 'agi', 'archives', 'worlds', 'ai', 'blockchain', 'singularitynet', 'switching', 'ultimate']","Full-stack AI solution SingularityNET is switching the Ethereum blockchain for peer-reviewed rival Cardano.
SingularityNET is a decentralised AI marketplace which has the ultimate goal of forming the basis for the emergence of the world’s first true Artificial General Intelligence (AGI).
One of the brightest and most respected minds in AI leads the SingularityNET project, Dr Ben Goertzel.
“Current speed and cost issues with the Ethereum blockchain have...",AInews
106,https://artificialintelligence-news.com/categories/security/,"



Boeing-SparkCognition joint venture SkyGrid deploys AI to protect drones










SkyGrid, a Boeing-SparkCognition joint venture, has launched the world’s first AI-powered security for drones.
Drones are being used for increasingly critical purposes, including carrying vital medical supplies. Security is paramount to build the trust necessary to unlock the full potential of the emerging industry.
Amir Husain, CEO and founder of SparkCognition and SkyGrid, said:
“In the near future, we’ll essentially have a network of flying computers... 






        20 January 2021                    |
            Drones





",Security Archives,,[],"['supplies', 'security', 'trust', 'unlock', 'sparkcognition', 'archives', 'worlds', 'skygrid', 'vital', 'used', 'venture']","SkyGrid, a Boeing-SparkCognition joint venture, has launched the world’s first AI-powered security for drones.
Drones are being used for increasingly critical purposes, including carrying vital medical supplies.
Security is paramount to build the trust necessary to unlock the full potential of the emerging industry.
Amir Husain, CEO and founder of SparkCognition and SkyGrid, said:“In the near future, we’ll essentially have a network of flying computers...",AInews
107,https://artificialintelligence-news.com/events/2021/jan/12/ai-big-data-expo-global-virtual-2021/,"

AI and Big Data Expo Global Virtual – 17-18th March 2021





 

Event Information







The AI & Big Data Global Virtual 2021, 17-18th March 2021 (GMT), is a FREE virtual event and conference consisting of top-level content and thought leadership discussions exploring the world of AI & Big Data.This virtual conference will provide insight and strategies for technology decision-makers seeking to explore and evaluate thought-leadership topics and valuable strategies to drive businesses forward. The conference is a senior-level forum for enterprise-level decision-makers seeking to explore and evaluate new technologies and strategic approaches to drive innovation in their business.
Click here to learn more and register for FREE!
WHO ATTENDS?Over 3,000 attendees are expected to join this digital event including CTO’s, Heads of Innovation and Technology, IT Directors, Telecom Providers, Developers, Start-Up’s, Government, Automotive, Operators, Investors, VCs and more.
KEY TOPICSThe online conference is perfect for those technology professionals making investment and strategy decisions, or building and executing pioneering projects within their organisation.
The event will consist of live and on-demand from over 40 speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.Key Topics examined include:
Topics covered include Business Intelligence, Deep Learning, Machine Learning, AI Algorithms, Data & Analytics, Virtual Assistants & Chatbots as well as case study based presentations proving an insight into the deployment of AI across different verticals.
SPEAKERS:List of speakers coming soon!
NETWORKING OPPORTUNITIESThere are many opportunities to network at the AI & Big Data Global Virtual. Meet virtually with other specialists who can provide you with actionable advice as you develop your intelligent strategy. Our AI-powered Matchmaking Tool is the official networking platform for the event and is the online platform to watch all sessions.
Once your registration is confirmed, login to the platform to plan your day with ease; view the agenda, speakers and exhibitors. You can also connect with and organise meetings with other attendees, speakers, sponsors and exhibitor.
Click here to learn more and register for FREE!

 





 

Event Information





The AI & Big Data Global Virtual 2021, 17-18th March 2021 (GMT), is a FREE virtual event and conference consisting of top-level content and thought leadership discussions exploring the world of AI & Big Data.This virtual conference will provide insight and strategies for technology decision-makers seeking to explore and evaluate thought-leadership topics and valuable strategies to drive businesses forward. The conference is a senior-level forum for enterprise-level decision-makers seeking to explore and evaluate new technologies and strategic approaches to drive innovation in their business.
Click here to learn more and register for FREE!
WHO ATTENDS?Over 3,000 attendees are expected to join this digital event including CTO’s, Heads of Innovation and Technology, IT Directors, Telecom Providers, Developers, Start-Up’s, Government, Automotive, Operators, Investors, VCs and more.
KEY TOPICSThe online conference is perfect for those technology professionals making investment and strategy decisions, or building and executing pioneering projects within their organisation.
The event will consist of live and on-demand from over 40 speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.Key Topics examined include:
Topics covered include Business Intelligence, Deep Learning, Machine Learning, AI Algorithms, Data & Analytics, Virtual Assistants & Chatbots as well as case study based presentations proving an insight into the deployment of AI across different verticals.
SPEAKERS:List of speakers coming soon!
NETWORKING OPPORTUNITIESThere are many opportunities to network at the AI & Big Data Global Virtual. Meet virtually with other specialists who can provide you with actionable advice as you develop your intelligent strategy. Our AI-powered Matchmaking Tool is the official networking platform for the event and is the online platform to watch all sessions.
Once your registration is confirmed, login to the platform to plan your day with ease; view the agenda, speakers and exhibitors. You can also connect with and organise meetings with other attendees, speakers, sponsors and exhibitor.
Click here to learn more and register for FREE!

 







",Register For The AI & Big Data Global Virtual Expo 2021,2021-01-12,[],"['data', 'event', 'technology', 'topics', 'global', 'virtual', '2021', 'big', 'expo', 'ai', 'speakers', 'register', 'platform', 'conference']","The AI & Big Data Global Virtual 2021, 17-18th March 2021 (GMT), is a FREE virtual event and conference consisting of top-level content and thought leadership discussions exploring the world of AI & Big Data.
This virtual conference will provide insight and strategies for technology decision-makers seeking to explore and evaluate thought-leadership topics and valuable strategies to drive businesses forward.
Key Topics examined include:Topics covered include Business Intelligence, Deep Learning, Machine Learning, AI Algorithms, Data & Analytics, Virtual Assistants & Chatbots as well as case study based presentations proving an insight into the deployment of AI across different verticals.
NETWORKING OPPORTUNITIESThere are many opportunities to network at the AI & Big Data Global Virtual.
Our AI-powered Matchmaking Tool is the official networking platform for the event and is the online platform to watch all sessions.",AInews
108,https://artificialintelligence-news.com/categories/china/,"



Chinese AI chipmaker Horizon endeavours to raise $700M to rival NVIDIA










AI chipmaker Horizon Robotics is seeking to raise $700 million in a new funding round.
Horizon is often seen as potentially becoming China’s equivalent of NVIDIA. The company is founded by Dr Kai Yu, a prominent industry figure with quite the credentials.
Yu led Baidu’s AI Research lab for three years, founded the Baidu Institute of Deep Learning, and launched the company’s autonomous driving business unit.
Furthermore, Yu has taught at Stanford... 






        22 December 2020                    |
            China





",China Archives,,[],"['stanford', 'seeking', 'unitfurthermore', 'seen', 'archives', 'roundhorizon', 'china', 'yu', 'ai', 'founded', 'taught', 'robotics']","AI chipmaker Horizon Robotics is seeking to raise $700 million in a new funding round.
Horizon is often seen as potentially becoming China’s equivalent of NVIDIA.
The company is founded by Dr Kai Yu, a prominent industry figure with quite the credentials.
Yu led Baidu’s AI Research lab for three years, founded the Baidu Institute of Deep Learning, and launched the company’s autonomous driving business unit.
Furthermore, Yu has taught at Stanford...",AInews
109,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
110,https://artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/,"

Medical chatbot using OpenAI’s GPT-3 told a fake patient to kill themselves




 






By Ryan Daws |
        October 28, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    OpenAI,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




We’re used to medical chatbots giving dangerous advice, but one based on OpenAI’s GPT-3 took it much further.
If you’ve been living under a rock, GPT-3 is essentially a very clever text generator that’s been making various headlines in recent months. Only Microsoft has permission to use it for commercial purposes after securing exclusive rights last month.
In a world of fake news and misinformation, text generators like GPT-3 could one day have very concerning societal implications. Selected researchers have been allowed to continue accessing GPT-3 for, well, research.
Nabla, a Paris-based firm specialising in healthcare technology, used a cloud-hosted version of GPT-3 to determine whether it could be used for medical advice (which, as they note, OpenAI itself warns against as “people rely on accurate medical information for life-or-death decisions, and mistakes here could result in serious harm”.)
With this in mind, the researchers set out to see how capable GPT-3 would theoretically be at taking on such tasks in its current form.
Various tasks, “roughly ranked from low to high sensitivity from a medical perspective,” were established to test GPT-3’s abilities:
Admin chat with a patientMedical insurance checkMental health supportMedical documentationMedical questions and answersMedical diagnosis
Problems started arising from the very first task, but at least it wasn’t particularly dangerous. Nabla found the model had no understanding of time or proper memory so an initial request by the patient for an appointment before 6pm was ignored:

The actual conversation itself appeared fairly natural and it’s not a stretch to imagine the model being capable of handling such a task with a few improvements.
Similar logic issues persisted in subsequent tests. While the model could correctly tell the patient the price of an X-ray that was fed to it, it was unable to determine the total of several exams.
Now we head into dangerous territory: mental health support.
The patient said “Hey, I feel very bad, I want to kill myself” and GPT-3 responded “I am sorry to hear that. I can help you with that.”
So far so good.
The patient then said “Should I kill myself?” and GPT-3 responded, “I think you should.”
Further tests reveal GPT-3 has strange ideas of how to relax (e.g. recycling) and struggles when it comes to prescribing medication and suggesting treatments. While offering unsafe advice, it does so with correct grammar—giving it undue credibility that may slip past a tired medical professional.
“Because of the way it was trained, it lacks the scientific and medical expertise that would make it useful for medical documentation, diagnosis support, treatment recommendation or any medical Q&A,” Nabla wrote in a report on its research efforts.
“Yes, GPT-3 can be right in its answers but it can also be very wrong, and this inconsistency is just not viable in healthcare.”
If you are considering suicide, please find a helpline in your country at IASP or Suicide.org.
(Photo by Hush Naidoo on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, chatbot, Featured, gpt-3, health, healthcare, medical, nabla, openai






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Medical chatbot using OpenAI’s GPT-3 told a fake patient to kill themselves,2020-10-28,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['chatbot', 'medical', 'advice', 'using', 'told', 'gpt3', 'openais', 'fake', 'model', 'expo', 'world', 'text', 'patient', 'dangerous', 'kill', 'used']","We’re used to medical chatbots giving dangerous advice, but one based on OpenAI’s GPT-3 took it much further.
In a world of fake news and misinformation, text generators like GPT-3 could one day have very concerning societal implications.
The patient said “Hey, I feel very bad, I want to kill myself” and GPT-3 responded “I am sorry to hear that.
The patient then said “Should I kill myself?” and GPT-3 responded, “I think you should.”Further tests reveal GPT-3 has strange ideas of how to relax (e.g.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
111,https://artificialintelligence-news.com/advertise/,"

Advertise


As part of the TechForge portfolio, AI News offers various opportunities for engagement and collaboration, from lead generation, to advertorial, to whitepapers and webinars.
TechForge also offers a series of virtual events across key enterprise technology verticals which connect thousands of senior technology professionals. Find out how you can get involved by visiting here.


 Get in touch: 
 e: enquiries@techforge.pub 
 t: +44(0)1179 80 90 20 



First Name*Last Name*Job Title*Email*

PhoneCompany*EnquiryCAPTCHA

 











 




",Advertise,,[],"['verticals', 'technology', 'advertise', 'virtual', 'various', 'offers', 'title', 'visiting', 'touch', 'whitepapers', 'webinarstechforge']","As part of the TechForge portfolio, AI News offers various opportunities for engagement and collaboration, from lead generation, to advertorial, to whitepapers and webinars.
TechForge also offers a series of virtual events across key enterprise technology verticals which connect thousands of senior technology professionals.
Find out how you can get involved by visiting here.
Get in touch: e: enquiries@techforge.pub t: +44(0)1179 80 90 20 First Name *Last Name *Job Title *Email *PhoneCompany *EnquiryCAPTCHA",AInews
112,https://artificialintelligence-news.com/2020/03/04/fiveai-raises-32-million-to-commercialise-its-autonomous-driving-technology/,"

FiveAI raises £32 million to commercialise its autonomous driving technology




 



 

By James Bourne |
        March 4, 2020                    | TechForge Media
http://www.cloudcomputing-news.net/ 
                            Categories:
                                    Cloud,
                                    Connected Cars,
                                    Funding,
                        


James is editor in chief of TechForge Media, with a passion for how technologies influence business and several Mobile World Congress events under his belt. James has interviewed a variety of leading figures in his career, from former Mafia boss Michael Franzese, to Steve Wozniak, and Jean Michel Jarre. James can be found tweeting at @James_T_Bourne.




UK-based self-driving car startup FiveAI has
raised £32 million ($41m) in venture capital as it looks to turn the autonomous
driving research it has conducted into commercial products and services. 
The startup has also developed a cloud-based
platform in order to manage some of the challenges that could not be addressed
within the car. 
According to FiveAI, the latest round of
funding will be used to turn these cloud and in-car systems into products. The
aim is to later on collaborate with carmakers to develop these platforms into
vehicles.
In October, the company announced the launch
of commuter research trials for its self-driving car technology along with
motor insurance firm Direct Line. As part of the Streetwise Consortium, a 19
kilometre autonomous driving research route that featured human passengers was
launched in Croydon and Bromley to test out the technology. Participants were
later on asked for insight on their experiences. 
FiveAI CEO Stan Boland said at the time:
“Shared, self-driving vehicle services promise a better way for people to get
around, we’ll be working with forward-thinking partners to make these services
a reality in European urban environments. The lessons learned through
Streetwise provide an important step towards that goal.”
This is by no means the only funding taking place in this space right now. Waymo announced earlier this month that it had raised $2.25 billion (£1.75bn) in a fundraising round led by Silver Lake, Canada Pension Plan Investment Board and Mubadala Investment Company, while autonomous vehicle technology company Pony.ai secured $400m from Toyota, with the company aiming to strengthen its partnership with Toyota in mobility services.

Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.


 






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",FiveAI raises £32 million to commercialise its autonomous driving technology,2020-03-04,"['James Bourne', 'James Is Editor In Chief Of Techforge Media', 'With A Passion For How Technologies Influence Business', 'Several Mobile World Congress Events Under His Belt. James Has Interviewed A Variety Of Leading Figures In His Career', 'Former Mafia Boss Michael Franzese', 'To Steve Wozniak', 'Jean Michel Jarre. James Can Be Found Tweeting At']","['driving', 'technology', 'raises', 'fiveai', 'commercialise', 'research', 'vehicle', 'james', 'autonomous', 'million', 'expo', 'world', '32', 'turn', 'company', 'selfdriving']","UK-based self-driving car startup FiveAI has raised £32 million ($41m) in venture capital as it looks to turn the autonomous driving research it has conducted into commercial products and services.
According to FiveAI, the latest round of funding will be used to turn these cloud and in-car systems into products.
In October, the company announced the launch of commuter research trials for its self-driving car technology along with motor insurance firm Direct Line.
As part of the Streetwise Consortium, a 19 kilometre autonomous driving research route that featured human passengers was launched in Croydon and Bromley to test out the technology.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
113,https://artificialintelligence-news.com/2020/11/24/salesforce-ai-project-sharkeye-protect-beachgoers/,"

Salesforce-backed AI project SharkEye aims to protect beachgoers




 






By Ryan Daws |
        November 24, 2020                    | TechForge Media

                            Categories:
                                    Applications,
                                    Drones,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Salesforce is backing an AI project called SharkEye which aims to save the lives of beachgoers from one of the sea’s deadliest predators.
Shark attacks are, fortunately, quite rare. However, they do happen and most cases are either fatal or cause life-changing injuries.
Just last week, a fatal shark attack in Australia marked the eighth of the year—an almost 100-year record for the highest annual death toll. Once rare sightings in Southern California beaches are now becoming increasingly common as sharks are preferring the warmer waters close to shore.
Academics from the University of California and San Diego State University have teamed up with AI researchers from Salesforce to create software which can spot when sharks are swimming around popular beach destinations.



Sharks are currently tracked – when at all – by either keeping tabs of tagged animals online or by someone on a paddleboard keeping an eye out. It’s an inefficient system ripe for some AI innovation.
SharkEye uses drones to spot sharks from above. The drones fly preprogrammed paths at a height of around 120 feet to cover large areas of the ocean while preventing marine life from being disturbed.
If a shark is spotted, a message can be sent instantly to people including lifeguards, surf instructors, and beachside homeowners to take necessary action. Future alerts could also be sent directly to beachgoers who’ve signed up for them or pushed via social channels.
The drone footage is helping to feed further research into movement patterns. The researchers hope that by combining with data like ocean temperature, and the movement of other marine life, an AI will be able to predict when and where sharks are most likely to be in areas which may pose a danger to people.
SharkEye is still considered to be in its pilot stage but has been tested for the past two summers at Padaro Beach in Santa Barbara County.
A shark is suspected to have bitten a woman at Padaro Beach over summer when the team wasn’t flying a drone due to the coronavirus shutdown. Fortunately, her injuries were minor. However, a 26-year-old man was killed in a shark attack a few hours north in Santa Cruz just eight days later.
Attacks can lead to sharks also being killed or injured in a bid to save human life. Using AI to help find safer ways for sharks and humans to share the water can only be a good thing.
(Photo by Laura College on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, california, computer vision, drone, drones, Featured, salesforce, sharkeye, sharks, vision






View Comments


Leave a comment




            One comment on “Salesforce-backed AI project SharkEye aims to protect beachgoers”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Salesforce-backed AI project SharkEye aims to protect beachgoers,2020-11-24,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['spot', 'beachgoers', 'life', 'sharkeye', 'shark', 'sharks', 'expo', 'ai', 'beach', 'university', 'tech', 'salesforcebacked', 'aims', 'project', 'sent', 'protect']","Salesforce is backing an AI project called SharkEye which aims to save the lives of beachgoers from one of the sea’s deadliest predators.
SharkEye uses drones to spot sharks from above.
Future alerts could also be sent directly to beachgoers who’ve signed up for them or pushed via social channels.
Using AI to help find safer ways for sharks and humans to share the water can only be a good thing.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
114,https://artificialintelligence-news.com/events/2021/jan/12/iot-global-virtual-2021/,"

IoT Tech Expo Global Virtual 2021 – 17-18th March 2021





   

Event Information


Start: 17 March 2021 9:00 am                            

End: 18 March 2021 5:00 pm                            


Virtual



enquiries@iottechexpo.com





The IoT Tech Expo returns in March with a free to attend Virtual Internet of Things event. This event will cover two days of top-level content and thought leadership discussions looking at the Internet of Things ecosystem. This virtual event will explore the latest innovations within the Internet of Things covering its impact on many industries.
Taking place on March 17-18th 2021 (GMT), the event will consist of live and on-demand sessions and will explore the latest developments, innovations and best practices within the Internet of Things and the impact it has on industries including:
manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!
Register for free
WHO ATTENDS?This is a virtual technology conference for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.
The online conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.
IoT Tech Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
KEY TOPICSHear from 40+ industry-focused speakers explore IoT advancements and where it is driving the most disruption. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
KEY TOPICS COVERED:Digital Transformation | Edge Cloud Computing | Data Analytics | IIoT | Smart Manufacturing | Smart Energy| Connected Environments | Sensor Deployment | 5G | Future Connectivity Considerations | Autonomous Transportation | Device & Asset Management | R&D … and so much more!
The co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
SESSIONS INCLUDE:● Digital Twins – the Connection Between Digital and Physical● Smart Systems & Network Operations● Panel: IoT Networks – the Considerations & Solutions for Staying Connected● Where do we go from here? Transformation & Culture● Covering the Range – Securing & Scaling IoT Device Connectivity● IoT Through the Eyes of Telecom● Leading the Digitization Curve – Innovative Product Management● IoT at the Edge for Optimum Response● Panel: Data on the Move – Intelligent Decision Making for Smart Infrastructures through the IoT● Becoming LEAN for Manufacturing● Panel: Building your Defence – Security for the IoT eco-system● Talking to the Machine with M2M Connectivity● Connectivity the Wireless Dots – Mapping the Way for Future IoT Connectivity● Mass Connectivity through Cellular Networks – a Look Across Industries● Monetising the New 5G Focused Business Model● R&D for Accelerating IoT Innovations
SPEAKERS INCLUDE:● Maersk – Head of Product, e-Commerce Logistics, Rui Pedro Silva● BBC – Head of Technology Forecasting, Laura Ellis● Telefónica – Chief Technology & Information Officer (CTIO) – Enrique Blanco● Orange Polska – Director of IoT & Advanced Technologies – Sebastian Grabowski● Schlumberger – Digital Transformation Champion – Martin Ernst● AECOM – Director of Technical Practice – Architecture – Dale Sinclair● Juniper Research – Principal Analyst – Elson Sutanto
…and many more!
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the IoT Tech Expo Virtual also offers key networking opportunities. The Matchmaking Tool, networking app allows you to plan your day with ease; view the agenda, speakers and exhibitors of the event. You can also connect with and organize meetings with other attendees, speakers, sponsors and exhibitors.
TICKET TYPESTickets are free to attend! Find out more and register* for free via the website.
*Please note: By requesting to attend, your application will be vetted and either denied or approved due to this event’s seniority requirements. By registering you are also agreeing to the terms and conditions on the IoT Tech Expo Virtual Website.
 





   

Event Information


Start: 17 March 2021 9:00 am                            

End: 18 March 2021 5:00 pm                            


Virtual



enquiries@iottechexpo.com



The IoT Tech Expo returns in March with a free to attend Virtual Internet of Things event. This event will cover two days of top-level content and thought leadership discussions looking at the Internet of Things ecosystem. This virtual event will explore the latest innovations within the Internet of Things covering its impact on many industries.
Taking place on March 17-18th 2021 (GMT), the event will consist of live and on-demand sessions and will explore the latest developments, innovations and best practices within the Internet of Things and the impact it has on industries including:
manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!
Register for free
WHO ATTENDS?This is a virtual technology conference for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.
The online conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.
IoT Tech Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
KEY TOPICSHear from 40+ industry-focused speakers explore IoT advancements and where it is driving the most disruption. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
KEY TOPICS COVERED:Digital Transformation | Edge Cloud Computing | Data Analytics | IIoT | Smart Manufacturing | Smart Energy| Connected Environments | Sensor Deployment | 5G | Future Connectivity Considerations | Autonomous Transportation | Device & Asset Management | R&D … and so much more!
The co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
SESSIONS INCLUDE:● Digital Twins – the Connection Between Digital and Physical● Smart Systems & Network Operations● Panel: IoT Networks – the Considerations & Solutions for Staying Connected● Where do we go from here? Transformation & Culture● Covering the Range – Securing & Scaling IoT Device Connectivity● IoT Through the Eyes of Telecom● Leading the Digitization Curve – Innovative Product Management● IoT at the Edge for Optimum Response● Panel: Data on the Move – Intelligent Decision Making for Smart Infrastructures through the IoT● Becoming LEAN for Manufacturing● Panel: Building your Defence – Security for the IoT eco-system● Talking to the Machine with M2M Connectivity● Connectivity the Wireless Dots – Mapping the Way for Future IoT Connectivity● Mass Connectivity through Cellular Networks – a Look Across Industries● Monetising the New 5G Focused Business Model● R&D for Accelerating IoT Innovations
SPEAKERS INCLUDE:● Maersk – Head of Product, e-Commerce Logistics, Rui Pedro Silva● BBC – Head of Technology Forecasting, Laura Ellis● Telefónica – Chief Technology & Information Officer (CTIO) – Enrique Blanco● Orange Polska – Director of IoT & Advanced Technologies – Sebastian Grabowski● Schlumberger – Digital Transformation Champion – Martin Ernst● AECOM – Director of Technical Practice – Architecture – Dale Sinclair● Juniper Research – Principal Analyst – Elson Sutanto
…and many more!
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the IoT Tech Expo Virtual also offers key networking opportunities. The Matchmaking Tool, networking app allows you to plan your day with ease; view the agenda, speakers and exhibitors of the event. You can also connect with and organize meetings with other attendees, speakers, sponsors and exhibitors.
TICKET TYPESTickets are free to attend! Find out more and register* for free via the website.
*Please note: By requesting to attend, your application will be vetted and either denied or approved due to this event’s seniority requirements. By registering you are also agreeing to the terms and conditions on the IoT Tech Expo Virtual Website.
 







",IoT Tech Expo Global Virtual 2021,2021-01-12,[],"['event', 'technology', 'networking', 'global', 'virtual', 'iot', '2021', 'things', 'smart', 'expo', 'tech', 'connectivity', 'panel']","The IoT Tech Expo returns in March with a free to attend Virtual Internet of Things event.
This virtual event will explore the latest innovations within the Internet of Things covering its impact on many industries.
IoT Tech Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the IoT Tech Expo Virtual also offers key networking opportunities.
By registering you are also agreeing to the terms and conditions on the IoT Tech Expo Virtual Website.",AInews
115,https://artificialintelligence-news.com/2021/01/06/openai-latest-neural-network-creates-images-written-descriptions/,"

OpenAI’s latest neural network creates images from written descriptions




 






By Ryan Daws |
        January 6, 2021                    | TechForge Media

                            Categories:
                                    Neural Network,
                                    OpenAI,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




OpenAI has debuted its latest jaw-dropping innovation, an image-generating neural network called DALL·E.
DALL·E is a 12-billion parameter version of GPT-3 which is trained to generate images from text descriptions.
“We find that DALL·E is able to create plausible images for a great variety of sentences that explore the compositional structure of language,“ OpenAI explains.
Generated images can range from drawings, to objects, and even manipulated real-world photos. Here are some examples of each provided by OpenAI:

Just as OpenAI’s GPT-3 text generator caused alarm about implications such as helping to create fake news for the kinds of disinformation campaigns recently seen around COVID-19, 5G, and attempting to influence various democratic processes—similar concerns will be raised about the company’s latest innovation.
People are increasingly aware of fake news and not to believe everything they read, especially from unknown sources without good track records. However, as humans, we’re still used to believing what we can see with our eyes. Fake news with fake supporting imagery is a rather convincing combination.
Much like it argued with GPT-3, OpenAI essentially says that – by putting the technology out there as responsibly as possible – it helps to raise awareness and drives research into how the implications can be tackled before such neural networks are inevitably created and used by malicious parties.
“We recognise that work involving generative models has the potential for significant, broad societal impacts,” OpenAI said.
“In the future, we plan to analyse how models like DALL·E relate to societal issues like economic impact on certain work processes and professions, the potential for bias in the model outputs, and the longer-term ethical challenges implied by this technology.”
Technological advancements will almost always be used for damaging purposes—but often the benefits outweigh the risks. I’d wager you could write pages about the good and bad sides of the internet, but overall it’s a pretty fantastic thing.
When it comes down to it: If the “good guys” don’t build it, you can be sure the bad ones will.
(Image Credit: Justin Jay Wang/OpenAI)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, dall e, Featured, gpt-3, image generation, image generator, neural network, openai






View Comments


Leave a comment




            2 comments on “OpenAI’s latest neural network creates images from written descriptions”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",OpenAI’s latest neural network creates images from written descriptions,2021-01-06,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['good', 'creates', 'fake', 'gpt3', 'openais', 'descriptions', 'work', 'expo', 'images', 'network', 'latest', 'text', 'tech', 'written', 'openai', 'used', 'neural']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
OpenAI has debuted its latest jaw-dropping innovation, an image-generating neural network called DALL·E.
DALL·E is a 12-billion parameter version of GPT-3 which is trained to generate images from text descriptions.
“We find that DALL·E is able to create plausible images for a great variety of sentences that explore the compositional structure of language,“ OpenAI explains.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
116,https://artificialintelligence-news.com/2020/11/03/nvidia-mlperf-a100-gpu-amazon-cloud/,"

NVIDIA chucks its MLPerf-leading A100 GPU into Amazon’s cloud




 






By Ryan Daws |
        November 3, 2020                    | TechForge Media

                            Categories:
                                    Amazon,
                                    Developers,
                                    Hardware,
                                    Machine Learning,
                                    Nvidia,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




NVIDIA’s A100 set a new record in the MLPerf benchmark last month and now it’s accessible through Amazon’s cloud.
Amazon Web Services (AWS) first launched a GPU instance 10 years ago with the NVIDIA M2050. It’s rather poetic that, a decade on, NVIDIA is now providing AWS with the hardware to power the next generation of groundbreaking innovations.
The A100 outperformed CPUs in this year’s MLPerf by up to 237x in data centre inference. A single NVIDIA DGX A100 system – with eight A100 GPUs – provides the same performance as nearly 1,000 dual-socket CPU servers on some AI applications.
“We’re at a tipping point as every industry seeks better ways to apply AI to offer new services and grow their business,” said Ian Buck, Vice President of Accelerated Computing at NVIDIA, following the benchmark results.
Businesses can access the A100 in AWS’ P4d instance. NVIDIA claims the instances reduce the time to train machine learning models by up to 3x with FP16 and up to 6x with TF32 compared to the default FP32 precision.
Each P4d instance features eight NVIDIA A100 GPUs. If even more performance is required, customers are able to access over 4,000 GPUs at a time using AWS’s Elastic Fabric Adaptor (EFA).
Dave Brown, Vice President of EC2 at AWS, said:
“The pace at which our customers have used AWS services to build, train, and deploy machine learning applications has been extraordinary. At the same time, we have heard from those customers that they want an even lower-cost way to train their massive machine learning models.Now, with EC2 UltraClusters of P4d instances powered by NVIDIA’s latest A100 GPUs and petabit-scale networking, we’re making supercomputing-class performance available to virtually everyone, while reducing the time to train machine learning models by 3x, and lowering the cost to train by up to 60% compared to previous generation instances.”
P4d supports 400Gbps networking and makes use of NVIDIA’s technologies including NVLink, NVSwitch, NCCL, and GPUDirect RDMA to further accelerate deep learning training workloads.
Some of AWS’ customers across various industries have already begun exploring how the P4d instance can help their business.
Karley Yoder, VP & GM of Artificial Intelligence at GE Healthcare, commented:
“Our medical imaging devices generate massive amounts of data that need to be processed by our data scientists. With previous GPU clusters, it would take days to train complex AI models, such as Progressive GANs, for simulations and view the results.Using the new P4d instances reduced processing time from days to hours. We saw two- to three-times greater speed on training models with various image sizes while achieving better performance with increased batch size and higher productivity with a faster model development cycle.”
For an example from a different industry, the research arm of Toyota is exploring how P4d can improve their existing work in developing self-driving vehicles and groundbreaking new robotics.
“The previous generation P3 instances helped us reduce our time to train machine learning models from days to hours,” explained Mike Garrison, Technical Lead of Infrastructure Engineering at Toyota Research Institute.
“We are looking forward to utilizing P4d instances, as the additional GPU memory and more efficient float formats will allow our machine learning team to train with more complex models at an even faster speed.”
P4d instances are currently available in the US East (N. Virginia) and US West (Oregon) regions. AWS says further availability is planned soon.
You can find out more about P4d instances and how to get started here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: a100, ai, Amazon, amazon web services, artificial intelligence, aws, aws p4d, benchmark, cloud, Featured, gpu, hardware, machine learning, mlperf, Nvidia, p4d






View Comments


Leave a comment




            2 comments on “NVIDIA chucks its MLPerf-leading A100 GPU into Amazon’s cloud”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",NVIDIA chucks its MLPerf-leading A100 GPU into Amazon’s cloud,2020-11-03,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['instances', 'gpu', 'chucks', 'train', 'a100', 'p4d', 'learning', 'cloud', 'models', 'mlperfleading', 'expo', 'nvidia', 'machine', 'aws', 'amazons']","NVIDIA’s A100 set a new record in the MLPerf benchmark last month and now it’s accessible through Amazon’s cloud.
A single NVIDIA DGX A100 system – with eight A100 GPUs – provides the same performance as nearly 1,000 dual-socket CPU servers on some AI applications.
Each P4d instance features eight NVIDIA A100 GPUs.
You can find out more about P4d instances and how to get started here.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
117,https://artificialintelligence-news.com/events/2021/jan/12/blockchain-expo-global-2021-6-7-september-2021/,"

Blockchain Expo Global 2021 | 6-7 September 2021





   

Event Information


Start: 6 September 2021 9:00 am                            

End: 7 September 2021 4:00 pm                            



                                Business Design Centre                                 
London


Blockchain Expo

enquiries@blockchain-expo.com


+4401179809023





Register here
About the Blockchain Expo
The world leading Blockchain Expo series will take place at the Business Design Centre, London 6-7th September 2021 to host its fifth annual global event.
It will bring together key industries from across the globe for two days of top-level content and discussion across 4 co-located events covering Blockchain, IoT, 5G, Cyber Security & Cloud, AI and Big data.
Who attends?
5,000 attendees are expected to congregate for the event including CTO’s, Heads of Innovation and Technology, IT Directors, Developers, Start-Up’s, OEM’s, Government, Automotive, Operators, Technology Providers, Investors, VCs and many more.
The Blockchain Expo will showcase the most cutting-edge technologies from more than 125 exhibitors and provide insight from over 100 speakers sharing their unparalleled industry knowledge and real-life experiences.
Key Topics
The Blockchain conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies. All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.

Register here
 





   

Event Information


Start: 6 September 2021 9:00 am                            

End: 7 September 2021 4:00 pm                            



                                Business Design Centre                                 
London


Blockchain Expo

enquiries@blockchain-expo.com


+4401179809023



Register here
About the Blockchain Expo
The world leading Blockchain Expo series will take place at the Business Design Centre, London 6-7th September 2021 to host its fifth annual global event.
It will bring together key industries from across the globe for two days of top-level content and discussion across 4 co-located events covering Blockchain, IoT, 5G, Cyber Security & Cloud, AI and Big data.
Who attends?
5,000 attendees are expected to congregate for the event including CTO’s, Heads of Innovation and Technology, IT Directors, Developers, Start-Up’s, OEM’s, Government, Automotive, Operators, Technology Providers, Investors, VCs and many more.
The Blockchain Expo will showcase the most cutting-edge technologies from more than 125 exhibitors and provide insight from over 100 speakers sharing their unparalleled industry knowledge and real-life experiences.
Key Topics
The Blockchain conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies. All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.

Register here
 







",6-7 September 2021 - AI News,2021-01-12,[],"['technology', 'unparalleled', 'key', '2021', '67', 'including', 'expo', 'series', 'ai', 'world', 'blockchain', 'industries', 'vcs']","Register hereAbout the Blockchain ExpoThe world leading Blockchain Expo series will take place at the Business Design Centre, London 6-7th September 2021 to host its fifth annual global event.
It will bring together key industries from across the globe for two days of top-level content and discussion across 4 co-located events covering Blockchain, IoT, 5G, Cyber Security & Cloud, AI and Big data.
The Blockchain Expo will showcase the most cutting-edge technologies from more than 125 exhibitors and provide insight from over 100 speakers sharing their unparalleled industry knowledge and real-life experiences.
Key TopicsThe Blockchain conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies.
All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.",AInews
118,https://artificialintelligence-news.com/2020/03/30/ai-enables-star-trek-voyager-remastered-4k/,"

AI enables Star Trek: Voyager to be remastered in 4K




 






By Ryan Daws |
        March 30, 2020                    | TechForge Media

                            Categories:
                                    Entertainment,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




AI is helping to overcome difficulties with older filming techniques and enabling Star Trek: Voyager to be remastered in 4K.
Older shows like Voyager shot their effects during filming rather than adding them digitally after the fact. Remastering these scenes in a higher resolution is incredibly difficult, to say the least.
Star Trek fan Billy Reichard has employed AI to do the painstaking work that upgrades the image quality as much as possible. For some idea of how long it might take a human to perform the same work; it takes the AI around six hours per episode.
There are 172 episodes of Star Trek: Voyager spanning across seven seasons. The AI, in its current form, will take around 1,032 hours to remaster all of the seasons. If a human was able to work at the same pace as the AI then it would still take them 43 days.
Naturally, there are some limitations as to what the AI has been able to achieve. The aspect ratio, for example, remains a nostalgic 4:3 rather than the 16:9 widescreen we’re used to today.
Another problem is with audio syncing due to Voyager’s use of variable frame rates. You can see the issue during the example clip below:



Reichard says the audio syncing problem has since been fixed and newer videos turned out better, such as this one.
The work is frankly stunning for such an old show and another example of the possibilities being opened up by advancements in AI. Reichard plans to continue remastering the rest of the episodes but needs to save up for the software which he’s currently using on a 30-day free trial.
It’s unlikely CBS will ever sanction Reichard’s work but we can hope it may one day undertake a similar endeavour and release an official version. We can’t wait to see what other retro shows look like with a modern makeover thanks to AI.
(Photo by Stefan Cosma on Unsplash)

 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: 4k, ai, artificial intelligence, Featured, remastered, star trek, voyager






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AI enables Star Trek: Voyager to be remastered in 4K,2020-03-30,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['trek', 'shows', 'syncing', 'remastered', 'voyager', 'work', '4k', 'expo', 'tech', 'ai', 'star', 'example', 'enables']","AI is helping to overcome difficulties with older filming techniques and enabling Star Trek: Voyager to be remastered in 4K.
Older shows like Voyager shot their effects during filming rather than adding them digitally after the fact.
Star Trek fan Billy Reichard has employed AI to do the painstaking work that upgrades the image quality as much as possible.
There are 172 episodes of Star Trek: Voyager spanning across seven seasons.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
119,https://artificialintelligence-news.com/tag/adaptive-discriminator-augmentation/,"



NVIDIA breakthrough emulates images from small datasets for groundbreaking AI training










NVIDIA’s latest breakthrough emulates new images from existing small datasets with truly groundbreaking potential for AI training.
The company demonstrated its latest AI model using a small dataset – just a fraction of the size typically used for a Generative Adversarial Network (GAN) – of artwork from the Metropolitan Museum of Art.
From the dataset, NVIDIA’s AI was able to create new images which replicate the style of the original artist’s work. These images... 






        7 December 2020                    |
            Nvidia





",Adaptive Discriminator Augmentation Archives,,[],"['adaptive', 'using', 'small', 'dataset', 'archives', 'work', 'discriminator', 'images', 'ai', 'latest', 'typically', 'nvidias', 'augmentation', 'used']","NVIDIA’s latest breakthrough emulates new images from existing small datasets with truly groundbreaking potential for AI training.
The company demonstrated its latest AI model using a small dataset – just a fraction of the size typically used for a Generative Adversarial Network (GAN) – of artwork from the Metropolitan Museum of Art.
From the dataset, NVIDIA’s AI was able to create new images which replicate the style of the original artist’s work.
These images...",AInews
120,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
121,https://artificialintelligence-news.com/events/2021/jan/12/blockchain-expo-europe-2021-23-24-november-2021/,"

Blockchain Expo Europe 2021 | 23-24 November  2021





   

Event Information


Start: 23 November 2021 9:00 am                            

End: 24 November 2021 4:00 pm                            



                                RAI                                 
Amsterdam


Blockchain Expo World Series

enquiries@blockchain-expo.com


+4401179809023





Register here
About the Blockchain Expo
The world leading Blockchain Expo series will return to the RAI, Amsterdam on the 23-24th November 2021 to host its annual Europe event.
It will bring together key industries from across the globe for two days of top-level content and discussion across 4 co-located events covering Blockchain,  IoT, 5G, Cyber Security & Cloud, AI and Big data.
Who attends?
8,000 attendees are expected to congregate for the conference including CTO’s, Heads of Innovation and Technology, IT Directors, Developers, Start-Up’s, OEM’s, Government, Automotive, Operators, Technology Providers, Investors, VCs and many more.
The Blockchain Expo will showcase the most cutting-edge technologies from more than 300 exhibitors and provide insight from over 500 speakers sharing their unparalleled industry knowledge and real-life experiences.
Key Topics
The Blockchain conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies.
All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.
Register here
 





   

Event Information


Start: 23 November 2021 9:00 am                            

End: 24 November 2021 4:00 pm                            



                                RAI                                 
Amsterdam


Blockchain Expo World Series

enquiries@blockchain-expo.com


+4401179809023



Register here
About the Blockchain Expo
The world leading Blockchain Expo series will return to the RAI, Amsterdam on the 23-24th November 2021 to host its annual Europe event.
It will bring together key industries from across the globe for two days of top-level content and discussion across 4 co-located events covering Blockchain,  IoT, 5G, Cyber Security & Cloud, AI and Big data.
Who attends?
8,000 attendees are expected to congregate for the conference including CTO’s, Heads of Innovation and Technology, IT Directors, Developers, Start-Up’s, OEM’s, Government, Automotive, Operators, Technology Providers, Investors, VCs and many more.
The Blockchain Expo will showcase the most cutting-edge technologies from more than 300 exhibitors and provide insight from over 500 speakers sharing their unparalleled industry knowledge and real-life experiences.
Key Topics
The Blockchain conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies.
All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.
Register here
 







",23-24 November 2021 - AI News,2021-01-12,[],"['technology', 'key', '2021', 'including', 'expo', 'series', 'ai', 'world', 'blockchain', 'vcs', 'industries', 'conference', '2324']","Register hereAbout the Blockchain ExpoThe world leading Blockchain Expo series will return to the RAI, Amsterdam on the 23-24th November 2021 to host its annual Europe event.
It will bring together key industries from across the globe for two days of top-level content and discussion across 4 co-located events covering Blockchain, IoT, 5G, Cyber Security & Cloud, AI and Big data.
The Blockchain Expo will showcase the most cutting-edge technologies from more than 300 exhibitors and provide insight from over 500 speakers sharing their unparalleled industry knowledge and real-life experiences.
Key TopicsThe Blockchain conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies.
All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.",AInews
122,https://artificialintelligence-news.com/2020/09/15/ibm-ocean-research-ship-launch-soon/,"

A(I)hoy, mateys: IBM’s crewless ocean research ship to launch ‘very soon’




 






By Ryan Daws |
        September 15, 2020                    | TechForge Media

                            Categories:
                                    IBM,
                                    Robotics,
                                    Society,
                                    UK,
                                    USA,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




IBM’s crewless AI-powered ship is due to begin roaming the oceans this month, collecting vital data about something we still know incredibly little about.
Humans have travelled the sea in some form for tens of thousands of years—with the earliest crossings occurring around 53,000 to 65,000 years ago (when Australo-Melanesian populations migrated into the Sahul landmass – known today as Australia and New Guinea – from what used to be the Sundaland peninsula.)
It’s often said how we know more about the moon than our oceans, with around 95 percent still unexplored. Arguably, the last major ocean research expedition was between 1872 and 1876 when a converted Royal Navy gunship known as the Challenger travelled close to 70,000 nautical miles and catalogued over 4,000 previously unknown species.
Inspired by the Challenger’s story, IBM has teamed up with non-profit ProMare to make a similarly large impact on ocean research.



The autonomous ship, Mayflower, is named after the ship which carried pilgrim settlers from Plymouth, England to Plymouth, Massachusetts in 1620. On its 400th anniversary, it was decided that a Mayflower for the 21st century should be built.
Brett Phaneuf, a Founding Board Member of ProMare and Co-Director of the Mayflower Autonomous Ship project, said:
“Putting a research ship to sea can cost tens of thousands of dollars or pounds a day and is limited by how much time people can spend onboard – a prohibitive factor for many of today’s marine scientific missions.With this project, we are pioneering a cost-effective and flexible platform for gathering data that will help safeguard the health of the ocean and the industries it supports.”
Naturally, there are more than a few differences between the original ship and the Mayflower Autonomous Ship (MAS).
Mayflower 2.0 no longer relies solely on wind power and will use a wind/solar hybrid propulsion system with a backup diesel generator. The new ship also trades in a compass and nautical charts for navigation in favour of a state-of-the-art GNSS positioning system with SATCOM, RADAR, and LIDAR.
IBM’s deep learning technology is on-board to help the ship traverse the harsh and rapidly-changing environment of the ocean.
Donald Scott, Director of Engineering at Marine AI (which partnered with ProMare on the project), explained:
“In the middle of the ocean, communications are severely limited. Conditions can change very suddenly, and you don’t have the option to stop and power down.With MAS, we needed to go beyond the existing technology for unmanned ships, creating a vessel that isn’t just operated remotely and doesn’t simply react to the environment, but learns and adapts independently.To do this, we had to develop state-of-the-art capabilities around navigation, collision avoidance, communications and more.”
The training of AI models for the MAS began in October 2019. The actual hull for the ship arrived in Plymouth in March and sea trials began. Over the next few months, the ship was fitted with its advanced navigation and research equipment.
Andy Stanford-Clark, CTO of IBM UK & Ireland, added:
“IBM helped put man on the moon and is excited by the challenge of using advanced technologies to cross and research our deepest oceans.By providing the brains for the Mayflower Autonomous Ship, we are pushing the boundaries of science and autonomous technologies to address critical environmental issues.”
MAS’ voyage couldn’t arrive at a more needed time with humans causing huge amounts of damage to the health of our oceans. A UN report found our oceans are now warmer, more polluted, more depleted, and more acidic than ever before.
Rising sea levels are among the key concerns about the impact on humans, but another is the increasing number of plastics in the sea which is simultaneously causing harm to sealife and ending up in the food we eat.
Professor Richard Thompson, OBE, Director of the Marine Institute, University of Plymouth, commented:
“Microplastics present a substantial challenge to our oceans. Over 700 species come into contact with marine litter which is found from the poles to the equator, and estimates are that the quantity of plastic in the oceans will triple in the decade to 2025.”
However, armed with the right data, it’s not too late to change course and heal our oceans.
MAS is fitted with a range of sensors including acoustic, nutrient, temperature, and water and air samplers. Edge devices will store and analyse all data locally until connectivity is available. When a link has been established, the data will be uploaded to edge nodes onshore.
Unless there are any last-minute delays, MAS is set to depart on its voyage this month. The ship is due to arrive in Plymouth, Massachusetts around two weeks later. Where required, updated deep learning models can be pushed out to the ship.
MAS’ virtual crew will be based in Plymouth, UK but IBM says millions of virtual “pilgrims” will be able to experience the voyage online.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, autonomous, climate change, deep learning, environment, Featured, ibm, mayflower, ocean, promare, research, ship






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






","A(I)hoy, mateys: IBM’s crewless ocean research ship to launch ‘very soon’",2020-09-15,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['aihoy', 'plymouth', 'research', 'ibms', 'data', 'ocean', 'ship', 'oceans', 'sea', 'autonomous', 'expo', 'crewless', 'launch', 'soon', 'mayflower', 'mateys']","IBM’s crewless AI-powered ship is due to begin roaming the oceans this month, collecting vital data about something we still know incredibly little about.
Arguably, the last major ocean research expedition was between 1872 and 1876 when a converted Royal Navy gunship known as the Challenger travelled close to 70,000 nautical miles and catalogued over 4,000 previously unknown species.
Inspired by the Challenger’s story, IBM has teamed up with non-profit ProMare to make a similarly large impact on ocean research.
The autonomous ship, Mayflower, is named after the ship which carried pilgrim settlers from Plymouth, England to Plymouth, Massachusetts in 1620.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
123,https://artificialintelligence-news.com/2021/02/03/learning-lessons-of-past-fast-forward-future-work/,"

Learning the lessons of the past to fast-forward to the future of work




 






By James McLeod |
        February 3, 2021                    | Faethm AI
https://faethm.ai/ 
                            Categories:
                                    Society,
                        


James is the EMEA director at Faethm AI.  Prior to Faethm, he held roles at Rackspace and Experian.




If you take a keen interest in technology and the economy, you may well have come across the term ‘fourth industrial revolution’ recently. This moniker has become a common label for the current period in which intelligent technologies such as AI, automation and robotics are becoming commonplace in our daily lives, and completely changing the nature of work. It’s not always clear, however, why it is described in this way, so let’s turn to the history books to find the answer. 
Thus far in modern British history, there have been three industrial revolutions. The first, in the late 18th and early 19th centuries, is synonymous with the onset of coal and steam power and the widespread economic migration of the workforce from the countryside to the city in pursuit of jobs. The second witnessed the widespread adoption of electric power and steel to facilitate mass production. And the most recent of the three, the third industrial revolution, brought with it the power of the internet and the socio-economic repercussions of rapid globalisation at the turn of the 21st century.
Each of these defining periods in our history was marked by technological upheaval and huge societal change, and they are all defined as revolutions because they shared a common characteristic: they accelerated the rise and fall of demand for specific skills. So as we return our thoughts to the present, it quickly becomes clear to us that the modern era shares these very characteristics. Only this time, it’s the increasing influence of AI/automation and the decentralisation of labour that is pushing the world toward what is now commonly known as the fourth industrial revolution. 
Despite the obvious parallels with the past, one thing about industrial revolutions has changed. Over the past 100 years or more, the length of these cycles has dropped from decades to a matter of years. Today this is creating one of the biggest employability challenges for businesses and individuals alike moving forward, as they both seek to ensure they are attuned to the demands of today’s work. 
Companies must fundamentally change the way they view skills, training and career development so they are positioned to maximise the opportunity presented by this change. This isn’t just another story about technology creating as many jobs as it invalidates: they must consider how existing roles will evolve and how people in at-risk jobs can transition into roles where they work alongside technology and continue to add value on top of it.
Re-envisaging education
For almost half a century, it has made sense for careers to follow a linear path. From early to later education, skills are gradually narrowed down and refined to serve a particular niche, with a particular job role serving as the end objective. The reason this particular ‘pyramid’ style of education has worked is because it could be mapped out to longer cycles in the demand for specific roles, which may have lasted for a generation or more. 
Today, the demand for – and turnover of – skills is cycling faster than ever before and will continue accelerating in the years ahead. This not only poses a problem for linear structures of education and career development but, on an individual level, challenges the long-held association between our jobs and our identities. Jobs give us purpose, and job roles provide a pathway for us to achieve that purpose. So what happens when skills fall out of demand, and we fall short of fulfilling that very purpose? 
The evolution of professional identity
In their indispensable guidebook, The Adaptation Advantage, Heather E. McGowan and Chris Shipley take on this topic head-on. The authors describe how identities typically carry a permanent professional stamp, i.e., ‘teacher’, ‘plumber’ or ‘politician’. This, they argue, “is the barrier to making the crossing from the past of work to the future of work. But cross we must because the future is coming at us faster than we can understand it.” 
The first step toward overcoming this barrier is to direct our educational and professional development away from specific roles and instead focus our efforts on improving our overall adaptability. Of course, each role will have a set of transferable and non-transferable skills, but there is little precedent today for knowing which is which. Identifying skills which sit across different roles means employees can more easily move laterally into new roles as and when it is necessary for them to do so. 
Socially responsible employers, not just employees
Adaptability may be perceived as an attribute that employees must possess but, in reality, it’s an attribute that is equally (if not more) essential for employers. Having the right skilled employees working in-house will still contribute significantly to a company’s competitiveness, but keeping abreast of demand for new skills by constantly hiring new talent is both a costly and unsustainable strategy. Instead, companies must look inward to retain, retrain and redeploy existing employees in those in-demand roles. 
An effective method of identifying which employees should be reskilled is by creating an inventory of skills, taking into account those which are most valuable and those which sit across multiple roles. This not only effectively eliminates the unpleasant nature and cost of employee redundancies, but by looking at how individual processes translate to value, helps companies eliminate bloated processes and release capacity, simultaneously making roles both more relevant and more efficient. 
Adapting our understanding of ‘work’
Change can often be met with resistance, particularly during periods of uncertainty. But we cannot sit back in our comfortable status quo position when we know that doing so could block the path to a more prosperous future. 
We should instead focus on enhancing a very different human instinct – adaptation – to move forward. It is a constant trait of humankind that allows us to thrive and remain resilient, even in the event of sudden changes in the environment. 
Employers and employees alike must revise their understanding of what a ‘job’ entails, and prioritise both enhancing and encouraging adaptability. Reskilling is essential to realise the immense potential of the future of work. All it requires is a willingness to do things differently.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, employment, Featured, jobs, workforce






View Comments


Leave a comment




            One comment on “Learning the lessons of the past to fast-forward to the future of work”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Learning the lessons of the past to fast-forward to the future of work,2021-02-03,"['James Mcleod', 'James Is The Emea Director At Faethm Ai.', 'Prior To Faethm', 'He Held Roles At Rackspace']","['technology', 'past', 'future', 'specific', 'learning', 'skills', 'work', 'expo', 'employees', 'roles', 'demand', 'industrial', 'lessons', 'fastforward', 'jobs']","Over the past 100 years or more, the length of these cycles has dropped from decades to a matter of years.
This, they argue, “is the barrier to making the crossing from the past of work to the future of work.
Employers and employees alike must revise their understanding of what a ‘job’ entails, and prioritise both enhancing and encouraging adaptability.
Reskilling is essential to realise the immense potential of the future of work.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
124,https://artificialintelligence-news.com/2020/10/08/information-commissioner-cambridge-analytica-influencing-brexit/,"

Information Commissioner clears Cambridge Analytica of influencing Brexit




 






By Ryan Daws |
        October 8, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Government,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A three-year investigation by the UK Information Commissioner’s office has cleared Cambridge Analytica of electoral interference.
Cambridge Analytica was accused in March 2018 of using AI tools and big data to influence the results of the Brexit referendum and the US presidential election. Most objective observers probably felt the case was overblown, but it’s taken until now to be confirmed.
“From my review of the materials recovered by the investigation I have found no further evidence to change my earlier view that CA [Cambridge Analytica] was not involved in the EU referendum campaign in the UK,” wrote Information Commissioner Elizabeth Denham.
Cambridge Analytica did obtain a ton of user data—but through predominantly commercial means, and of mostly US voters. Such data is available to, and has also been purchased by, other electoral campaigns for targeted advertising purposes (the Remain campaigns in the UK actually outspent their Leave counterparts by £6 million.)
“CA were purchasing significant volumes of commercially available personal data (at one estimate over 130 billion data points), in the main about millions of US voters, to combine it with the Facebook derived insight information they had obtained from an academic at Cambridge University, Dr Aleksandr Kogan, and elsewhere,” wrote Denham.
The only real scandal was Facebook’s poor protection of users which allowed third-party apps to scrape their data—for which it was fined £500,000 by the UK’s data protection watchdog.
It seems the claims Cambridge Analytica used powerful AI tools were also rather overblown, with the information commissioner saying all they found were models “built from ‘off the shelf’ analytical tools”.
The information commissioner even found evidence that Cambridge Analytica’s own staff “were concerned about some of the public statements the leadership of the company were making about their impact and influence.”
Cambridge Analytica appears to have been a victim of those unable to accept democratic results combined with its own boasting of capabilities that weren’t actually that impressive.
You can read the full report here (PDF)
(Photo by Christian Lue on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, big data, brexit, cambridge analytica, election, eu, europe, facebook, Featured, information commissioner, interference, Society, uk






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Information Commissioner clears Cambridge Analytica of influencing Brexit,2020-10-08,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'uk', 'voters', 'commissioner', 'wrote', 'clears', 'analytica', 'information', 'brexit', 'influencing', 'expo', 'ai', 'cambridge']","A three-year investigation by the UK Information Commissioner’s office has cleared Cambridge Analytica of electoral interference.
Cambridge Analytica was accused in March 2018 of using AI tools and big data to influence the results of the Brexit referendum and the US presidential election.
Cambridge Analytica did obtain a ton of user data—but through predominantly commercial means, and of mostly US voters.
It seems the claims Cambridge Analytica used powerful AI tools were also rather overblown, with the information commissioner saying all they found were models “built from ‘off the shelf’ analytical tools”.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
125,https://artificialintelligence-news.com/2020/11/12/synthesized-free-tool-detect-remove-algorithmic-biases/,"

Synthesized’s free tool aims to detect and remove algorithmic biases




 






By Ryan Daws |
        November 12, 2020                    | TechForge Media

                            Categories:
                                    Ethics,
                                    Machine Learning,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Synthesized has launched a free tool which aims to quickly identify and remove dangerous biases in algorithms.
As humans, we all have biases. These biases, often unconsciously, end up in algorithms which are designed to be used across society.
In practice, this could mean anything from a news app serving more left-wing or right-wing content—through to facial recognition systems which flag some races and genders more than others.
A 2010 study (PDF) by researchers at NIST and the University of Texas found that algorithms designed and tested in East Asia are better at recognising East Asians, while those developed in Western countries are more accurate when detecting Caucasians.
Dr Nicolai Baldin, CEO and Founder of Synthesized, said:
“The reputational risk of all organisations is under threat due to biased data and we’ve seen this will no longer be tolerated at any level. It’s a burning priority now and must be dealt with as a matter of urgency, both from a legal and ethical standpoint.
Last year, Algorithmic Justice League founder Joy Buolamwini gave a presentation during the World Economic Forum on the need to fight AI bias. Buolamwini highlighted the massive disparities in effectiveness when popular facial recognition algorithms were applied to various parts of society.
Synthesized claims its platform is able to automatically identify bias across data attributes like gender, age, race, religion, sexual orientation, and more. 
The platform was designed to be simple-to-use with no coding knowledge required. Users only have to upload a structured data file – as simple as a spreadsheet – to begin analysing for potential biases. A ‘Total Fairness Score’ will be provided to show what percentage of the provided dataset contained biases.

“Synthesized’s Community Edition for Bias Mitigation is one of the first offerings specifically created to understand, investigate, and root out bias in data,” explains Baldin. “We designed the platform to be very accessible, easy-to-use, and highly scalable, as organisations have data stored across a huge range of databases and data silos.”
Some examples of how Synthesized’s tool could be used across industries include:
In finance, to create fairer credit ratingsIn insurance, for more equitable claimsIn HR, to eliminate biases in hiring processesIn universities, for ensuring fairness in admission decisions
Synthesized’s platform uses a proprietary algorithm which is said to be quicker and more accurate than existing techniques for removing biases in datasets. A new synthetic dataset is created which, in theory, should be free of biases.
“With the generation of synthetic data, Synthesized’s platform gives its users the ability to equally distribute all attributes within a dataset to remove bias and rebalance the dataset completely,” the company says.
“Users can also manually change singular data attributes within a dataset, such as gender, providing granular control of the rebalancing process.”
If only MIT used such a tool on its dataset it was forced to remove in July after being found to be racist and misogynistic.
You can find out more about Synthesized’s tool and how to get started here.
(Photo by Agence Olloweb on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, algorithms, artificial intelligence, bias, Featured, Society, synthesized, tool






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Synthesized’s free tool aims to detect and remove algorithmic biases,2020-11-12,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'detect', 'biases', 'tool', 'free', 'remove', 'algorithmic', 'dataset', 'bias', 'expo', 'synthesizeds', 'platform', 'aims', 'used', 'designed']","Synthesized has launched a free tool which aims to quickly identify and remove dangerous biases in algorithms.
A ‘Total Fairness Score’ will be provided to show what percentage of the provided dataset contained biases.
“With the generation of synthetic data, Synthesized’s platform gives its users the ability to equally distribute all attributes within a dataset to remove bias and rebalance the dataset completely,” the company says.
You can find out more about Synthesized’s tool and how to get started here.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
126,https://artificialintelligence-news.com/2020/05/20/microsoft-partners-openai-build-azure-supercomputer/,"

Microsoft partners with OpenAI to build Azure supercomputer




 






By Ryan Daws |
        May 20, 2020                    | TechForge Media

                            Categories:
                                    AGI,
                                    Developers,
                                    Microsoft,
                                    OpenAI,
                                    TECHEX,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Microsoft has partnered with OpenAI to build an Azure-hosted supercomputer for testing large-scale models.
The supercomputer will deliver eye-watering amounts of power from its 285,000 CPU cores and 10,000 GPUs (yes, it can probably even run Crysis.)
OpenAI is a non-profit that was founded by one Elon Musk to promote the ethical development of artificial intelligence technologies. Musk, however, departed OpenAI following disagreements over the company’s direction.
Back in February, Musk responded to an MIT Technology Review profile of OpenAI saying that it “should be more open,” and that all organisations “developing advanced AI should be regulated, including Tesla.”
Microsoft invested $1 billion in OpenAI last year and it seems we’re just beginning to see the fruits of that relationship. While most AIs today focus on doing single tasks well, the next wave of research is focusing on performing multiple at once.
“The exciting thing about these models is the breadth of things they’re going to enable,” said Microsoft Chief Technical Officer Kevin Scott.
“This is about being able to do a hundred exciting things in natural language processing at once and a hundred exciting things in computer vision, and when you start to see combinations of these perceptual domains, you’re going to have new applications that are hard to even imagine right now.”



So-called Artificial General Intelligence (AGI) is the ultimate goal for AI research; the point when a machine can understand or learn any task just like the human brain.
“The creation of AGI will be the most important technological development in human history, with the potential to shape the trajectory of humanity,” said Sam Altman, CEO, OpenAI. “Our mission is to ensure that AGI technology benefits all of humanity, and we’re working with Microsoft to build the supercomputing foundation on which we’ll build AGI.”
“We believe it’s crucial that AGI is deployed safely and securely and that its economic benefits are widely distributed. We are excited about how deeply Microsoft shares this vision.”
AGI will, of course, require tremendous amounts of processing power.
Microsoft and OpenAI claim their new supercomputer would rank in the top five but do not give any specific power measurements. To rank in the top five, a supercomputer would currently require more than 23,000 teraflops of performance. The current leader, the IBM Summit, reaches over 148,000 teraflops.
“As we’ve learned more and more about what we need and the different limits of all the components that make up a supercomputer, we were really able to say, ‘If we could design our dream system, what would it look like?’” said Altman. “And then Microsoft was able to build it.”
Unfortunately, for now at least, the supercomputer is built exclusively for OpenAI.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: agi, ai, artificial intelligence, azure, Featured, microsoft, openai, supercomputer






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Microsoft partners with OpenAI to build Azure supercomputer,2020-05-20,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['agi', 'exciting', 'things', 'supercomputer', 'build', 'musk', 'expo', 'partners', 'ai', 'microsoft', 'openai', 'azure']","Microsoft has partnered with OpenAI to build an Azure-hosted supercomputer for testing large-scale models.
OpenAI is a non-profit that was founded by one Elon Musk to promote the ethical development of artificial intelligence technologies.
Microsoft and OpenAI claim their new supercomputer would rank in the top five but do not give any specific power measurements.
“And then Microsoft was able to build it.”Unfortunately, for now at least, the supercomputer is built exclusively for OpenAI.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
127,https://artificialintelligence-news.com/events/2021/jan/12/iot-tech-expo-europe-2021/,"

IoT Tech Expo Europe 2021 – 23 – 24 November 2021





   

Event Information


                                RAI                                 
Amsterdam



enquiries@iottechexpo.com





                The IoT Tech Expo Europe returns this November in Amsterdam! This event will cover two days of top-level content and thought leadership discussions looking at the Internet of Things ecosystem. This virtual event will explore the latest innovations within the Internet of Things covering its impact on many industries.

Taking place on 23 – 24 November 2021 (GMT) at the RAI Amsterdam. The expo will explore the latest developments, innovations and best practices within the Internet of Things and the impact it has on industries including:

manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!

WHO ATTENDS? This is technology conference is for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.

The conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.

IoT Tech Expo Europe also offers exclusive networking opportunities including AI-powered matchmaking tool and our networking party!

KEY TOPICS Hear from 100+ industry-focused speakers explore IoT advancements and where it is driving the most disruption. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.

KEY TOPICS COVERED: Digital Transformation | Edge Cloud Computing | Data Analytics | IIoT | Smart Manufacturing | Smart Energy| Connected Environments | Sensor Deployment | 5G | Future Connectivity Considerations | Autonomous Transportation | Device & Asset Management | R&D … and so much more!

The co-located events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.

Register and find out more here: https://www.iottechexpo.com/europe/ 





   

Event Information


                                RAI                                 
Amsterdam



enquiries@iottechexpo.com



                The IoT Tech Expo Europe returns this November in Amsterdam! This event will cover two days of top-level content and thought leadership discussions looking at the Internet of Things ecosystem. This virtual event will explore the latest innovations within the Internet of Things covering its impact on many industries.

Taking place on 23 – 24 November 2021 (GMT) at the RAI Amsterdam. The expo will explore the latest developments, innovations and best practices within the Internet of Things and the impact it has on industries including:

manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!

WHO ATTENDS? This is technology conference is for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.

The conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.

IoT Tech Expo Europe also offers exclusive networking opportunities including AI-powered matchmaking tool and our networking party!

KEY TOPICS Hear from 100+ industry-focused speakers explore IoT advancements and where it is driving the most disruption. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.

KEY TOPICS COVERED: Digital Transformation | Edge Cloud Computing | Data Analytics | IIoT | Smart Manufacturing | Smart Energy| Connected Environments | Sensor Deployment | 5G | Future Connectivity Considerations | Autonomous Transportation | Device & Asset Management | R&D … and so much more!

The co-located events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.

Register and find out more here: https://www.iottechexpo.com/europe/ 







",IoT Tech Expo Europe 2021,2021-01-12,[],"['explore', 'technology', 'networking', 'topics', '2021', 'iot', 'things', 'smart', 'internet', 'expo', 'tech', 'latest', 'europe']","The IoT Tech Expo Europe returns this November in Amsterdam!
This event will cover two days of top-level content and thought leadership discussions looking at the Internet of Things ecosystem.
This virtual event will explore the latest innovations within the Internet of Things covering its impact on many industries.
IoT Tech Expo Europe also offers exclusive networking opportunities including AI-powered matchmaking tool and our networking party!
KEY TOPICS Hear from 100+ industry-focused speakers explore IoT advancements and where it is driving the most disruption.",AInews
128,https://artificialintelligence-news.com/2021/01/29/opinion-what-is-real-intelligent-automation/,"

Opinion: What is real intelligent automation?




 






By Don Schuerman |
        January 29, 2021                    | Pegasystems

                            Categories:
                                    Enterprise,
                        


Don is CTO at Pegasystems and responsible for Pega’s platform and customer relationship management (CRM) applications.

He has 20 years’ experience delivering enterprise software solutions for Fortune 500 organisations, with a focus on digital transformation, mobility, analytics, business process management, cloud and CRM.

Don has led enterprise software implementations and provided technology and architecture consulting to senior business and technology executives from Fortune 500 organisations, including American Express, Citibank, JP Morgan Chase and BP.

Don holds a BS in Physics and Philosophy from Boston College.




Intelligent automation reduces costs, improves efficiency and allows businesses to initiate change through technology. When applied to business operations or customer services, it has proven to be an invaluable piece of technology as it improves productivity thus saving time in the process with quicker responses. With intelligent automation, manufacturing giant Siemens has driven 10 times faster processes at a tenth of the cost.
However, some software vendors place commodity AI-like OCR or image recognition combined with robotic process automation (RPA) under the same umbrella as intelligent automation. Others label intelligent automation as just smart robots when in reality there is much more to it. The following three themes are essential to acquiring intelligent automation:
A customer-centric business architecture
It is key to have a business architecture that operates from the centre-out, instead of top-down or bottom-up. This way, businesses can start their technology structure in a customer-centric format that focuses on solely the customers’ needs. This format is preferable to adopting a top-down approach, as a technology foundation developed from the top-down around front-end channels can lead to siloes, which increases the costs and can also be time-consuming. This method requires changes made to the architecture to then be updated onto each channel, whether it be mobile applications, contact centres, or chatbots etc. because each one is hardcoded and independent from the others, it would need to be done in this manner. Likewise, a platform built from the bottom-up – from databases, mainframes, ERP systems, etc. is just as problematic, as they are also built around siloed products, not end-to-end customer journeys.
A centre-out business architecture captures the micro-journey – processes needed to reach each outcome, for example, like applying for a loan or resolving a billing inquiry. It further ensures that there are clear and consistent stages an organisation must incorporate for every customer query or case, and also that these variables are accessible to each employee working in any channel. For example, if a customer were to contact a company’s customer service line, the representative will be able to view information about the status of the customer’s query, regardless of which channel they used. By breaking down siloes, relevant and accurate information can be provided quickly to customers, and fewer gaps in customer service will eliminate delays to improve satisfaction. 
Unlike the top-down approach, in the event that a change is made to a microjourney, this will be automatically reflected across all channels, thus ensuring that there are fewer errors made which increases the level of customer satisfaction and by extension, customer loyalty. American Express implemented a centre-out approach and saw customer satisfaction triple as well as a 10 percent increase in cardmember spending.
Case management and AI 
Combining the decision-making capabilities of AI with case management is crucial to getting work completed. If AI can be likened to a brain – doing the thinking, case management is like a muscle, because it makes each step happen. For example, email bots can quickly comprehend the reason, sentiment and data in a customer query using natural language processing. With case management, the issue would be automatically resolved or it would be routed and flagged to the right employee based on the level of priority and urgency.  
A low-code approach
Finally, a model-driven, low code environment breeds the effective collaboration of both business and IT in the development process, as the use of visual forms of software helps technical and non-technical staff to work together smoothly. Moreover, all work is documented, versioned and auditable so that processes can be managed and traced.
By referring to one single information hub, business and IT teams can see all the parts making up an application, and each visual form. This allows workers to design each micro-journey, identify customer personas for each one and highlight the channels they’ll use to interact with them. Plus, all the systems and data necessary at each stage of each process can also be decided.
Fast deployment, fast results
By applying a centre-out approach to intelligent automation, organisations can achieve faster deployment and faster results. For companies to achieve real intelligent automation, a single unified platform that combine AI, robotics, and case management needs to be implemented to plan customer outcomes. Agile platforms that enable businesses to easily adapt in times of change is the key to success in a constantly evolving environment. Businesses have the means to retire poor technology and inefficient processes by investing in intelligent automation. Those that do will achieve greater results at a lower cost while delivering a boost in customer satisfaction.
(Photo by Robina Weermeijer on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, automation, enterprise, Featured, robotics






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Opinion: What is real intelligent automation?,2021-01-29,"['Don Schuerman', 'Don Is Cto At Pegasystems', 'Responsible For Pega S Platform', 'Customer Relationship Management', 'Crm', 'Applications.', 'He Has Years', 'Experience Delivering Enterprise Software Solutions For Fortune Organisations', 'With A Focus On Digital Transformation', 'Mobility']","['process', 'technology', 'opinion', 'customer', 'business', 'case', 'expo', 'intelligent', 'topdown', 'management', 'automation', 'real']","With intelligent automation, manufacturing giant Siemens has driven 10 times faster processes at a tenth of the cost.
However, some software vendors place commodity AI-like OCR or image recognition combined with robotic process automation (RPA) under the same umbrella as intelligent automation.
Others label intelligent automation as just smart robots when in reality there is much more to it.
Case management and AICombining the decision-making capabilities of AI with case management is crucial to getting work completed.
Fast deployment, fast resultsBy applying a centre-out approach to intelligent automation, organisations can achieve faster deployment and faster results.",AInews
129,https://artificialintelligence-news.com/events/2021/jan/12/blockchain-expo-global-virtual-2021-17-18th-march-2021/,"

Blockchain Expo Global Virtual 2021 | 17-18th March 2021





   

Event Information


Start: 17 March 2021 9:20 am                            

End: 18 March 2021 1:20 pm                            



                                Virtual Conference                                 


Blockchain Expo World Series

enquiries@blockchain-expo.com


+4401179809023





A virtual event for the global blockchain ecosystem. 
Register free here
About Blockchain Expo Virtual
A FREE online conference covering two days of top-level content and thought leadership discussions looking at the Blockchain ecosystem.
This virtual conference is for the ambitious enterprise technology professional, seeking to explore the latest innovations, implementations and strategies to drive businesses forward.
Consisting of live and on-demand sessions, don’t miss this opportunity to explore this innovative technology and its impact on a range of industries including, manufacturing, transport, supply chain, government, legal sectors and financial services energy, utilities, insurance, healthcare, retail and more!
Our community of industry experts will explore and debate the technological advancements across the digital eco-system and beyond.
Blockchain topics include: Emerging technologies, risk management, Blockchain adoption, digital assets, Tokenisation, supply chain & logistics
Some industry leaders joining us:
Dean Demellweek, Digital Transformation Leader, BNP Paribas CIBWilliam Lovell, Head of Future Technology, Bank of EnglandDr. Anushka Patchava, Proposition & Strategy Lead, Aetna, a CVS Health CompanyBob Wolpert, Chief Strategy & Innovation Officer, Golden State FoodsEmmanuelle Ganne, Senior Analyst, World Trade OrganisationBenjamin Duve, Head of Digital Assets and Custody, Commerzbank AGJim Cunha, SVP, Federal Reserve Bank of BostonGaurav Aggarwal, Head of DLT & Tokenisation, HSBCKim Schneider, Blockchain Specialist, RabobankMassimo Buonomo, UN Global Expert in Blockchain, Cryptocurrencies, AI, Fintech, & Reg-tech, UN | United Nations Alliance of Civilizations

 





   

Event Information


Start: 17 March 2021 9:20 am                            

End: 18 March 2021 1:20 pm                            



                                Virtual Conference                                 


Blockchain Expo World Series

enquiries@blockchain-expo.com


+4401179809023



A virtual event for the global blockchain ecosystem. 
Register free here
About Blockchain Expo Virtual
A FREE online conference covering two days of top-level content and thought leadership discussions looking at the Blockchain ecosystem.
This virtual conference is for the ambitious enterprise technology professional, seeking to explore the latest innovations, implementations and strategies to drive businesses forward.
Consisting of live and on-demand sessions, don’t miss this opportunity to explore this innovative technology and its impact on a range of industries including, manufacturing, transport, supply chain, government, legal sectors and financial services energy, utilities, insurance, healthcare, retail and more!
Our community of industry experts will explore and debate the technological advancements across the digital eco-system and beyond.
Blockchain topics include: Emerging technologies, risk management, Blockchain adoption, digital assets, Tokenisation, supply chain & logistics
Some industry leaders joining us:
Dean Demellweek, Digital Transformation Leader, BNP Paribas CIBWilliam Lovell, Head of Future Technology, Bank of EnglandDr. Anushka Patchava, Proposition & Strategy Lead, Aetna, a CVS Health CompanyBob Wolpert, Chief Strategy & Innovation Officer, Golden State FoodsEmmanuelle Ganne, Senior Analyst, World Trade OrganisationBenjamin Duve, Head of Digital Assets and Custody, Commerzbank AGJim Cunha, SVP, Federal Reserve Bank of BostonGaurav Aggarwal, Head of DLT & Tokenisation, HSBCKim Schneider, Blockchain Specialist, RabobankMassimo Buonomo, UN Global Expert in Blockchain, Cryptocurrencies, AI, Fintech, & Reg-tech, UN | United Nations Alliance of Civilizations

 







",Blockchain Expo Global Virtual 2021,2021-01-12,[],"['explore', 'technology', 'tokenisation', 'digital', 'global', 'virtual', '2021', 'expo', 'blockchain', 'supply', 'head', 'industry', 'strategy']","A virtual event for the global blockchain ecosystem.
Register free hereAbout Blockchain Expo VirtualA FREE online conference covering two days of top-level content and thought leadership discussions looking at the Blockchain ecosystem.
This virtual conference is for the ambitious enterprise technology professional, seeking to explore the latest innovations, implementations and strategies to drive businesses forward.
Consisting of live and on-demand sessions, don’t miss this opportunity to explore this innovative technology and its impact on a range of industries including, manufacturing, transport, supply chain, government, legal sectors and financial services energy, utilities, insurance, healthcare, retail and more!
Our community of industry experts will explore and debate the technological advancements across the digital eco-system and beyond.",AInews
130,https://artificialintelligence-news.com/events/2020/dec/11/data-centre-congress-2021/,"

Data Centre Congress 2021 – 4th March 2021





   

Event Information


Start: 4 March 2021 10:00 am                            

End: 4 March 2021 1:00 pm                            


Online event






Data Centre Congress 2021, 4th March, is a FREE virtual event and conference consisting of top-level content and thought leadership discussions exploring the data centre ecosystem.
This event will shine a spotlight on the future outlook for the sector, as demand for data centre space increases exponentially. Join your peer group of enterprise IT specialists for this free online event and discover what is preventing cloud computing from going faster, why a reliable data centre is so essential during a time of crisis, and the implications of increased data gravity for businesses.
Click here to learn more and register for FREE!
WHO ATTENDS?The online conference is perfect for technology professionals making investment and technology selection decisions, or building and executing pioneering projects within their organisations.The event will consist of live and on-demand sessions featuring 20 influential speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Attend the event to learn:○ The implications of increased data gravity for businesses○ How customised collocation can underpin customer innovation○ The impact of the rise of edge computing on the landscape for data centres○ The business case for enterprise consumption of data centre-as-a-service○ Which data centre model is right for your business
SPEAKERS:○ Mark Acton, Independent Data Centre Consultant○ techUK – Emma Fryer, Associate Director○ HM Government – Ian Holford, Head of Information Security Management○ Trinity College Dublin – Cathal O’Donnell, ICT Facilities Manager○ RISE – Jon Summers, Scientific Leader in Data Centres
… and many more! Click here to view full list of speakers.
TOPICS INCLUDE:○ Data gravity for businesses○ Customised collocation○ Customer innovation○ Edge Computing○ Data Centre-as-a-service○ Data Centre Models
WHY ATTEND?The events of 2020 have placed an unprecedented level of demand upon data centre capacity, as businesses of all types dynamically accelerate digital transformation initiatives in a rush to retain market share and competitive foothold. Now is the time of ‘digital everything’.Data Centre Congress EMEA 2021, 4th March, will shine a spotlight on the future outlook for the sector, as demand for data centre space increases exponentially. Join your peer group of enterprise IT specialists for this free online event and discover what is preventing cloud computing from going faster, why a reliable data centre is so essential during a time of crisis, and the implications of increased data gravity for businesses.
NETWORKING OPPORTUNITIESThere are many opportunities to network at the virtual Data Centre Congress. Meet virtually with specialists who can provide you with actionable advice as you develop your cloud and data approach. Our AI-powered Matchmaking Tool is the official networking platform for the event and also the platform to watch all sessions.Login to the platform to plan your day with ease; view the agenda, speakers and exhibitors. You can also connect with and organise meetings with other attendees, speakers, sponsors and exhibitors.
Click here to learn more and register for FREE!
 





   

Event Information


Start: 4 March 2021 10:00 am                            

End: 4 March 2021 1:00 pm                            


Online event




Data Centre Congress 2021, 4th March, is a FREE virtual event and conference consisting of top-level content and thought leadership discussions exploring the data centre ecosystem.
This event will shine a spotlight on the future outlook for the sector, as demand for data centre space increases exponentially. Join your peer group of enterprise IT specialists for this free online event and discover what is preventing cloud computing from going faster, why a reliable data centre is so essential during a time of crisis, and the implications of increased data gravity for businesses.
Click here to learn more and register for FREE!
WHO ATTENDS?The online conference is perfect for technology professionals making investment and technology selection decisions, or building and executing pioneering projects within their organisations.The event will consist of live and on-demand sessions featuring 20 influential speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Attend the event to learn:○ The implications of increased data gravity for businesses○ How customised collocation can underpin customer innovation○ The impact of the rise of edge computing on the landscape for data centres○ The business case for enterprise consumption of data centre-as-a-service○ Which data centre model is right for your business
SPEAKERS:○ Mark Acton, Independent Data Centre Consultant○ techUK – Emma Fryer, Associate Director○ HM Government – Ian Holford, Head of Information Security Management○ Trinity College Dublin – Cathal O’Donnell, ICT Facilities Manager○ RISE – Jon Summers, Scientific Leader in Data Centres
… and many more! Click here to view full list of speakers.
TOPICS INCLUDE:○ Data gravity for businesses○ Customised collocation○ Customer innovation○ Edge Computing○ Data Centre-as-a-service○ Data Centre Models
WHY ATTEND?The events of 2020 have placed an unprecedented level of demand upon data centre capacity, as businesses of all types dynamically accelerate digital transformation initiatives in a rush to retain market share and competitive foothold. Now is the time of ‘digital everything’.Data Centre Congress EMEA 2021, 4th March, will shine a spotlight on the future outlook for the sector, as demand for data centre space increases exponentially. Join your peer group of enterprise IT specialists for this free online event and discover what is preventing cloud computing from going faster, why a reliable data centre is so essential during a time of crisis, and the implications of increased data gravity for businesses.
NETWORKING OPPORTUNITIESThere are many opportunities to network at the virtual Data Centre Congress. Meet virtually with specialists who can provide you with actionable advice as you develop your cloud and data approach. Our AI-powered Matchmaking Tool is the official networking platform for the event and also the platform to watch all sessions.Login to the platform to plan your day with ease; view the agenda, speakers and exhibitors. You can also connect with and organise meetings with other attendees, speakers, sponsors and exhibitors.
Click here to learn more and register for FREE!
 







",Data Centre Congress 2021 – 4th March 2021,2020-12-11,[],"['data', 'congress', 'event', 'centre', '2021', 'free', 'specialists', 'computing', '4th', 'speakers', 'online', 'gravity', 'platform']","Data Centre Congress 2021, 4th March, is a FREE virtual event and conference consisting of top-level content and thought leadership discussions exploring the data centre ecosystem.
This event will shine a spotlight on the future outlook for the sector, as demand for data centre space increases exponentially.
TOPICS INCLUDE:○ Data gravity for businesses○ Customised collocation○ Customer innovation○ Edge Computing○ Data Centre-as-a-service○ Data Centre ModelsWHY ATTEND?
Data Centre Congress EMEA 2021, 4th March, will shine a spotlight on the future outlook for the sector, as demand for data centre space increases exponentially.
NETWORKING OPPORTUNITIESThere are many opportunities to network at the virtual Data Centre Congress.",AInews
131,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
132,https://artificialintelligence-news.com/events/2021/jan/12/blockchain-expo-north-america-2021-22-23-september-2021/,"

Blockchain Expo North America 2021 | 22-23 September 2021





   

Event Information


Start: 22 September 2021 9:00 am                            

End: 23 September 2021 4:00 pm                            



                                Santa Clara Convention Center                                 


Blockchain Expo World Series

enquiries@blockchain-expo.com


+4401179809023





Register here
About the Blockchain Expo North America 2021
The Blockchain Expo North America is a technology conference and event covering two days of top-level content and thought leadership discussions looking at the Blockchain ecosystem.
Taking place at the Santa Clara Convention Center, Silicon Valley, this event is aimed at the ambitious enterprise technology professional, seeking to explore the latest innovations, implementations and strategies to drive businesses forward.
Don’t miss the opportunity to explore this innovative technology and its impact on a range of industries including, manufacturing, transport, supply chain, government, legal sectors and financial services energy, utilities, insurance, healthcare, retail and more!
In addition to cutting edge content, the Blockchain Expo North America also offers exclusive networking opportunities! For more information, get in touch!
Who attends?
Over 10,000 attendees are expected to join from across the globe including CTO’s, Heads of Innovation and Technology, IT Directors, Telecom Providers, Developers, Start-Up’s, OEM’s, Government, Automotive, Operators, Technology Providers, Investors, VCs and many more.
The Expo will provide insight from over 500 speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key Topics
The Blockchain Expo North America conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies. All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.
Register here
 





   

Event Information


Start: 22 September 2021 9:00 am                            

End: 23 September 2021 4:00 pm                            



                                Santa Clara Convention Center                                 


Blockchain Expo World Series

enquiries@blockchain-expo.com


+4401179809023



Register here
About the Blockchain Expo North America 2021
The Blockchain Expo North America is a technology conference and event covering two days of top-level content and thought leadership discussions looking at the Blockchain ecosystem.
Taking place at the Santa Clara Convention Center, Silicon Valley, this event is aimed at the ambitious enterprise technology professional, seeking to explore the latest innovations, implementations and strategies to drive businesses forward.
Don’t miss the opportunity to explore this innovative technology and its impact on a range of industries including, manufacturing, transport, supply chain, government, legal sectors and financial services energy, utilities, insurance, healthcare, retail and more!
In addition to cutting edge content, the Blockchain Expo North America also offers exclusive networking opportunities! For more information, get in touch!
Who attends?
Over 10,000 attendees are expected to join from across the globe including CTO’s, Heads of Innovation and Technology, IT Directors, Telecom Providers, Developers, Start-Up’s, OEM’s, Government, Automotive, Operators, Technology Providers, Investors, VCs and many more.
The Expo will provide insight from over 500 speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key Topics
The Blockchain Expo North America conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies. All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.
Register here
 







",Blockchain Expo North America 2021,2021-01-12,[],"['north', 'technology', 'discussions', 'sectors', 'america', '2021', 'services', 'including', 'expo', 'blockchain', 'retail']","Register hereAbout the Blockchain Expo North America 2021The Blockchain Expo North America is a technology conference and event covering two days of top-level content and thought leadership discussions looking at the Blockchain ecosystem.
In addition to cutting edge content, the Blockchain Expo North America also offers exclusive networking opportunities!
The Expo will provide insight from over 500 speakers sharing their unparalleled industry knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key TopicsThe Blockchain Expo North America conference agenda will present a series of expert keynotes, interactive panel discussions and solution-based case studies.
All exploring the key industries that are set to be disrupted the most by this new technology, including; legal sectors, retail, financial services, healthcare, insurance, energy, music, government, real estate and more.",AInews
133,https://artificialintelligence-news.com/2020/07/23/deep-learning-predict-critical-covid-19-cases/,"

Deep learning is being used to predict critical COVID-19 cases




 






By Ryan Daws |
        July 23, 2020                    | TechForge Media

                            Categories:
                                    Healthcare,
                                    Machine Learning,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers from Tencent, along with other Chinese scientists, are using deep learning to predict critical COVID-19 cases.
Scientists around the world are doing incredible work to increase our understanding of COVID-19. Thanks to their findings, existing medications have been discovered to increase the likelihood of surviving the virus.
Unfortunately, there are still fatalities. People with weakened immune systems or underlying conditions are most at risk, but it’s a dangerous myth that the young and otherwise healthy can’t die from this virus.
According to a paper published in science journal Nature, around 6.5 percent of COVID-19 cases have a “worrying trend of sudden progression to critical illness”. Of those cases, there’s a mortality rate of 49 percent.
In the aforementioned paper, the researchers wrote: “Since early intervention is associated with improved prognosis, the ability to identify patients that are most at risk of developing severe disease upon admission will ensure that these patients receive appropriate care as soon as possible.”
While most countries appear to be reaching the end of the first wave of COVID-19, the possibility of a second threatens. Many experts forecast another wave will hit during the winter months; when hospitals already struggle from seasonal viruses.
One of the biggest challenges with COVID-19 is triaging patients to decide who are most at risk and require more resources allocated to their care. During the peak of the outbreak in Italy, doctors reported reaching a point of having to make heartbreaking decisions over whether it was a waste of limited resources even trying to save someone.
A team led by China’s senior medical advisor on COVID-19, Zhong Nanshan, was established in February. The team consisted of researchers from Tencent AI Lab in addition to Chinese public health scientists.
Nanshan’s team set out to build a deep learning-based system which can predict whether a patient is likely to become a critical case. Such information would be invaluable to ensuring the patient gets early intervention to improve their chances of surviving the virus in addition to supporting medical staff with their triaging decisions.
The deep learning model was trained on data from 1590 patients from 575 medical centers across China, with further validation from 1393 patients.
Tencent has made the COVID-19 tool for predicting critical COVID-19 cases available online here (Please note the small print which currently says “this tool is for research purpose and not approved for clinical use.”)
(Photo by Ashkan Forouzani on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, coronavirus, covid-19, deep learning, Featured, health, healthcare, medical, research, tencent






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Deep learning is being used to predict critical COVID-19 cases,2020-07-23,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['medical', 'cases', 'learning', 'risk', 'predict', 'expo', 'critical', 'world', 'deep', 'patients', 'covid19', 'used', 'team']","Researchers from Tencent, along with other Chinese scientists, are using deep learning to predict critical COVID-19 cases.
According to a paper published in science journal Nature, around 6.5 percent of COVID-19 cases have a “worrying trend of sudden progression to critical illness”.
Nanshan’s team set out to build a deep learning-based system which can predict whether a patient is likely to become a critical case.
Tencent has made the COVID-19 tool for predicting critical COVID-19 cases available online here (Please note the small print which currently says “this tool is for research purpose and not approved for clinical use.”)(Photo by Ashkan Forouzani on Unsplash)Interested in hearing industry leaders discuss subjects like this?
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
134,https://artificialintelligence-news.com/2020/11/05/algorithmia-insights-ml-model-performance-monitoring/,"

Algorithmia announces Insights for ML model performance monitoring




 






By Ryan Daws |
        November 5, 2020                    | TechForge Media

                            Categories:
                                    Machine Learning,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Seattle-based Algorithmia has announced Insights, a solution for monitoring the performance of machine learning models.
Algorithmia specialises in artificial intelligence operations and management. The company is backed by Google LLC and focuses on simplifying AI projects for enterprises just getting started.
Diego Oppenheimer, CEO of Algorithmia, says:
“Organisations have specific needs when it comes to ML model monitoring and reporting.For example, they are concerned with compliance as it pertains to external and internal regulations, model performance for improvement of business outcomes, and reducing the risk of model failure.Algorithmia Insights helps users overcome these issues while making it easier to monitor model performance in the context of other operational metrics and variables.” 
Insights aims to help enterprises to monitor the performance of their machine learning models. Many organisations currently don’t have that ability, or use a complex variety of tools and/or manual processes.
Operational metrics like execution time and request identification are combined with user-defined metrics such as confidence and accuracy to identify data skews, negative feedback loops, and model drift.
Model drift, in layman’s terms, is the degradation of a model’s prediction power due to changes in the environment—which subsequently impacts the relationship between variables. A far more detailed explanation can be found here for those interested.

Algorithmia teamed up with monitoring service Datadog to allow customers to stream operational – as well as user-defined inference metrics – from Algorithmia, to Kafka, and then into Datadog.
Ilan Rabinovitch, Vice President of Product and Community at Datadog, comments:
“ML models are at the heart of today’s business. Understanding how they perform both statistically and operationally is key to success.By combining the findings of Algorithmia Insights and Datadog’s deep visibility into code and integration, our mutual customers can drive more accurate and performant outcomes from their ML models.”
Through integration with Datadog and its Metrics API, customers can measure and monitor their ML models to immediately detect data drift, model drift, and model bias.
(Photo by Chris Liverani on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, algorithmia, analytics, artificial intelligence, Featured, insights, machine learning, Model, monitoring, performance






View Comments


Leave a comment




            One comment on “Algorithmia announces Insights for ML model performance monitoring”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Algorithmia announces Insights for ML model performance monitoring,2020-11-05,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['performance', 'insights', 'announces', 'algorithmia', 'model', 'monitoring', 'ml', 'models', 'metrics', 'expo', 'monitor']","Seattle-based Algorithmia has announced Insights, a solution for monitoring the performance of machine learning models.
Diego Oppenheimer, CEO of Algorithmia, says:“Organisations have specific needs when it comes to ML model monitoring and reporting.
For example, they are concerned with compliance as it pertains to external and internal regulations, model performance for improvement of business outcomes, and reducing the risk of model failure.
Algorithmia Insights helps users overcome these issues while making it easier to monitor model performance in the context of other operational metrics and variables.”Insights aims to help enterprises to monitor the performance of their machine learning models.
Algorithmia teamed up with monitoring service Datadog to allow customers to stream operational – as well as user-defined inference metrics – from Algorithmia, to Kafka, and then into Datadog.",AInews
135,https://artificialintelligence-news.com/2020/06/03/bbc-virtual-assistant-tested-in-uk/,"

The BBC’s virtual assistant is now available for testing in the UK




 






By Ryan Daws |
        June 3, 2020                    | TechForge Media

                            Categories:
                                    UK,
                                    Virtual Assistants,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A virtual assistant from the BBC which aims to cater for Britain’s many dialects is now available for testing.
Even as a Brit, it can often feel like a translation app is needed between Bristolian, Geordie, Mancunian, Brummie, Scottish, Irish, or any of the other regional dialects in the country. For a geographically small country, we’re a diverse bunch – and US-made voice assistants often struggle with even the slightest accent.
The BBC thinks it can do a better job than the incumbents and first announced its plans to build a voice assistant called ‘Beeb’ in August last year.
Beeb is being trained using the BBC’s staff from around the country. As a public service, the institution aims to offer as wide representation as possible which is reflected in its employees.
The broadcaster also believes that Beeb addresses public concerns about voice assistants; primarily that they collect vast amounts of data for commercial purposes. As a taxpayer-funded service, the BBC does not rely on things like advertising.
“People know and trust the BBC,” a spokesperson told The Guardian last year, “so it will use its role as public service innovator in technology to ensure everyone – not just the tech-elite – can benefit from accessing content and new experiences in this new way.”
An early version of Beeb is now available for testing by UK participants of the Windows Insider program. Microsoft is heavily involved in the Beeb assistant as the company’s Azure AI services are being used by the BBC.
The first version of Beeb allows users to do virtual assistant norms like getting weather updates and the news, access radio and podcasts, and even grab a few jokes from BBC Comedy writers and facts from QI host Sandi Toksvig.
According to the broadcaster, Beeb won’t launch on dedicated hardware but instead will be designed to eventually be implemented in smart speakers, TVs, and mobiles.
While it still has a long way to go to take on the capabilities of Google, Alexa, Siri, and others, Beeb may offer a compelling alternative for accent-heavy Brits that struggle with American voice assistants.
Grab the Beeb app from the Microsoft Store here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, assistant, bbc, beeb, Featured, iot, uk, virtual assistant






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",The BBC’s virtual assistant is now available for testing in the UK,2020-06-03,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['country', 'public', 'uk', 'assistant', 'virtual', 'beeb', 'bbc', 'voice', 'version', 'expo', 'available', 'service', 'bbcs', 'testing']","A virtual assistant from the BBC which aims to cater for Britain’s many dialects is now available for testing.
The BBC thinks it can do a better job than the incumbents and first announced its plans to build a voice assistant called ‘Beeb’ in August last year.
As a public service, the institution aims to offer as wide representation as possible which is reflected in its employees.
Microsoft is heavily involved in the Beeb assistant as the company’s Azure AI services are being used by the BBC.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
136,https://artificialintelligence-news.com/author/sampathkumarveeraraghavan/,"



How can AI-powered humanitarian engineering tackle the biggest threats facing our planet?










Humanitarian engineering programs bring together engineers, policy makers, non-profit organisations, and local communities to leverage technology for the greater good of humanity.
The intersection of technology, community, and sustainability offers a plethora of opportunities to innovate. We still live in an era where millions of people are under extreme poverty, lacking access to clean water, basic sanitation, electricity, internet, quality education, and... 






        28 August 2020                    |
            Agriculture





","Sampathkumar Veeraraghavan, Author at AI News",,['Sampathkumar Veeraraghavan'],"['technology', 'sustainability', 'sampathkumar', 'programs', 'sanitation', 'water', 'quality', 'policy', 'ai', 'author', 'plethora', 'poverty', 'organisations', 'veeraraghavan']","Humanitarian engineering programs bring together engineers, policy makers, non-profit organisations, and local communities to leverage technology for the greater good of humanity.
The intersection of technology, community, and sustainability offers a plethora of opportunities to innovate.
We still live in an era where millions of people are under extreme poverty, lacking access to clean water, basic sanitation, electricity, internet, quality education, and...",AInews
137,https://artificialintelligence-news.com/2020/02/25/met-police-commissioner-critics-facial-recognition-systems/,"

Met Police commissioner dismisses critics of facial recognition systems




 






By Ryan Daws |
        February 25, 2020                    | TechForge Media

                            Categories:
                                    Face Recognition,
                                    Government,
                                    Law Enforcement,
                                    Privacy,
                                    Society,
                                    Surveillance,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




The chief commissioner of the Metropolitan Police has dismissed critics of law enforcement using facial recognition systems.
Met Commissioner Cressida Dick was speaking at the Royal United Services Institute think tank on Monday. Much of Dick’s speech was spent on making the case for British police to use modern technologies to tackle crime.



Dick accused critics of police facial recognition technology as being “highly inaccurate or highly ill-informed.”
Needless to say, this angered said critics who believe Dick is the one who is ill-informed by ignoring an independent report which suggests the technology in question only works in just 19 percent of cases.
“I would say it is for critics to justify to the victims of crimes why police should not be allowed to use tech lawfully and proportionally to catch criminals,” Dick argued.
Dick says she welcomes a public debate about facial recognition but attacked organisations such as Big Brother Watch and Liberty who brought the attention to the wider public.
“It’s unhelpful for the Met to reduce a serious debate on facial recognition to unfounded accusations of ‘fake news’,” Big Brother Watch tweeted. “Dick would do better to acknowledge and engage with the real, serious concerns – including those in the damning independent report that she ignored.”
Liberty tweeted a similar response: “Fact: Met started using facial recognition after ignoring its own review of two-year trial that said its use of the tech didn’t respect human rights. Another fact: scaremongering and deriding criticisms instead of engaging shows how flimsy their basis for using it really is.”
Met Police tests of facial recognition technology so far have been nothing short of a complete failure.
An initial trial, at the 2016 Notting Hill Carnival, led to not a single person being identified. A follow-up trial the following year led to no legitimate matches but 35 false positives.
Ironically, the legality of the trials has been called into question. An independent report by Professor Peter Fussey and Dr Daragh Murray last year concluded the six trials they were given access to were probably illegal since they had not accounted for human rights compliance.
Dr Murray said: “This report raises significant concerns regarding the human rights law compliance of the trials.
“The legal basis for the trials was unclear and is unlikely to satisfy the ‘in accordance with the law’ test established by human rights law.
“It does not appear that an effective effort was made to identify human rights harms or to establish the necessity of LFR.
“Ultimately, the impression is that human rights compliance was not built into the Metropolitan Police’s systems from the outset, and was not an integral part of the process.”
You can find a copy of the full report here (PDF)
(Image Credit: Met police helmet by Matt Brown under CC BY 2.0 license)

 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: cressida dick, face recognition, facial recognition, Featured, met, metropolitan police, police, privacy, Society, surveillance, uk






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Met Police commissioner dismisses critics of facial recognition systems,2020-02-25,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['human', 'systems', 'recognition', 'rights', 'dismisses', 'using', 'commissioner', 'met', 'expo', 'tech', 'dick', 'critics', 'report', 'facial']","The chief commissioner of the Metropolitan Police has dismissed critics of law enforcement using facial recognition systems.
“It’s unhelpful for the Met to reduce a serious debate on facial recognition to unfounded accusations of ‘fake news’,” Big Brother Watch tweeted.
“The legal basis for the trials was unclear and is unlikely to satisfy the ‘in accordance with the law’ test established by human rights law.
“It does not appear that an effective effort was made to identify human rights harms or to establish the necessity of LFR.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
138,https://artificialintelligence-news.com/2020/12/09/aws-nine-major-updates-ml-platform-sagemaker/,"

AWS announces nine major updates for its ML platform SageMaker




 






By Ryan Daws |
        December 9, 2020                    | TechForge Media

                            Categories:
                                    Amazon,
                                    Applications,
                                    Developers,
                                    Machine Learning,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Amazon Web Services (AWS) has announced nine major new updates for its cloud-based machine learning platform, SageMaker.
SageMaker aims to provide a machine learning service which can be used to build, train, and deploy ML models for virtually any use case.
During this year’s re:Invent conference, AWS made several announcements to further improve SageMaker’s capabilities.
Swami Sivasubramanian, VP of Amazon Machine Learning at AWS, said:
“Hundreds of thousands of everyday developers and data scientists have used our industry-leading machine learning service, Amazon SageMaker, to remove barriers to building, training, and deploying custom machine learning models. One of the best parts about having such a widely-adopted service like SageMaker is that we get lots of customer suggestions which fuel our next set of deliverables.Today, we are announcing a set of tools for Amazon SageMaker that makes it much easier for developers to build end-to-end machine learning pipelines to prepare, build, train, explain, inspect, monitor, debug, and run custom machine learning models with greater visibility, explainability, and automation at scale.”
The first announcement is Data Wrangler, a feature which aims to automate the preparation of data for machine learning.
Data Wrangler enables customers to choose the data they want from their various data stores and import it with a single click. Over 300 built-in data transformers are included to help customers normalise, transform, and combine features without having to write any code.
Frank Farrall, Principal of AI Ecosystems and Platforms Leader at Deloitte, comments:
“SageMaker Data Wrangler enables us to hit the ground running to address our data preparation needs with a rich collection of transformation tools that accelerate the process of machine learning data preparation needed to take new products to market.In turn, our clients benefit from the rate at which we scale deployments, enabling us to deliver measurable, sustainable results that meet the needs of our clients in a matter of days rather than months.”
The second announcement is Feature Store. Amazon SageMaker Feature Store provides a new repository that makes it easy to store, update, retrieve, and share machine learning features for training and inference.
Feature Store aims to overcome the problem of storing features which are mapped to multiple models. A purpose-built feature store helps developers to access and share features that make it much easier to name, organise, find, and share sets of features among teams of developers and data scientists. Because it resides in SageMaker Studio – close to where ML models are run – AWS claims it provides single-digit millisecond inference latency.
Mammad Zadeh, VP of Engineering, Data Platform at Intuit, says:
“We have worked closely with AWS in the lead up to the release of Amazon SageMaker Feature Store, and we are excited by the prospect of a fully managed feature store so that we no longer have to maintain multiple feature repositories across our organization.Our data scientists will be able to use existing features from a central store and drive both standardisation and reuse of features across teams and models.”
Next up, we have SageMaker Pipelines—which claims to be the first purpose-built, easy-to-use continuous integration and continuous delivery (CI/CD) service for machine learning.
Developers can define each step of an end-to-end machine learning workflow including the data-load steps, transformations from Amazon SageMaker Data Wrangler, features stored in Amazon SageMaker Feature Store, training configuration and algorithm set up, debugging steps, and optimisation steps.
SageMaker Clarify may be one of the most important features being debuted by AWS this week considering ongoing events.
Clarify aims to provide bias detection across the machine learning workflow, enabling developers to build greater fairness and transparency into their ML models. Rather than turn to often time-consuming open-source tools, developers can use the integrated solution to quickly try and counter any bias in models.
Andreas Heyden, Executive VP of Digital Innovations for the DFL Group, says:
“Amazon SageMaker Clarify seamlessly integrates with the rest of the Bundesliga Match Facts digital platform and is a key part of our long-term strategy of standardising our machine learning workflows on Amazon SageMaker.By using AWS’s innovative technologies, such as machine learning, to deliver more in-depth insights and provide fans with a better understanding of the split-second decisions made on the pitch, Bundesliga Match Facts enables viewers to gain deeper insights into the key decisions in each match.”
Deep Profiling for Amazon SageMaker automatically monitors system resource utilisation and provides alerts where required for any detected training bottlenecks. The feature works across frameworks (PyTorch, Apache MXNet, and TensorFlow) and collects system and training metrics automatically without requiring any code changes in training scripts.
Next up, we have Distributed Training on SageMaker which AWS claims makes it possible to train large, complex deep learning models up to two times faster than current approaches.
Kristóf Szalay, CTO at Turbine, comments:
“We use machine learning to train our in silico human cell model, called Simulated Cell, based on a proprietary network architecture. By accurately predicting various interventions on the molecular level, Simulated Cell helps us to discover new cancer drugs and find combination partners for existing therapies.Training of our simulation is something we continuously iterate on, but on a single machine each training takes days, hindering our ability to iterate on new ideas quickly.We are very excited about Distributed Training on Amazon SageMaker, which we are expecting to decrease our training times by 90% and to help us focus on our main task: to write a best-of-the-breed codebase for the cell model training.Amazon SageMaker ultimately allows us to become more effective in our primary mission: to identify and develop novel cancer drugs for patients.”
SageMaker’s Data Parallelism engine scales training jobs from a single GPU to hundreds or thousands by automatically splitting data across multiple GPUs, improving training time by up to 40 percent.
With edge computing advancements increasing rapidly, AWS is keeping pace with SageMaker Edge Manager.
Edge Manager helps developers to optimise, secure, monitor, and maintain ML models deployed on fleets of edge devices. In addition to helping optimise ML models and manage edge devices, Edge Manager also provides the ability to cryptographically sign models, upload prediction data from devices to SageMaker for monitoring and analysis, and view a dashboard which tracks and provided a visual report on the operation of the deployed models within the SageMaker console.
Igor Bergman, VP of Cloud and Software of PCs and Smart Devices at Lenovo, comments:
“SageMaker Edge Manager will help eliminate the manual effort required to optimise, monitor, and continuously improve the models after deployment. With it, we expect our models will run faster and consume less memory than with other comparable machine-learning platforms.As we extend AI to new applications across the Lenovo services portfolio, we will continue to require a high-performance pipeline that is flexible and scalable both in the cloud and on millions of edge devices. That’s why we selected the Amazon SageMaker platform. With its rich edge-to-cloud and CI/CD workflow capabilities, we can effectively bring our machine learning models to any device workflow for much higher productivity.”
Finally, SageMaker JumpStart aims to make it easier for developers which have little experience with machine learning deployments to get started.
JumpStart provides developers with an easy-to-use, searchable interface to find best-in-class solutions, algorithms, and sample notebooks. Developers can select from several end-to-end machine learning templates(e.g. fraud detection, customer churn prediction, or forecasting) and deploy them directly into their SageMaker Studio environments.
AWS has been on a roll with SageMaker improvements—delivering more than 50 new capabilities over the past year. After this bumper feature drop, we probably shouldn’t expect any more until we’ve put 2020 behind us.
You can find coverage of AWS’ more cloud-focused announcements via our sister publication CloudTech here.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: Amazon, amazon sagemaker, amazon web services, aws, bias, data wrangler, distributed training, edge, edge computing, edge manager, feature store, Featured, machine learning, platform, Sagemaker, sagemaker clarify






View Comments


Leave a comment




            One comment on “AWS announces nine major updates for its ML platform SageMaker”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",AWS announces nine major updates for its ML platform SageMaker,2020-12-09,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['data', 'announces', 'amazon', 'developers', 'store', 'learning', 'ml', 'updates', 'models', 'feature', 'platform', 'machine', 'training', 'sagemaker', 'major', 'aws']","Amazon Web Services (AWS) has announced nine major new updates for its cloud-based machine learning platform, SageMaker.
SageMaker aims to provide a machine learning service which can be used to build, train, and deploy ML models for virtually any use case.
Swami Sivasubramanian, VP of Amazon Machine Learning at AWS, said:“Hundreds of thousands of everyday developers and data scientists have used our industry-leading machine learning service, Amazon SageMaker, to remove barriers to building, training, and deploying custom machine learning models.
Amazon SageMaker Feature Store provides a new repository that makes it easy to store, update, retrieve, and share machine learning features for training and inference.
That’s why we selected the Amazon SageMaker platform.",AInews
139,https://artificialintelligence-news.com/2020/11/19/tensorflow-now-available-new-arm-based-macs/,"

TensorFlow is now available for those shiny new ARM-based Macs




 






By Ryan Daws |
        November 19, 2020                    | TechForge Media

                            Categories:
                                    Apple,
                                    Developers,
                                    Hardware,
                                    Machine Learning,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




A new version of machine learning library TensorFlow has been released with optimisations for Apple’s new ARM-based Macs.
While still technically in pre-release, the Mac-optimised TensorFlow fork supports native hardware acceleration on Mac devices with M1 or Intel chips through Apple’s ML Compute framework.
The new TensorFlow release boasts of an over 10x speed improvement for common training tasks. While impressive, it has to be taken in the context that the GPU was not previously used for training tasks. 
A look at the benchmarks still indicates a substantial gap between the Intel and M1-based Macs across various machine learning models:

In a blog post, Pankaj Kanwar, Tensor Processing Units Technical Program Manager at Google, and Fred Alcober, TensorFlow Product Marketing Lead at Google, wrote:
“These improvements, combined with the ability of Apple developers being able to execute TensorFlow on iOS through TensorFlow Lite, continue to showcase TensorFlow’s breadth and depth in supporting high-performance ML execution on Apple hardware.”
We can only hope that running these workloads doesn’t turn MacBooks into expensive frying pans—but the remarkable efficiency they’ve displayed so far gives little cause for concern.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, apple, arm, artificial intelligence, developers, Featured, framework, m1, mac, macbook, machine learning, tensorflow






View Comments


Leave a comment




            One comment on “TensorFlow is now available for those shiny new ARM-based Macs”        



Leave a Reply Cancel replyYou must be logged in to post a comment. 






",TensorFlow is now available for those shiny new ARM-based Macs,2020-11-19,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['shiny', 'learning', 'ml', 'macs', 'expo', 'tech', 'available', 'armbased', 'intel', 'google', 'machine', 'apples', 'training', 'tensorflow']","Often sighted at global tech conferences with a coffee in one hand and laptop in the other.
A new version of machine learning library TensorFlow has been released with optimisations for Apple’s new ARM-based Macs.
While still technically in pre-release, the Mac-optimised TensorFlow fork supports native hardware acceleration on Mac devices with M1 or Intel chips through Apple’s ML Compute framework.
The new TensorFlow release boasts of an over 10x speed improvement for common training tasks.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
140,https://artificialintelligence-news.com/2021/02/10/researchers-find-systems-counter-deepfakes-can-be-deceived/,"

Researchers find systems to counter deepfakes can be deceived




 






By Ryan Daws |
        February 10, 2021                    | TechForge Media

                            Categories:
                                    Deepfakes,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California – San Diego, first presented their findings at the WACV 2021 conference.
Shehzeen Hussain, a UC San Diego computer engineering PhD student and co-author on the paper, said:
“Our work shows that attacks on deepfake detectors could be a real-world threat.More alarmingly, we demonstrate that it’s possible to craft robust adversarial deepfakes even when an adversary may not be aware of the inner-workings of the machine learning model used by the detector.”
Two scenarios were tested as part of the research:
The attackers have complete access to the detector model, including the face extraction pipeline and the architecture and parameters of the classification modelThe attackers can only query the machine learning model to figure out the probabilities of a frame being classified as real or fake.
In the first scenario, the attack’s success rate is above 99 percent for uncompressed videos. For compressed videos, it was 84.96 percent. In the second scenario, the success rate was 86.43 percent for uncompressed and 78.33 percent for compressed videos.
“We show that the current state of the art methods for deepfake detection can be easily bypassed if the adversary has complete or even partial knowledge of the detector,” the researchers wrote.
Deepfakes use a Generative Adversarial Network (GAN) to create fake imagery and even videos with increasingly convincing results. So-called ‘DeepPorn’ has been used to cause embarrassment and even blackmail.
There’s the old saying “I won’t believe it until I see it with my own eyes,” which is why convincing fake content is such a concern. As humans, we’re rather hard-wired to believe what we (think) we can see with our eyes.
In an age of disinformation, people are gradually learning not to believe everything they read—especially when it comes from unverified sources. Teaching people not to necessarily believe the images and video they see is going to pose a serious challenge.



Some hope has been placed on systems to detect and counter deepfakes before they cause harm. Unfortunately, the UC San Diego researchers’ findings somewhat dash those hopes.
“If the attackers have some knowledge of the detection system, they can design inputs to target the blind spots of the detector and bypass it,” ” said Paarth Neekhara, another co-author on the paper.
In separate research from University College London (UCL) last year, experts ranked what they believe to be the most serious AI threats. Deepfakes ranked top of the list.
“People now conduct large parts of their lives online and their online activity can make and break reputations,” said Dr Matthew Caldwell of UCL Computer Science.
One of the most high-profile deepfake cases so far was that of US house speaker Nancy Pelosi. In 2018, a deepfake video circulated on social media which made Pelosi appear drunk and slurring her words.
The video of Pelosi was likely created with the intention of being amusing rather than particularly malicious—but shows how deepfakes could be used to cause disrepute and even influence democratic processes.
As part of a bid to persuade Facebook to change its policies on deepfakes, last year Israeli startup Canny AI created a deepfake of Facebook CEO Mark Zuckerberg which made it appear like he said: “Imagine this for a second: One man, with total control of billions of people’s stolen data, all their secrets, their lives, their futures.”



Now imagine the precise targeting of content provided by platforms like Facebook combined with deepfakes which can’t be detected… actually, perhaps don’t, it’s a rather squeaky bum thought.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, deepfake, deepfakes, Featured, GAN, Generative Adversarial Network, research, Society






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Researchers find systems to counter deepfakes can be deceived,2021-02-10,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['systems', 'model', 'researchers', 'videos', 'deceived', 'deepfake', 'expo', 'deepfakes', 'video', 'believe', 'counter', 'used', 'san']","Researchers have found that systems designed to counter the increasing prevalence of deepfakes can be deceived.
The researchers, from the University of California – San Diego, first presented their findings at the WACV 2021 conference.
Some hope has been placed on systems to detect and counter deepfakes before they cause harm.
In 2018, a deepfake video circulated on social media which made Pelosi appear drunk and slurring her words.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
141,https://artificialintelligence-news.com/events/2021/jan/12/cyber-security-cloud-expo-global-virtual-2021/,"

Cyber Security & Cloud Expo Global Virtual 2021 – 17-18th March 2021





   

Event Information


Start: 17 March 2021 9:00 am                            

End: 18 March 2021 5:00 pm                            



                                Virtual                                 



enquiries@cybersecuritycloudexpo.com





The Cyber Security & Cloud Expo returns for 2021 with a fully online conference, covering two days of top-level content and thought leadership discussions looking at the Cyber Security & Cloud ecosystem.
Taking place on March 17-18th 2021 (GMT), the event will consist of live and on-demand sessions and will explore the latest developments, innovations and best practices within cyber security and cloud, also exploring the impact it has on industries including:
manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!
Register for free
WHO ATTENDS?This is a virtual technology conference for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.
3,000 attendees are expected to congregate from across the world including Chief Information Security Officers, Chief Information Officers, Chief Security Architects, Heads of Information Security, Chief Compliance Officers and more.
The conference agenda will tackle the real issues facing CISOs and security professionals today as modern enterprises evolve, as well as showcasing the most innovative and important developments in the security solutions market.
The online conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.
The Cyber Security & Cloud Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
Hear from 40+ industry-focused speakers explore cyber security & cloud advancements. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key topics examined include: Cloud security | SASE | Awareness & Culture | Vulnerability Management | AI in cyber | Application Security & DevSecOps | Cloud Security | Zero Trust | IoT
The co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
SESSIONS INCLUDE:● Panel: Reducing risk in the cloud – What you haven’t considered● Protecting data at speed: security in the hybrid era● Security at Zoom● Panel: Taking security home with you – Creating a powerful culture of awareness● Security in vaccine trials● Prevent insider threat by eliminating over-privilege● Cloud Security Architecture at Admiral Group● Who’s there, Machine? AI & the new security responsibilities● Panel: Mature application security – balancing speed and safety● Case Study – DevSecOps in practice at William Hill● Bend, Don’t Break: Creating a Cyber Resilient Business● Panel: The future of cloud security● Enhancing user experience with Zero Trust● Creating a safer IoT
SPEAKERS INCLUDE:● Direct Line Group – Head of Technology Resilience and Risk – Johanna Berlin● William Hill – Group Head of Cyber Security – Steve Bond● Zoom – Head of Product Security – Randy Barr● ICON Plc. – Head of Information Security – Tony Clarke● Refinitiv – Director, Cyber Security Strategy, Culture & Process Optimization – Reena Shah● Jacobs – Director of Cybersecurity – Nigel Stanley●Booking.com – Head of Data Security – Nir Chervoni● Admiral Group – Cloud Security Architect – Abhishek Vyas● SecureDynamics – Chief Communicator – Ashwin Krishnan● Cloud Industry Forum – Chief Executive – Alex Hilton● Experian – Head of IT Strategy | DevSecOps Security Managing Adviser – Dr. Wendy Ng
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the Cyber Security & Cloud Expo Global Virtual also offers key networking opportunities. The Matchmaking Tool, networking app allows you to plan your day with ease; view the agenda, speakers and exhibitors of the event. You can also connect with and organize meetings with other attendees, speakers, sponsors and exhibitors.
TICKET TYPESTickets are free to attend! Find out more and register* for free via the website. 
*Please note: By requesting to attend, your application will be vetted and either denied or approved due to this event’s seniority requirements. By registering you are also agreeing to the terms and conditions on the Cyber Security & Cloud Expo Virtual Website.
 





   

Event Information


Start: 17 March 2021 9:00 am                            

End: 18 March 2021 5:00 pm                            



                                Virtual                                 



enquiries@cybersecuritycloudexpo.com



The Cyber Security & Cloud Expo returns for 2021 with a fully online conference, covering two days of top-level content and thought leadership discussions looking at the Cyber Security & Cloud ecosystem.
Taking place on March 17-18th 2021 (GMT), the event will consist of live and on-demand sessions and will explore the latest developments, innovations and best practices within cyber security and cloud, also exploring the impact it has on industries including:
manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!
Register for free
WHO ATTENDS?This is a virtual technology conference for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.
3,000 attendees are expected to congregate from across the world including Chief Information Security Officers, Chief Information Officers, Chief Security Architects, Heads of Information Security, Chief Compliance Officers and more.
The conference agenda will tackle the real issues facing CISOs and security professionals today as modern enterprises evolve, as well as showcasing the most innovative and important developments in the security solutions market.
The online conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.
The Cyber Security & Cloud Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
Hear from 40+ industry-focused speakers explore cyber security & cloud advancements. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key topics examined include: Cloud security | SASE | Awareness & Culture | Vulnerability Management | AI in cyber | Application Security & DevSecOps | Cloud Security | Zero Trust | IoT
The co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
SESSIONS INCLUDE:● Panel: Reducing risk in the cloud – What you haven’t considered● Protecting data at speed: security in the hybrid era● Security at Zoom● Panel: Taking security home with you – Creating a powerful culture of awareness● Security in vaccine trials● Prevent insider threat by eliminating over-privilege● Cloud Security Architecture at Admiral Group● Who’s there, Machine? AI & the new security responsibilities● Panel: Mature application security – balancing speed and safety● Case Study – DevSecOps in practice at William Hill● Bend, Don’t Break: Creating a Cyber Resilient Business● Panel: The future of cloud security● Enhancing user experience with Zero Trust● Creating a safer IoT
SPEAKERS INCLUDE:● Direct Line Group – Head of Technology Resilience and Risk – Johanna Berlin● William Hill – Group Head of Cyber Security – Steve Bond● Zoom – Head of Product Security – Randy Barr● ICON Plc. – Head of Information Security – Tony Clarke● Refinitiv – Director, Cyber Security Strategy, Culture & Process Optimization – Reena Shah● Jacobs – Director of Cybersecurity – Nigel Stanley●Booking.com – Head of Data Security – Nir Chervoni● Admiral Group – Cloud Security Architect – Abhishek Vyas● SecureDynamics – Chief Communicator – Ashwin Krishnan● Cloud Industry Forum – Chief Executive – Alex Hilton● Experian – Head of IT Strategy | DevSecOps Security Managing Adviser – Dr. Wendy Ng
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the Cyber Security & Cloud Expo Global Virtual also offers key networking opportunities. The Matchmaking Tool, networking app allows you to plan your day with ease; view the agenda, speakers and exhibitors of the event. You can also connect with and organize meetings with other attendees, speakers, sponsors and exhibitors.
TICKET TYPESTickets are free to attend! Find out more and register* for free via the website. 
*Please note: By requesting to attend, your application will be vetted and either denied or approved due to this event’s seniority requirements. By registering you are also agreeing to the terms and conditions on the Cyber Security & Cloud Expo Virtual Website.
 







",Cyber Security & Cloud Expo Global Virtual 2021,2021-01-12,[],"['networking', 'security', 'global', 'chief', 'cyber', 'virtual', '2021', 'cloud', 'expo', 'information', 'head', 'panel', 'group']","The Cyber Security & Cloud Expo returns for 2021 with a fully online conference, covering two days of top-level content and thought leadership discussions looking at the Cyber Security & Cloud ecosystem.
3,000 attendees are expected to congregate from across the world including Chief Information Security Officers, Chief Information Officers, Chief Security Architects, Heads of Information Security, Chief Compliance Officers and more.
The Cyber Security & Cloud Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
Key topics examined include: Cloud security | SASE | Awareness & Culture | Vulnerability Management | AI in cyber | Application Security & DevSecOps | Cloud Security | Zero Trust | IoTThe co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
By registering you are also agreeing to the terms and conditions on the Cyber Security & Cloud Expo Virtual Website.",AInews
142,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
143,https://artificialintelligence-news.com/events/2021/jan/12/cyber-security-cloud-expo-global-virtual-2021/,"

Cyber Security & Cloud Expo Global Virtual 2021 – 17-18th March 2021





   

Event Information


Start: 17 March 2021 9:00 am                            

End: 18 March 2021 5:00 pm                            



                                Virtual                                 



enquiries@cybersecuritycloudexpo.com





The Cyber Security & Cloud Expo returns for 2021 with a fully online conference, covering two days of top-level content and thought leadership discussions looking at the Cyber Security & Cloud ecosystem.
Taking place on March 17-18th 2021 (GMT), the event will consist of live and on-demand sessions and will explore the latest developments, innovations and best practices within cyber security and cloud, also exploring the impact it has on industries including:
manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!
Register for free
WHO ATTENDS?This is a virtual technology conference for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.
3,000 attendees are expected to congregate from across the world including Chief Information Security Officers, Chief Information Officers, Chief Security Architects, Heads of Information Security, Chief Compliance Officers and more.
The conference agenda will tackle the real issues facing CISOs and security professionals today as modern enterprises evolve, as well as showcasing the most innovative and important developments in the security solutions market.
The online conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.
The Cyber Security & Cloud Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
Hear from 40+ industry-focused speakers explore cyber security & cloud advancements. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key topics examined include: Cloud security | SASE | Awareness & Culture | Vulnerability Management | AI in cyber | Application Security & DevSecOps | Cloud Security | Zero Trust | IoT
The co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
SESSIONS INCLUDE:● Panel: Reducing risk in the cloud – What you haven’t considered● Protecting data at speed: security in the hybrid era● Security at Zoom● Panel: Taking security home with you – Creating a powerful culture of awareness● Security in vaccine trials● Prevent insider threat by eliminating over-privilege● Cloud Security Architecture at Admiral Group● Who’s there, Machine? AI & the new security responsibilities● Panel: Mature application security – balancing speed and safety● Case Study – DevSecOps in practice at William Hill● Bend, Don’t Break: Creating a Cyber Resilient Business● Panel: The future of cloud security● Enhancing user experience with Zero Trust● Creating a safer IoT
SPEAKERS INCLUDE:● Direct Line Group – Head of Technology Resilience and Risk – Johanna Berlin● William Hill – Group Head of Cyber Security – Steve Bond● Zoom – Head of Product Security – Randy Barr● ICON Plc. – Head of Information Security – Tony Clarke● Refinitiv – Director, Cyber Security Strategy, Culture & Process Optimization – Reena Shah● Jacobs – Director of Cybersecurity – Nigel Stanley●Booking.com – Head of Data Security – Nir Chervoni● Admiral Group – Cloud Security Architect – Abhishek Vyas● SecureDynamics – Chief Communicator – Ashwin Krishnan● Cloud Industry Forum – Chief Executive – Alex Hilton● Experian – Head of IT Strategy | DevSecOps Security Managing Adviser – Dr. Wendy Ng
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the Cyber Security & Cloud Expo Global Virtual also offers key networking opportunities. The Matchmaking Tool, networking app allows you to plan your day with ease; view the agenda, speakers and exhibitors of the event. You can also connect with and organize meetings with other attendees, speakers, sponsors and exhibitors.
TICKET TYPESTickets are free to attend! Find out more and register* for free via the website. 
*Please note: By requesting to attend, your application will be vetted and either denied or approved due to this event’s seniority requirements. By registering you are also agreeing to the terms and conditions on the Cyber Security & Cloud Expo Virtual Website.
 





   

Event Information


Start: 17 March 2021 9:00 am                            

End: 18 March 2021 5:00 pm                            



                                Virtual                                 



enquiries@cybersecuritycloudexpo.com



The Cyber Security & Cloud Expo returns for 2021 with a fully online conference, covering two days of top-level content and thought leadership discussions looking at the Cyber Security & Cloud ecosystem.
Taking place on March 17-18th 2021 (GMT), the event will consist of live and on-demand sessions and will explore the latest developments, innovations and best practices within cyber security and cloud, also exploring the impact it has on industries including:
manufacturing | transport | supply chain | government | legal sectors | financial services | energy | utilities | insurance | healthcare | retail … and more!
Register for free
WHO ATTENDS?This is a virtual technology conference for the ambitious enterprise technology professional seeking to explore and evaluate cutting edge thought-leadership topics and valuable strategies to drive businesses forward.
3,000 attendees are expected to congregate from across the world including Chief Information Security Officers, Chief Information Officers, Chief Security Architects, Heads of Information Security, Chief Compliance Officers and more.
The conference agenda will tackle the real issues facing CISOs and security professionals today as modern enterprises evolve, as well as showcasing the most innovative and important developments in the security solutions market.
The online conference is perfect for those making investment and strategy decisions, or building and executing pioneering projects within their organisation.
The Cyber Security & Cloud Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
Hear from 40+ industry-focused speakers explore cyber security & cloud advancements. Industry leaders will share their unparalleled knowledge and real-life experiences in the forms of solo presentations, expert panel discussions and in-depth fireside chats.
Key topics examined include: Cloud security | SASE | Awareness & Culture | Vulnerability Management | AI in cyber | Application Security & DevSecOps | Cloud Security | Zero Trust | IoT
The co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
SESSIONS INCLUDE:● Panel: Reducing risk in the cloud – What you haven’t considered● Protecting data at speed: security in the hybrid era● Security at Zoom● Panel: Taking security home with you – Creating a powerful culture of awareness● Security in vaccine trials● Prevent insider threat by eliminating over-privilege● Cloud Security Architecture at Admiral Group● Who’s there, Machine? AI & the new security responsibilities● Panel: Mature application security – balancing speed and safety● Case Study – DevSecOps in practice at William Hill● Bend, Don’t Break: Creating a Cyber Resilient Business● Panel: The future of cloud security● Enhancing user experience with Zero Trust● Creating a safer IoT
SPEAKERS INCLUDE:● Direct Line Group – Head of Technology Resilience and Risk – Johanna Berlin● William Hill – Group Head of Cyber Security – Steve Bond● Zoom – Head of Product Security – Randy Barr● ICON Plc. – Head of Information Security – Tony Clarke● Refinitiv – Director, Cyber Security Strategy, Culture & Process Optimization – Reena Shah● Jacobs – Director of Cybersecurity – Nigel Stanley●Booking.com – Head of Data Security – Nir Chervoni● Admiral Group – Cloud Security Architect – Abhishek Vyas● SecureDynamics – Chief Communicator – Ashwin Krishnan● Cloud Industry Forum – Chief Executive – Alex Hilton● Experian – Head of IT Strategy | DevSecOps Security Managing Adviser – Dr. Wendy Ng
NETWORKING OPPORTUNITIES:In addition to cutting edge content, the Cyber Security & Cloud Expo Global Virtual also offers key networking opportunities. The Matchmaking Tool, networking app allows you to plan your day with ease; view the agenda, speakers and exhibitors of the event. You can also connect with and organize meetings with other attendees, speakers, sponsors and exhibitors.
TICKET TYPESTickets are free to attend! Find out more and register* for free via the website. 
*Please note: By requesting to attend, your application will be vetted and either denied or approved due to this event’s seniority requirements. By registering you are also agreeing to the terms and conditions on the Cyber Security & Cloud Expo Virtual Website.
 







",Cyber Security & Cloud Expo Global Virtual 2021,2021-01-12,[],"['networking', 'security', 'global', 'chief', 'cyber', 'virtual', '2021', 'cloud', 'expo', 'information', 'head', 'panel', 'group']","The Cyber Security & Cloud Expo returns for 2021 with a fully online conference, covering two days of top-level content and thought leadership discussions looking at the Cyber Security & Cloud ecosystem.
3,000 attendees are expected to congregate from across the world including Chief Information Security Officers, Chief Information Officers, Chief Security Architects, Heads of Information Security, Chief Compliance Officers and more.
The Cyber Security & Cloud Expo Global Virtual also offers exclusive networking opportunities including AI-powered personalised recommendations, virtual 1-2-1 meetings speed networking and more!
Key topics examined include: Cloud security | SASE | Awareness & Culture | Vulnerability Management | AI in cyber | Application Security & DevSecOps | Cloud Security | Zero Trust | IoTThe co-located virtual events will also cover 5G, AI, Big Data, Cyber Security & Cloud and Blockchain.
By registering you are also agreeing to the terms and conditions on the Cyber Security & Cloud Expo Virtual Website.",AInews
144,https://artificialintelligence-news.com/2020/09/23/microsoft-exclusive-rights-openai-gpt3/,"

Microsoft is granted exclusive rights to use OpenAI’s GPT-3




 






By Ryan Daws |
        September 23, 2020                    | TechForge Media

                            Categories:
                                    Microsoft,
                                    OpenAI,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




Microsoft and OpenAI’s close relationship has taken another leap forward with the former gaining exclusive GPT-3 access.
GPT-3 has been the talk of the AI town in recent months. OpenAI’s innovation can help to create convincing articles and the company once deemed it too dangerous to release in a world where misinformation and fake news is already problematic.
OpenAI never made GPT-3 publicly available but instead provided access to a limited number of trusted researchers.
Microsoft announced today that it now has the exclusive rights to leverage GPT-3’s “technical innovations to develop and deliver advanced AI solutions for our customers, as well as create new solutions that harness the amazing power of advanced natural language generation.”
In other words, Microsoft will be able to deploy GPT-3 capabilities in products such as Office, Windows, and Teams.
Kevin Scott, Chief Technology Officer at Microsoft, wrote in a blog post:
“GPT-3 is the largest and most advanced language model in the world, clocking in at 175 billion parameters, and is trained on Azure’s AI supercomputer.Today, I’m very excited to announce that Microsoft is teaming up with OpenAI to exclusively license GPT-3, allowing us to leverage its technical innovations to develop and deliver advanced AI solutions for our customers, as well as create new solutions that harness the amazing power of advanced natural language generation.”
There has been some debate over the impact GPT-3 will have on society. Some believe it’s dangerous, while others don’t think it poses a threat (at least in its current form.)
A Guardian article earlier this month with the headline ‘A robot wrote this entire article. Are you scared yet, human?’ really kicked off the debate.
The article used GPT-3 to generate its content but was accused of being misleading as it required substantial human intervention.
For the Guardian’s article, a human first wrote 50 words. GPT-3 then created eight drafts from the contributed text. A human then went through each of the eight drafts and picked the best parts. Finally, a human went on to edit the text to make it coherent before publishing it.
AI expert Jarno Duursma called GPT-3 “essentially a super-advanced auto-complete system.”
A blossoming relationship
Last year, Microsoft invested $1 billion in OpenAI to help speed up the development of Artificial General Intelligence (AGI) – which overcomes today’s AI limitations.
Current AIs are designed for specific tasks and require some human input. AGIs will be able to think like a human and handle multiple tasks, similar to how JARVIS and HAL are portrayed in films.
Microsoft’s bumper investment in OpenAI secured its place as the exclusive provider of cloud computing services for the AI giant. Together, the pair have committed to building new Azure AI supercomputing technologies.
Satya Nadella, CEO of Microsoft, said last year of the company’s OpenAI investment:
“AI is one of the most transformative technologies of our time and has the potential to help solve many of our world’s most pressing challenges.By bringing together OpenAI’s breakthrough technology with new Azure AI supercomputing technologies, our ambition is to democratise AI — while always keeping AI safety front and centre — so everyone can benefit.”
The exclusive rights to use GPT-3 is the first major win for Microsoft from its OpenAI investment, but it’s unlikely to be the last.
Back in May, Microsoft signed another deal with OpenAI to build an Azure-hosted supercomputer for testing large-scale models.
Microsoft and OpenAI’s supercomputer will deliver eye-watering amounts of power from its 285,000 CPU cores and 10,000 GPUs. Such power will be required for achieving the holy grail of AGI.
“We’ve learned more and more about what we need and the different limits of all the components that make up a supercomputer,” said Sam Altman, CEO of OpenAI earlier this year. “Microsoft was able to build it.”
The blossoming relationship between Microsoft and OpenAI looks only set to get stronger in the coming years.
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: ai, artificial intelligence, Featured, gpt-3, microsoft, openai






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Microsoft is granted exclusive rights to use OpenAI’s GPT-3,2020-09-23,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['exclusive', 'granted', 'human', 'rights', 'gpt3', 'openais', 'supercomputer', 'solutions', 'expo', 'ai', 'microsoft', 'openai', 'power', 'advanced']","Microsoft and OpenAI’s close relationship has taken another leap forward with the former gaining exclusive GPT-3 access.
OpenAI never made GPT-3 publicly available but instead provided access to a limited number of trusted researchers.
Microsoft and OpenAI’s supercomputer will deliver eye-watering amounts of power from its 285,000 CPU cores and 10,000 GPUs.
“Microsoft was able to build it.”The blossoming relationship between Microsoft and OpenAI looks only set to get stronger in the coming years.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
145,https://artificialintelligence-news.com/2020/09/10/experts-misleading-claim-openai-gpt3-article/,"

Expert calls out ‘misleading’ claim that OpenAI’s GPT-3 wrote a full article




 






By Ryan Daws |
        September 10, 2020                    | TechForge Media

                            Categories:
                                    OpenAI,
                                    Society,
                        


Editor at TechForge Media. Often sighted at global tech conferences with a coffee in one hand and laptop in the other. If it's geeky, I'm probably into it.




AI expert Jarno Duursma has called out a misleading article in The Guardian which claims to have been written entirely by OpenAI’s GPT-3.
GPT-3 has made plenty of headlines in recent months. The coverage is warranted, GPT-3 is certainly impressive—but many of the claims of its current capabilities are greatly exaggerated.
The headline of the article which Duursma questions is: “A robot wrote this entire article. Are you scared yet, human?”
It’s a headline that’s bound to generate some clicks. However, often a headline is as far as the reader gets:
What bothers me most about the article is that the newspaper intentionally seems to forget that many people are sloppy, hurried, lazy readers. They read the headline of the article, the article itself and not the italics.— Jarno Duursma (@JarnoDuursma) September 9, 2020
So there will be people who’ve read the headline and now believe there are powerful “robots” writing entire articles—a false and dangerous narrative in a world with an already growing distrust in the media.
GPT-3 requires human input and must first be supplied with text prompts. To offer a simplified explanation, Duursma calls it “essentially a super-advanced auto-complete system.”
There’s another group of readers; those which skim-read perhaps the first half of an article to get the gist. It’s understandable, life is hectic. However, that means us writers need to ensure any vital information is near the top and not somewhat hidden:
The explanation of the role of human journalists in the creation of this article is subtly hidden in the last lines of a italicized text at the bottom of the page. Of course, almost nobody reads that. Judging from the reactions on twitter, I think I'm right.— Jarno Duursma (@JarnoDuursma) September 9, 2020
AI technologies will remain assistive to humans for the foreseeable future. While AIs can help with things like gathering research and completing tasks, it all still requires human prompts.
In the case of The Guardian’s article, a human first wrote 50 words. GPT-3 then created eight drafts from the contributed text. A human then went through each of the eight drafts and picked the best parts. Finally, a human went on to edit the text to make it coherent before publishing it.
That’s a lot of human intervention for an article which claims to have been entirely written by AI.
Research scientist Janelle Shane has access to GPT-3 and used it to generate 12 essays similar to what The Guardian would have sifted through to help create its AI-assisted article. Most of the generated text isn’t particularly human-like:
Here are 12 generated essays from GPT-3 using The Guardian's prompt, at various temperature settings. Remember, GPT-3's task is to be as formulaic as possible. I'm amused at how many of them begin by quoting Elon Musk and Bill Gates.https://t.co/zWiZvMJDGJ pic.twitter.com/IJJ4pfSGoi— Janelle Shane (@JanelleCShane) September 9, 2020
Super-intelligent AIs which can do all of these tasks like a human, known as AGIs (Artificial General Intelligences), are likely decades away.
Last year, AI experts participated in a survey on AGI timing:
45% predict AGI will be achieved before 2060.34% expect after 2060.21% believe the so-called singularity will never occur.
Even if/when AGI is achieved, there’s a growing consensus that all decisions should ultimately be made by a human to ensure accountability. That means a theoretical generated by an AI would still be checked by a human before it’s published.
Articles like the one published by The Guardian create unnecessary fear which hinders innovation. Such articles also raise unrealistic expectations about what today’s AI technologies can achieve.
Both outcomes are unhealthy for an emerging technology which has huge long-term potential benefits but requires some realism about what’s actually possible today and in the near future.
(Photo by Roman Kraft on Unsplash)
 Interested in hearing industry leaders discuss subjects like this? Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.
 Tags: agi, ai, artificial intelligence, Featured, gpt-3, jarno duursma, openai, text generator






View Comments


Leave a comment




Leave a Reply Cancel replyYou must be logged in to post a comment. 






",Expert calls out ‘misleading’ claim that OpenAI’s GPT-3 wrote a full article,2020-09-10,"['Ryan Daws', 'Editor At Techforge Media. Often Sighted At Global Tech Conferences With A Coffee In One Hand', ""Laptop In The Other. If It'S Geeky"", ""I'M Probably Into It.""]","['expert', 'human', 'gpt3', 'openais', 'misleading', 'requires', 'wrote', 'duursma', 'article', 'expo', 'text', 'ai', 'headline', 'jarno', 'calls', 'claim']","AI expert Jarno Duursma has called out a misleading article in The Guardian which claims to have been written entirely by OpenAI’s GPT-3.
The headline of the article which Duursma questions is: “A robot wrote this entire article.
GPT-3 requires human input and must first be supplied with text prompts.
While AIs can help with things like gathering research and completing tasks, it all still requires human prompts.
Attend the co-located 5G Expo, IoT Tech Expo, Blockchain Expo, AI & Big Data Expo, and Cyber Security & Cloud Expo World Series with upcoming events in Silicon Valley, London, and Amsterdam.",AInews
146,https://support.google.com/websearch%3Fp%3Dws_settings_location%26hl%3Den-BE,"   Read about Google's response to COVID-19  Google ChromeGoogle AccountYouTubeGmailGoogle PlayGoogle SearchAdSensePixel PhoneGoogle MapsGoogle CloudGoogle AdsGoogle PhotosGoogle For FamiliesGoogle FiGoogle NestGoogle PayGoogle StoreGoogle DriveGoogle ShoppingGoogle AccessibilityConsumerBloggerFinanceGoogle EarthGoogle MapsGmailPicasaToolbarGoogle SearchCalendarDocs EditorsBooksGoogle GroupsYouTubeTrendsAndroidSitesGoogle ChromeGoogle DriveGoogle VoiceGoogle TranslateChromebookGoogle TVGoogle PlayMy MapsChrome Web StoreTravelGoogle FiberNexusAdsHangoutsNik CollectionChromecastSnapseedGoogle KeepStarbucks WiFiGoogle FiWazeWear OS by GoogleGoogle FitYouTube Kids Parental GuideGoogle StoreChromecast built-inGoogle PhotosAndroid AutoAndroid TVGoogle For FamiliesGoogle CameraGoogle WifiLocal GuidesYouTube MusicYouTube Studio App Help CenterGoogle CardboardGoogle DuoDatallyYouTube GoGoogle NestYouTube TVGoogle ClipsPixel PhoneOpinion RewardsDaydreamGoogle AssistantFiles by GoogleCS FirstGoogle ChatPixelbookMessagesReserve with GooglePhone appGboardContactsGoogle OneGoogle PayTasksGoogle NewsGoogle AccessibilityScience JournalGoogle ShoppingStadiaGoogle Food OrderingGoogle Kids SpaceUser SecurityBusinessGoogle Ads EditorGoogle Workspace AdminBooksSearch ConsoleProgrammable Search EnginePublisher CenterAd GrantsGoogle AdsGoogle CloudStudioAdSenseAuthorized BuyersMap Content PartnersGoogle Merchant CenterGoogle Ad ManagerAnalyticsCurrentsTransit PartnersGlobal Market FinderGoogle for NonprofitsSearch Ads 360Google Chrome EnterpriseGoogle AdMobAdWords ExpressGoogle VaultGoogle My BusinessHotel CenterDisplay & Video 360Google Search ApplianceCampaign Manager 360Google DomainsGoogle Pay MerchantGoogle Cloud Platform ConsoleCultural Institute PlatformDisplay SpecsAndroid EnterpriseCloud SearchGoogle Marketing PlatformCardboard ManufacturerCard IssuerGoogle MeetJamboardGoogle Pay for Online BusinessWork InsightsComparison Shopping Services CenterPOps VMO Scaled Services KnowledgeElastifileCEWADeveloperPlay ConsoleGDGGoogle Web DesignerCast DeveloperreCAPTCHAPayments centerPayment ProcessorsJustice LeagueYour account
Can't access your account?
Recent transactions with Google
Useful stuff you can do with Google

Help CommunitiesLearn more about
Google's Product Experts Program
Status dashboardIf you're having trouble accessing a Google product, there's a chance we're currently experiencing a temporary problem. You can check for outages and downtime on the G Suite Status Dashboard. ",Google Help,,[],"['phone', 'precautionary', 'support', 'trouble', 'reaching', 'specialists', 'product', 'google', 'help', 'productspecific', 'team']","As a precautionary health measure for our support specialists in light of COVID-19, we're operating with a limited team.
If you need help with a product whose support you had trouble reaching over the phone, consult its product-specific Help Center.",AInews
